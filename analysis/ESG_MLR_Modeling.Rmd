---
title: "ESG MLR Modeling"
author: "Jonathan Maynard"
email: jonathan.maynard@ars.usda.gov
date: "Feb 10, 2017"
output: html_document
---


```{r eval=FALSE}
required.packages <- c("here", "parallelMap", "mlr", "mlrHyperopt", "e1071", 
    "Cairo", "raster", "lattice", "ggplot2", "scales", "rasterVis", "caret", 
    "kernlab", "pROC", "parallel", "foreach", "snowfall", "ranger", "randomForest", 
    "rgdal", "MODIS", "iml", "dplyr", "gridExtra", "Rsenal", "FSelector")
new.packages <- required.packages[!(required.packages %in% installed.packages()[, 
    "Package"])]
if (length(new.packages)) install.packages(new.packages)
lapply(required.packages, require, character.only = T)
rm(required.packages, new.packages)

no_cores <- detectCores() - 1
cl <- makeCluster(no_cores, type = "SOCK", outfile = "")
registerDoParallel(cl)
getDoParWorkers()
```

```{r eval=FALSE}
############################################################################################################################### Load data Load covariate names
load("/data/data2/data/esgMapping/R/co_covariate_names.Rdata")
load("/data/data2/data/esgMapping/R/nm_covariate_names.Rdata")
load("/data/data2/data/esgMapping/R/CO_ESG_modeling_data.Rdata")
load("/data/data2/data/esgMapping/R/NM_ESG_modeling_data.Rdata")
co.points <- readOGR(dsn = "/data/data2/data/esgMapping/analysis/data/derived_data/vector_data", 
    layer = "CO_points_final")
nm.points <- readOGR(dsn = "/data/data2/data/esgMapping/analysis/data/derived_data/vector_data", 
    layer = "NM_points_final")
############################################################################################################################### Study areas
CO <- readOGR(dsn = "/data/data1/R_DATA/Imagery_Vector/Ecosite_Group_Mapping/CO_Plat_study_area", 
    layer = "epaL4_mlra35sel_bndc")
# read in second shapefile of Mongolia and use projection of first to
# reproject new shapefile
NM <- readOGR(dsn = "/data/data1/R_DATA/Imagery_Vector/Ecosite_Group_Mapping/Chihuahuan_study_area", 
    layer = "Chihauhuan_Study_Area_Boundary")

CO.shapepath <- "/data/data1/R_DATA/Imagery_Vector/Ecosite_Group_Mapping/CO_Plat_study_area/epaL4_mlra35sel_bndc.shp"
NM.shapepath <- "/data/data1/R_DATA/Imagery_Vector/Ecosite_Group_Mapping/Chihuahuan_study_area/Chihauhuan_Study_Area_Boundary.shp"

# CO rasterize Set up a raster 'template' to use in rasterize()
ext.co <- extent(CO)
xy.co <- abs(apply(as.matrix(bbox(CO)), 1, diff))
r.co <- raster(ext.co, ncol = xy.co[1]/250, nrow = xy.co[2]/250)

# Rasterize the shapefile
CO_raster <- rasterize(CO, r.co)
res(CO_raster) <- 250
plot(CO_raster)

# NM rasterize Set up a raster 'template' to use in rasterize()
ext.nm <- extent(NM)
xy.nm <- abs(apply(as.matrix(bbox(NM)), 1, diff))
r.nm <- raster(ext.nm, ncol = xy.nm[1]/250, nrow = xy.nm[2]/250)

# Rasterize the shapefile
NM_raster <- rasterize(NM, r.nm)
res(NM_raster) <- 250
plot(NM_raster)

```

## Plotting of Covariates
```{r eval=FALSE}
cbPalette <- Set3(87)
NM_TAXOUSDA_plot <- gplot(nm.cov.brick[[269]], maxpixels=800000) +
  geom_raster(aes(fill = factor(value))) +
  coord_equal()+ #labs(x = "Easting (m)", y = "Northing (m)", fill = "Eco-Site") +
  ggtitle("NM TAXOUSDA") +scale_fill_manual(values=cbPalette)#, labels = c(as.character(c("Clayey", "Loamy", "Shallow Sandy", "Sandy","Deep Sandy"))))
NM_TAXOUSDA_plot
ggsave(NM_TAXOUSDA_plot, file = "NM_TAXOUSDA_plot.pdf", width = 8, height = 8)
ggsave(NM_TAXOUSDA_plot, file = "NM_TAXOUSDA_plot.png", width = 8, height = 8, type = "cairo-png")

```


# MODELING

## Modelling steps
  1. Create preprocess wrapper, wrap in the filter wrappers and tune across models to select filter threshold
  2. Perform hyperparameter tuning with preprocess and filter selection done within CV folds
  3. Assign learning optimal hyperparameters and then run final model using repeated 10-fold cross validation.
  4. Perform stacked ensemble modeling using selected models.
  5. Evaluate models with external validation dataset.

```{r eval=FALSE}
#-------------------------------------------------------------------------------------------
# --------register parallel backend
parallelStartSocket(cpus = 24, show.info = TRUE)
# parallelStop() --------create svm parameter set
svm.sigest.par = makeParamSet(makeNumericParam("cost", lower = -5, upper = 10, 
    trafo = function(x) 2^x), makeNumericParam(id = "gamma", lower = -10, 
    upper = 10, trafo = function(x) 2^x))
svm.sigest.par.config = makeParConfig(par.set = svm.sigest.par, learner.name = "classif.svm")
getParConfigParSet(svm.sigest.par.config)

# --------create random forest parameter set
rf.par.config = generateParConfig(learner = "classif.randomForest")
getParConfigParSet(rf.par.config)

# --------create xgboost parameter set
xgboost.par.config = generateParConfig(learner = "classif.xgboost")
getParConfigParSet(xgboost.par.config)

xgboost.par = makeParamSet(makeIntegerParam("max_depth", lower = 1, upper = 25), 
    makeNumericParam("eta", lower = 0.002, upper = 0.6), makeDiscreteParam("nrounds", 
        values = c(10, 30, 50, 80, 100)), makeNumericParam("lambda", lower = -1, 
        upper = 0, trafo = function(x) 10^x))

xgboost.par.config = makeParConfig(par.set = xgboost.par, learner.name = "classif.xgboost")
getParConfigParSet(xgboost.par.config)

#-------------------Set hypercontrol parameters
hyper.control = makeHyperControl(mlr.control = makeTuneControlRandom(maxit = 50L), 
    resampling = cv3, measures = list(acc, mmce, timetrain))
hyper.control.xgboost = makeHyperControl(mlr.control = makeTuneControlRandom(maxit = 50L), 
    resampling = cv3, measures = list(acc, mmce, timetrain))
#-------------------------------------------------------------------------------------------

# lookup key
unique(co.points@data[10:11])
unique(nm.points@data[14:15])
```


## Define modeling functions
```{r eval=FALSE}
#-----------------------------------------------------------------------------------------------
# multi-learner preprocessing function
#-----------------------------------------------------------------------------------------------

multiLearner.preprocess <- function(task) {
    
    #---------------Create preprocessing wrappers for each learner
    svm.proc.lrn = makePreprocWrapperCaret("classif.svm", ppc.nzv = TRUE, 
        ppc.center = TRUE, ppc.scale = TRUE)
    rf.proc.lrn = makePreprocWrapperCaret("classif.randomForest", ppc.nzv = TRUE, 
        ppc.center = TRUE, ppc.scale = TRUE)
    xgboost.proc.lrn = makePreprocWrapperCaret("classif.xgboost", ppc.nzv = TRUE, 
        ppc.center = TRUE, ppc.scale = TRUE)
    
    
    #----------------Feature selection with filter tuning
    # define different learners
    svm.lrn = makeFilterWrapper(learner = svm.proc.lrn, fw.method = "information.gain")
    rf.lrn = makeFilterWrapper(learner = rf.proc.lrn, fw.method = "information.gain")
    xgboost.lrn = makeFilterWrapper(learner = xgboost.proc.lrn, fw.method = "information.gain")
    
    # set threshold range for feature selection tuning
    ps.thresh = makeParamSet(makeDiscreteParam("fw.threshold", values = seq(0, 
        0.6, 0.05)))
    # set resampling scheme for feature tuning
    rdesc.3fcv = makeResampleDesc("CV", iters = 3)
    
    set.seed(120, "L'Ecuyer-CMRG")
    Task.filtune.svm = tuneParams(svm.lrn, task = task, resampling = rdesc.3fcv, 
        par.set = ps.thresh, control = makeTuneControlGrid(), measures = list(acc, 
            mmce, timetrain))
    
    Task.filtune.svm.lrn = makeFilterWrapper(learner = svm.proc.lrn, fw.method = "information.gain", 
        fw.threshold = Task.filtune.svm$x$fw.threshold)
    
    set.seed(120, "L'Ecuyer-CMRG")
    Task.filtune.rf = tuneParams(rf.lrn, task = task, resampling = rdesc.3fcv, 
        par.set = ps.thresh, control = makeTuneControlGrid(), measures = list(acc, 
            mmce, timetrain))
    
    Task.filtune.rf.lrn = makeFilterWrapper(learner = rf.proc.lrn, fw.method = "information.gain", 
        fw.threshold = Task.filtune.rf$x$fw.threshold)
    
    set.seed(120, "L'Ecuyer-CMRG")
    Task.filtune.xgboost = tuneParams(xgboost.lrn, task = task, resampling = rdesc.3fcv, 
        par.set = ps.thresh, control = makeTuneControlGrid(), measures = list(acc, 
            mmce, timetrain))
    
    Task.filtune.xgboost.lrn = makeFilterWrapper(learner = xgboost.proc.lrn, 
        fw.method = "information.gain", fw.threshold = Task.filtune.xgboost$x$fw.threshold)
    
    # #----------------Filter features using maximum optimized thresholds
    # from the three models threshold <-
    # min(c(Task.filtune.svm$x$fw.threshold,
    # Task.filtune.rf$x$fw.threshold, Task.filtune.xgboost$x$fw.threshold))
    # #------------------Set learners to minimum threshold--retain all
    # important covariates Task.filtune.svm.lrn <-
    # setHyperPars(Task.filtune.svm.lrn, fw.threshold = threshold)
    # Task.filtune.rf.lrn <- setHyperPars(Task.filtune.rf.lrn, fw.threshold
    # = threshold) Task.filtune.xgboost.lrn <-
    # setHyperPars(Task.filtune.xgboost.lrn, fw.threshold = threshold)
    
    #----------------Tune hyperparameters with Hyperopt approach
    # Hyperparameter tuning where feature selection is perfored within each
    # CV fold during parameter tuning
    
    set.seed(120, "L'Ecuyer-CMRG")
    Task_hyper.svm = hyperopt(task = task, learner = Task.filtune.svm.lrn, 
        par.config = svm.sigest.par.config, hyper.control = hyper.control)
    Task.filtune.partune.svm.lrn = setHyperPars(Task.filtune.svm.lrn, par.vals = Task_hyper.svm$x)
    Task.filtune.partune.svm.lrn = setLearnerId(Task.filtune.partune.svm.lrn, 
        id = "SVM")
    Task.filtune.partune.svm.lrn$short.name = "SVM"
    
    set.seed(120, "L'Ecuyer-CMRG")
    Task_hyper.rf = hyperopt(task = task, learner = Task.filtune.rf.lrn, 
        par.config = rf.par.config, hyper.control = hyper.control)
    Task.filtune.partune.rf.lrn = setHyperPars(Task.filtune.rf.lrn, par.vals = c(Task_hyper.rf$x, 
        importance = TRUE))
    Task.filtune.partune.rf.lrn = setLearnerId(Task.filtune.partune.rf.lrn, 
        id = "RF")
    Task.filtune.partune.rf.lrn$short.name = "RF"
    
    Task.filtune.xgboost.lrn <- setHyperPars(Task.filtune.xgboost.lrn, 
        nthread = 2)
    
    set.seed(120, "L'Ecuyer-CMRG")
    Task_hyper.xgboost = hyperopt(task = task, learner = Task.filtune.xgboost.lrn, 
        par.config = xgboost.par.config, hyper.control = hyper.control.xgboost)
    Task.filtune.partune.xgboost.lrn = setHyperPars(Task.filtune.xgboost.lrn, 
        par.vals = c(Task_hyper.xgboost$x, nthread = 2))
    Task.filtune.partune.xgboost.lrn = setLearnerId(Task.filtune.partune.xgboost.lrn, 
        id = "XGB")
    Task.filtune.partune.xgboost.lrn$short.name = "XGB"
    
    Task.stacked.lrns = list(Task.filtune.partune.svm.lrn, Task.filtune.partune.rf.lrn, 
        Task.filtune.partune.xgboost.lrn)
    Task.stacked.lrns = lapply(Task.stacked.lrns, setPredictType, "prob")
    # averaging of base learner probabiilties
    Task.stacked.lrns.model = makeStackedLearner(base.learners = Task.stacked.lrns, 
        predict.type = "prob", method = "average")
    Task.stacked.lrns.model = setLearnerId(Task.stacked.lrns.model, id = "Ensemble")
    Task.stacked.lrns.model$short.name = "Ensemble"
    
    Task.lrns = list(Task.filtune.partune.svm.lrn, Task.filtune.partune.rf.lrn, 
        Task.filtune.partune.xgboost.lrn, Task.stacked.lrns.model)
    
    return(Task.lrns)
    
}

#-----------------------------------------------------------------------------------------------
# Resampling function
#-----------------------------------------------------------------------------------------------
resample.multi.learner <- function(Task.lrns, m.task, resamp, m) {
    set.seed(120, "L'Ecuyer-CMRG")
    Model_var.resamp.ksvm = mlr::resample(learner = Task.lrns[[1]], task = m.task, 
        resampling = resamp, measures = m)
    
    set.seed(120, "L'Ecuyer-CMRG")
    Model_var.resamp.rf = mlr::resample(learner = Task.lrns[[2]], task = m.task, 
        resampling = resamp, measures = m)
    
    set.seed(120, "L'Ecuyer-CMRG")
    Model_var.resamp.xgb = mlr::resample(learner = Task.lrns[[3]], task = m.task, 
        resampling = resamp, measures = m)
    
    set.seed(120, "L'Ecuyer-CMRG")
    Model_var.resamp.ens = mlr::resample(learner = Task.lrns[[4]], task = m.task, 
        resampling = resamp, measures = m)
    
    Mod.resamp = list(Model_var.resamp.ksvm, Model_var.resamp.rf, Model_var.resamp.xgb, 
        Model_var.resamp.ens)
    return(Mod.resamp)
}

#-----------------------------------------------------------------------------------------------
# raster parallel predict function for MLR models
#-----------------------------------------------------------------------------------------------

# x=covariate brick, model=mlr model, block_n = sets min number of
# blocks
mlr.raster.predict.run <- function(x, filename, model, block_n, mask, layers) {
    out <- brick(x, nl = layers, values = FALSE)
    out <- writeStart(out, filename = filename, format = "GTiff", overwrite = TRUE)
    bs <- blockSize(x, minblocks = block_n)
    pb <- pbCreate(bs$n)
    pb <- txtProgressBar(min = 1, max = bs$n, style = 3)
    todisk <- TRUE
    # foreach(i=1:bs$n, .packages = c('mlr', 'raster', 'caret'),
    # .export=c('out', 'bs', 'pb')) %dopar% {
    for (i in 1:bs$n) {
        v <- getValuesBlock(x, row = bs$row[i], nrows = bs$nrows[i])
        v <- as.data.frame(v)
        v[is.na(v)] <- 0
        vv <- array(, dim = c(nrow(v), layers))
        class_out <- predict(model, newdata = v)
        class_out$data$response <- as.numeric(sub("ES", "", class_out$data$response))
        vv <- class_out$data
        vvv <- do.call("cbind", lapply(vv, array))
        out <- writeValues(out, vvv, bs$row[i])
        setTxtProgressBar(pb, i)
    }
    out <- writeStop(out)
    out.mask <- mask(out, mask, filename = filename, overwrite = T)
    return(out.mask)
    close(pb)
}

#-----------------------------------------------------------------------------------------------
# raster parallel predict function for confusion index
#-----------------------------------------------------------------------------------------------
CI.calc.run <- function(x, filename) {
    out <- brick(x, nl = 1, values = FALSE)
    out <- writeStart(out, filename = filename, format = "GTiff", overwrite = TRUE)
    bs <- blockSize(x, minblocks = block_n)
    pb <- pbCreate(bs$n)
    pb <- txtProgressBar(min = 1, max = bs$n, style = 3)
    todisk <- TRUE
    # foreach(i=1:bs$n, .packages = c('mlr', 'raster', 'caret'),
    # .export=c('out', 'bs', 'pb')) %dopar% {
    for (i in 1:bs$n) {
        v <- getValuesBlock(x, row = bs$row[i], nrows = bs$nrows[i])
        v <- as.data.frame(v)
        vv <- array(, dim = c(nrow(v), 1))
        vv <- (1 - (first(v[, 1:(length(v) - 1)]) - second(v[, 1:(length(v) - 
            1)])))
        # vv[,2] <- apply(v[,1:(ncol(v)-1)], 1, which.max)
        vvv <- t(do.call("cbind", lapply(vv, array)))
        out <- writeValues(out, vvv, bs$row[i])
        setTxtProgressBar(pb, i)
    }
    out <- writeStop(out)
    return(out)
    close(pb)
}

## Calculate confusion index and most probable class confusion index
first <- function(x) {
    # order by row number then by value
    y <- t(x)
    array(y[order(col(y), y)], dim(y))[nrow(y), ]
}
second <- function(x) {
    # order by row number then by value
    y <- t(x)
    array(y[order(col(y), y)], dim(y))[nrow(y) - 1, ]
}


#-----------------------------------------------------------------------------------------------
# Scaled Shannon Entropy Index
#-----------------------------------------------------------------------------------------------
# input probability raster
SSEI.calc.run <- function(x, filename) {
    out <- brick(x, nl = 1, values = FALSE)
    out <- writeStart(out, filename = filename, format = "GTiff", overwrite = TRUE)
    bs <- blockSize(x, minblocks = block_n)
    pb <- pbCreate(bs$n)
    pb <- txtProgressBar(min = 1, max = bs$n, style = 3)
    todisk <- TRUE
    # foreach(i=1:bs$n, .packages = c('mlr', 'raster', 'caret'),
    # .export=c('out', 'bs', 'pb')) %dopar% {
    for (i in 1:bs$n) {
        v <- getValuesBlock(x, row = bs$row[i], nrows = bs$nrows[i])
        v <- as.data.frame(v)
        vv <- array(, dim = c(nrow(v), 1))
        prob.ent <- unlist(alply(v, 1, .fun = function(x) {
            entropy.empirical(unlist(x))
        }))
        vv <- round(prob.ent/entropy.empirical(rep(1/ncol(v), ncol(v))) * 
            100)
        vvv <- t(do.call("cbind", lapply(vv, array)))
        out <- writeValues(out, vvv, bs$row[i])
        setTxtProgressBar(pb, i)
    }
    out <- writeStop(out)
    return(out)
    close(pb)
}

#---------------------------------------------------------------------------------------
# Function requires mlr resampling object with probabilities
classwise_accuracy_stats <- function(model) {
    n.l <- plyr::count(model$pred$data$truth)
    n.l <- data.frame(matrix(n.l$freq, nrow = 1, dimnames = list(1, paste(n.l$x))))
    probs <- model$pred$data[, 3:10]
    names <- colnames(n.l)
    names(probs) = names
    obs <- data.frame(lapply(names, FUN = function(i) {
        ifelse(model$pred$data$truth == i, 1, 0)
    }))
    names(obs) = names
    obs.pred <- list(as.matrix(obs[, names]), probs[, names])
    error <- Reduce("-", obs.pred)
    error.l <- as.data.frame(t(signif(colSums(error, na.rm = T), 3)))
    ## copy ID of the point
    error <- as.data.frame(error)
    error$id <- paste(model$pred$data$id)
    out <- list(n.l, obs.pred, error, error.l)
    names(out) <- c("n.l", "obs.pred", "error", "error.l")
    ## calculate totals per soil type
    N.tot <- plyr::rbind.fill(out[["n.l"]])
    N.tot <- colSums(N.tot)
    
    ## mean error per soil type:
    mean.error <- plyr::rbind.fill(out[["error.l"]])
    mean.error <- colSums(mean.error)/N.tot
    obs2 <- plyr::rbind.fill(as.data.frame(out[["obs.pred"]][[1]]))
    pred <- plyr::rbind.fill(as.data.frame(out[["obs.pred"]][[2]]))
    ## Get the most probable class:
    ranks.pred <- apply(pred, MARGIN = 1, which.max)
    ranks.obs <- apply(obs2, MARGIN = 1, which.max)
    ## derive confusion matrix:
    cf <- mda::confusion(names(obs2)[ranks.obs], names(pred)[ranks.pred])
    c.kappa <- psych::cohen.kappa(cbind(names(obs2)[ranks.obs], names(pred)[ranks.pred]))
    purity <- sum(diag(cf))/sum(cf) * 100
    ## Accuracy for Binomial var
    ## [http://www.r-bloggers.com/evaluating-logistic-regression-models/]:
    TPR <- sapply(1:ncol(obs2), function(c) {
        mean(performance(prediction(pred[, c], obs2[, c]), measure = "tpr")@y.values[[1]])
    })
    AUC <- sapply(1:ncol(obs2), function(c) {
        performance(prediction(pred[, c], obs2[, c]), measure = "auc")@y.values[[1]]
    })
    cv.r <- list(obs2, pred, error, data.frame(ME = mean.error, TPR = TPR, 
        AUC = AUC, N = N.tot), cf, c.kappa, purity)
    names(cv.r) <- c("Observed", "Predicted", "CV_residuals", "Classes", 
        "Confusion.matrix", "Cohen.Kappa", "Purity")
    return(cv.r)
}

```


## Colorado Plateau Models
```{r eval=FALSE}
# register parallel backend
parallelStartSocket(cpus = 24, show.info = TRUE)

# Create covariate datasets
#---------------CO All covariate dataframe and task
co.esg.all.cov <- co.points.covariates[, -1]

co.esg.all.cov <- na.omit(co.esg.all.cov)
co.esg.all.cov.rm <- removeConstantFeatures(co.esg.all.cov)
CO_all_var = makeClassifTask(id = "CO_ESG_all", data = co.esg.all.cov.rm, 
    target = "esite")

#---------------CO Hyper-temp covariate dataframe and task
co.esg.hyper.cov <- co.points.covariates[, c("esite", hype.ndvi.names, 
    hype.swir2.names, hype.lst_day.names, hype.lst_night.names)]

co.esg.hyper.cov <- na.omit(co.esg.hyper.cov)
co.esg.hyper.cov.rm <- removeConstantFeatures(co.esg.hyper.cov)
CO_hyper_var = makeClassifTask(id = "CO_ESG_hyper", data = co.esg.hyper.cov.rm, 
    target = "esite")

#---------------CO NDVI covariate dataframe and task
co.esg.ndvi.cov <- co.points.covariates[, c("esite", hype.ndvi.names)]

co.esg.ndvi.cov <- na.omit(co.esg.ndvi.cov)
co.esg.ndvi.cov.rm <- removeConstantFeatures(co.esg.ndvi.cov)
CO_ndvi_var = makeClassifTask(id = "CO_ESG_ndvi", data = co.esg.ndvi.cov.rm, 
    target = "esite")

#---------------CO Abiotic covariate dataframe and task
co.esg.abiotic.cov <- co.points.covariates[, c("esite", terrain.co.names, 
    lithology.co.names, prec.co.names, temp.co.names, bio.co.names, namrad.co.names, 
    soil.thick.co.names, soilGrids.co.names)]

co.esg.abiotic.cov <- na.omit(co.esg.abiotic.cov)
co.esg.abiotic.cov.rm <- removeConstantFeatures(co.esg.abiotic.cov)
CO_abiotic_var = makeClassifTask(id = "CO_ESG_abiotic", data = co.esg.abiotic.cov.rm, 
    target = "esite")

#---------------CO SoilsGrid covariate dataframe and task
co.esg.sg.cov <- co.points.covariates[, c("esite", soilGrids.co.names)]

co.esg.sg.cov <- na.omit(co.esg.sg.cov)
co.esg.sg.cov.rm <- removeConstantFeatures(co.esg.sg.cov)
CO_sg_var = makeClassifTask(id = "CO_ESG_sg", data = co.esg.sg.cov.rm, 
    target = "esite")

#---------------CO DSM covariate dataframe and task
co.esg.dsm.cov <- co.points.covariates[, c("esite", terrain.co.names, lithology.co.names, 
    prec.co.names, temp.co.names, bio.co.names, namrad.co.names, soil.thick.co.names, 
    soilGrids.co.names, ndvi.co.names, mir.co.names, lst.day.co.names, 
    lst.night.co.names)]

co.esg.dsm.cov <- na.omit(co.esg.dsm.cov)
co.esg.dsm.cov.rm <- removeConstantFeatures(co.esg.dsm.cov)
CO_dsm_var = makeClassifTask(id = "CO_ESG_dsm", data = co.esg.dsm.cov.rm, 
    target = "esite")


#--------------All covariate models-------------------------------------------------------------------------------
stime1 <- system.time({
    CO_all_lrns <- multiLearner.preprocess(task = CO_all_var)
})[3]
stime1

## Choose the resampling strategy
rdesc.10fcv = makeResampleDesc(method = "CV", iters = 10, stratify = TRUE)
m = list(acc, kappa, mmce, timetrain)

# Apply resampling function
stime2 <- system.time({
    CO_all_resample <- resample.multi.learner(CO_all_lrns, CO_all_var, 
        rdesc.10fcv, m)
})[3]
stime2
save(CO_all_resample, CO_all_lrns, file = "/data/data2/data/esgMapping/R/CO_all_resample.RData")

#---------------------------------------------------------------------------------------

CO_all.svm.pred = getRRPredictions(CO_all_resample[[1]])
CO_all.svm.cm <- calculateConfusionMatrix(CO_all.svm.pred, relative = TRUE)
CO_all.rf.pred = getRRPredictions(CO_all_resample[[2]])
CO_all.rf.cm <- calculateConfusionMatrix(CO_all.rf.pred, relative = TRUE)
CO_all.xgb.pred = getRRPredictions(CO_all_resample[[3]])
CO_all.xgb.cm <- calculateConfusionMatrix(CO_all.xgb.pred, relative = TRUE)
CO_all.ens.pred = getRRPredictions(CO_all_resample[[4]])
CO_all.ens.cm <- calculateConfusionMatrix(CO_all.ens.pred, relative = TRUE)

save(CO_all_resample, CO_all_lrns, file = "/data/data2/data/esgMapping/R/CO_all_resample.RData")
rm(CO_all_resample)

#--------------Hyper covariate models-------------------------------------------------------------------------------
stime1 <- system.time({
    CO_hyper_lrns <- multiLearner.preprocess(task = CO_hyper_var)
})[3]
stime1

## Choose the resampling strategy
rdesc.10fcv = makeResampleDesc(method = "CV", iters = 10, stratify = TRUE)
m = list(acc, kappa, mmce, timetrain)

# Apply resampling function
stime2 <- system.time({
    CO_hyper_resample <- resample.multi.learner(CO_hyper_lrns, CO_hyper_var, 
        rdesc.10fcv, m)
})[3]
stime2
save(CO_hyper_resample, CO_hyper_lrns, file = "/data/data2/data/esgMapping/R/CO_hyper_resample.RData")

#---------------------------------------------------------------------------------------

CO_hyper.svm.pred = getRRPredictions(CO_hyper_resample[[1]])
CO_hyper.svm.cm <- calculateConfusionMatrix(CO_hyper.svm.pred, relative = TRUE)
CO_hyper.rf.pred = getRRPredictions(CO_hyper_resample[[2]])
CO_hyper.rf.cm <- calculateConfusionMatrix(CO_hyper.rf.pred, relative = TRUE)
CO_hyper.xgb.pred = getRRPredictions(CO_hyper_resample[[3]])
CO_hyper.xgb.cm <- calculateConfusionMatrix(CO_hyper.xgb.pred, relative = TRUE)
CO_hyper.ens.pred = getRRPredictions(CO_hyper_resample[[4]])
CO_hyper.ens.cm <- calculateConfusionMatrix(CO_hyper.ens.pred, relative = TRUE)

save(CO_hyper_resample, CO_hyper_lrns, file = "/data/data2/data/esgMapping/R/CO_hyper_resample.RData")
rm(CO_hyper_resample)

#----------------------------------------------------------------------------------------
#--------------NDVI covariate models----------------------------------------------------
stime1 <- system.time({
    CO_ndvi_lrns <- multiLearner.preprocess(task = CO_ndvi_var)
})[3]
stime1

## Choose the resampling strategy
rdesc.10fcv = makeResampleDesc(method = "CV", iters = 10, stratify = TRUE)
m = list(acc, kappa, mmce, timetrain)

# # Apply resampling function
stime2 <- system.time({
    CO_ndvi_resample <- resample.multi.learner(CO_ndvi_lrns, CO_ndvi_var, 
        rdesc.10fcv, m)
})[3]
stime2
save(CO_ndvi_resample, "/data/data2/data/esgMapping/R/CO_ndvi_resample.RData")

#---------------------------------------------------------------------------------------

CO_ndvi.svm.pred = getRRPredictions(CO_ndvi_resample[[1]])
CO_ndvi.svm.cm <- calculateConfusionMatrix(CO_ndvi.svm.pred, relative = TRUE)
CO_ndvi.rf.pred = getRRPredictions(CO_ndvi_resample[[2]])
CO_ndvi.rf.cm <- calculateConfusionMatrix(CO_ndvi.rf.pred, relative = TRUE)
CO_ndvi.xgb.pred = getRRPredictions(CO_ndvi_resample[[3]])
CO_ndvi.xgb.cm <- calculateConfusionMatrix(CO_ndvi.xgb.pred, relative = TRUE)
CO_ndvi.ens.pred = getRRPredictions(CO_ndvi_resample[[4]])
CO_ndvi.ens.cm <- calculateConfusionMatrix(CO_ndvi.ens.pred, relative = TRUE)

save(CO_ndvi_resample, CO_ndvi_lrns, file = "/data/data2/data/esgMapping/R/CO_ndvi_resample.RData")
rm(CO_ndvi_resample)

#----------------------------------------------------------------------------------------
#--------------Abiotic models-----------------------------------------------------------
stime1 <- system.time({
    CO_abiotic_lrns <- multiLearner.preprocess(task = CO_abiotic_var)
})[3]
stime1

## Choose the resampling strategy
rdesc.10fcv = makeResampleDesc(method = "CV", iters = 10, stratify = TRUE)
m = list(acc, kappa, mmce, timetrain)

# Apply resampling function
stime2 <- system.time({
    CO_abiotic_resample <- resample.multi.learner(CO_abiotic_lrns, CO_abiotic_var, 
        rdesc.10fcv, m)
})[3]
stime2
save(CO_abiotic_resample, "/data/data2/data/esgMapping/R/CO_abiotic_resample.RData")

#----------------------------------------------------------------------------------------

CO_abiotic.svm.pred = getRRPredictions(CO_abiotic_resample[[1]])
CO_abiotic.svm.cm <- calculateConfusionMatrix(CO_abiotic.svm.pred, relative = TRUE)
CO_abiotic.rf.pred = getRRPredictions(CO_abiotic_resample[[2]])
CO_abiotic.rf.cm <- calculateConfusionMatrix(CO_abiotic.rf.pred, relative = TRUE)
CO_abiotic.xgb.pred = getRRPredictions(CO_abiotic_resample[[3]])
CO_abiotic.xgb.cm <- calculateConfusionMatrix(CO_abiotic.xgb.pred, relative = TRUE)
CO_abiotic.ens.pred = getRRPredictions(CO_abiotic_resample[[4]])
CO_abiotic.ens.cm <- calculateConfusionMatrix(CO_abiotic.ens.pred, relative = TRUE)

save(CO_abiotic_resample, CO_abiotic_lrns, file = "/data/data2/data/esgMapping/R/CO_abiotic_resample.RData")
rm(CO_abiotic_resample)

#----------------------------------------------------------------------------------------
#--------------SG covariate models------------------------------------------------------
stime1 <- system.time({
    CO_sg_lrns <- multiLearner.preprocess(task = CO_sg_var)
})[3]
stime1

## Choose the resampling strategy
rdesc.10fcv = makeResampleDesc(method = "CV", iters = 10, stratify = TRUE)
m = list(acc, kappa, mmce, timetrain)

# Apply resampling function
stime2 <- system.time({
    CO_sg_resample <- resample.multi.learner(CO_sg_lrns, CO_sg_var, rdesc.10fcv, 
        m)
})[3]
stime2
save(CO_sg_resample, "/data/data2/data/esgMapping/R/CO_sg_resample.RData")

#----------------------------------------------------------------------------------------

CO_sg.svm.pred = getRRPredictions(CO_sg_resample[[1]])
CO_sg.svm.cm <- calculateConfusionMatrix(CO_sg.svm.pred, relative = TRUE)
CO_sg.rf.pred = getRRPredictions(CO_sg_resample[[2]])
CO_sg.rf.cm <- calculateConfusionMatrix(CO_sg.rf.pred, relative = TRUE)
CO_sg.xgb.pred = getRRPredictions(CO_sg_resample[[3]])
CO_sg.xgb.cm <- calculateConfusionMatrix(CO_sg.xgb.pred, relative = TRUE)
CO_sg.ens.pred = getRRPredictions(CO_sg_resample[[4]])
CO_sg.ens.cm <- calculateConfusionMatrix(CO_sg.ens.pred, relative = TRUE)

save(CO_sg_resample, CO_sg_lrns, file = "/data/data2/data/esgMapping/R/CO_sg_resample.RData")
rm(CO_sg_resample)

#----------------------------------------------------------------------------------------
#--------------DSM covariate models-----------------------------------------------------
stime1 <- system.time({
    CO_dsm_lrns <- multiLearner.preprocess(task = CO_dsm_var)
})[3]
stime1

## Choose the resampling strategy
rdesc.10fcv = makeResampleDesc(method = "CV", iters = 10, stratify = TRUE)
m = list(acc, kappa, mmce, timetrain)

# Apply resampling function
stime2 <- system.time({
    CO_dsm_resample <- resample.multi.learner(CO_dsm_lrns, CO_dsm_var, 
        rdesc.10fcv, m)
})[3]
stime2
save(CO_dsm_resample, "/data/data2/data/esgMapping/R/CO_dsm_resample.RData")

stime2 <- system.time({
    CO_dsm_resample_prob <- resample.multi.learner(CO_dsm_lrns.prob, CO_dsm_var, 
        rdesc.10fcv, m)
})[3]
stime2

CO_dsm_svm_acc <- classwise_accuracy_stats(CO_dsm_resample_prob[[1]])
CO_dsm_rf_acc <- classwise_accuracy_stats(CO_dsm_resample_prob[[2]])
CO_dsm_xgb_acc <- classwise_accuracy_stats(CO_dsm_resample_prob[[3]])
CO_dsm_ens_acc <- classwise_accuracy_stats(CO_dsm_resample_prob[[4]])
#----------------------------------------------------------------------------------------

CO_dsm.svm.pred = getRRPredictions(CO_dsm_resample[[1]])
CO_dsm.svm.cm <- calculateConfusionMatrix(CO_dsm.svm.pred, relative = TRUE)
CO_dsm.rf.pred = getRRPredictions(CO_dsm_resample[[2]])
CO_dsm.rf.cm <- calculateConfusionMatrix(CO_dsm.rf.pred, relative = TRUE)
CO_dsm.xgb.pred = getRRPredictions(CO_dsm_resample[[3]])
CO_dsm.xgb.cm <- calculateConfusionMatrix(CO_dsm.xgb.pred, relative = TRUE)
CO_dsm.ens.pred = getRRPredictions(CO_dsm_resample[[4]])
CO_dsm.ens.cm <- calculateConfusionMatrix(CO_dsm.ens.pred, relative = TRUE)

save(CO_dsm_resample, CO_dsm_lrns, file = "/data/data2/data/esgMapping/R/CO_dsm_resample.RData")
rm(CO_dsm_resample)

# Calculate qunatity and allocation dissagreement
CO_dsm_ens.kstat <- kstat(CO_dsm.ens.pred$data$response, CO_dsm.ens.pred$data$truth)

#-----------------------------------------------------------------------------------------------
# Calculate multiclass Precision-Recall AUC with boostrapped 95% CI
model = CO_dsm_resample_prob[[4]]

n.l <- plyr::count(model$pred$data$truth)
n.l <- data.frame(matrix(n.l$freq, nrow = 1, dimnames = list(1, paste(n.l$x))))
probs <- model$pred$data[, 3:10]
names <- colnames(n.l)
names(probs) = names
obs <- data.frame(lapply(names, FUN = function(i) {
    ifelse(model$pred$data$truth == i, 1, 0)
}))
names(obs) = names
obs.pred <- bind_cols(obs, probs)
colnames(obs.pred) <- c("G1_true", "G2_true", "G3_true", "G4_true", "G5_true", 
    "G6_true", "G7_true", "G8_true", "G1_pred_m1", "G2_pred_m1", "G3_pred_m1", 
    "G4_pred_m1", "G5_pred_m1", "G6_pred_m1", "G7_pred_m1", "G8_pred_m1")

# Generate ROC and PR curve data
roc_res <- multi_roc(obs.pred, force_diag = T)
pr_res <- multi_pr(obs.pred, force_diag = T)

# Plot PR curves
plot_pr_df <- plot_pr_data(pr_res)
ggplot(plot_pr_df, aes(x = Recall, y = Precision)) + geom_path(aes(color = Group, 
    linetype = Method), size = 1.5) + theme_bw() + theme(plot.title = element_text(hjust = 0.5), 
    legend.justification = c(1, 0), legend.position = c(0.95, 0.05), legend.title = element_blank(), 
    legend.background = element_rect(fill = NULL, size = 0.5, linetype = "solid", 
        colour = "black"))

# Calculate PR data with confidence intervals
CO_dsm_pr_auc_ci <- pr_auc_with_ci(obs.pred, conf = 0.95, type = "basic", 
    R = 100)

#-----------------------------------------------------------------------------------------------
multiclass.AUNU.class = function(probabilities, truth) {
    if (length(unique(truth)) != nlevels(truth)) {
        warning("Measure is undefined if there isn't at least one sample per class.")
        return(NA_real_)
    }
    BBmisc::vnapply(1:nlevels(truth), function(i) caTools::colAUC(probabilities[, 
        i], truth == levels(truth)[i]))
}
#-----------------------------------------------------------------------------------------------
TPR.multiclass = function(truth, response) {
    if (length(unique(truth)) != nlevels(truth)) {
        warning("Measure is undefined if there isn't at least one sample per class.")
        return(NA_real_)
    }
    signif(BBmisc::vnapply(1:nlevels(truth), function(i) sum(truth == response & 
        response == levels(truth)[i])/sum(truth == levels(truth)[i])), 
        2)
}
#-----------------------------------------------------------------------------------------------
PPV.multiclass = function(truth, response) {
    signif(BBmisc::vnapply(1:nlevels(truth), function(i) measures::TP(truth, 
        response, levels(truth)[i])/sum(response == levels(truth)[i])), 
        2)
}

#-----------------------------------------------------------------------------------------------

CO_dsm.ens.pred.prob <- CO_dsm.ens.pred$data[, 3:10] %>% set_names("ES1", 
    "ES2", "ES3", "ES4", "ES5", "ES6", "ES7", "ES99")

MMCE(CO_dsm.ens.pred$data$truth, CO_dsm.ens.pred$data$response)
ACC(CO_dsm.ens.pred$data$truth, CO_dsm.ens.pred$data$response)
BER(CO_dsm.ens.pred$data$truth, CO_dsm.ens.pred$data$response)
KAPPA(CO_dsm.ens.pred$data$truth, CO_dsm.ens.pred$data$response)
WKAPPA(CO_dsm.ens.pred$data$truth, CO_dsm.ens.pred$data$response)
TPR(CO_dsm.ens.pred$data$truth, CO_dsm.ens.pred$data$response)

CO_dsm.ens.tpr <- TPR.multiclass(CO_dsm.ens.pred$data$truth, CO_dsm.ens.pred$data$response)
CO_dsm.ens.ppv <- PPV.multiclass(CO_dsm.ens.pred$data$truth, CO_dsm.ens.pred$data$response)
CO_dsm.ens.aunu <- multiclass.AUNU.class(CO_dsm.ens.pred$data[, 3:10], 
    CO_dsm.ens.pred$data$truth)
CO_dsm.ens.logloss <- Logloss(CO_dsm.ens.pred.prob, CO_dsm.ens.pred$data$truth)
#----------------------------------------------------------------------------------------

#--------------------------------------------------------------------------------------------
load("/data/data2/data/esgMapping/R/CO_all_resample.RData")
co.all.resamp.metrics <- cbind(rep("All", 4), c("SVM", "RF", "XGB", "ENS"), 
    data.frame(rbind(CO_all_resample[[1]]$aggr, CO_all_resample[[2]]$aggr, 
        CO_all_resample[[3]]$aggr, CO_all_resample[[4]]$aggr)))
colnames(co.all.resamp.metrics)[1] <- "Data"
colnames(co.all.resamp.metrics)[2] <- "Model"
rm(CO_all_resample)
load("/data/data2/data/esgMapping/R/CO_hyper_resample.RData")
co.hyper.resamp.metrics <- cbind(rep("Hyper", 4), c("SVM", "RF", "XGB", 
    "ENS"), data.frame(rbind(CO_hyper_resample[[1]]$aggr, CO_hyper_resample[[2]]$aggr, 
    CO_hyper_resample[[3]]$aggr, CO_hyper_resample[[4]]$aggr)))
colnames(co.hyper.resamp.metrics)[1] <- "Data"
colnames(co.hyper.resamp.metrics)[2] <- "Model"
rm(CO_hyper_resample)
load("/data/data2/data/esgMapping/R/CO_ndvi_resample.RData")
co.ndvi.resamp.metrics <- cbind(rep("NDVI", 4), c("SVM", "RF", "XGB", "ENS"), 
    data.frame(rbind(CO_ndvi_resample[[1]]$aggr, CO_ndvi_resample[[2]]$aggr, 
        CO_ndvi_resample[[3]]$aggr, CO_ndvi_resample[[4]]$aggr)))
colnames(co.ndvi.resamp.metrics)[1] <- "Data"
colnames(co.ndvi.resamp.metrics)[2] <- "Model"
rm(CO_ndvi_resample)
load("/data/data2/data/esgMapping/R/CO_abiotic_resample.RData")
co.Abiotic.resamp.metrics <- cbind(rep("Abiotic", 4), c("SVM", "RF", "XGB", 
    "ENS"), data.frame(rbind(CO_abiotic_resample[[1]]$aggr, CO_abiotic_resample[[2]]$aggr, 
    CO_abiotic_resample[[3]]$aggr, CO_abiotic_resample[[4]]$aggr)))
colnames(co.Abiotic.resamp.metrics)[1] <- "Data"
colnames(co.Abiotic.resamp.metrics)[2] <- "Model"
rm(CO_abiotic_resample)
load("/data/data2/data/esgMapping/R/CO_sg_resample.RData")
co.sg.resamp.metrics <- cbind(rep("SG", 4), c("SVM", "RF", "XGB", "ENS"), 
    data.frame(rbind(CO_sg_resample[[1]]$aggr, CO_sg_resample[[2]]$aggr, 
        CO_sg_resample[[3]]$aggr, CO_sg_resample[[4]]$aggr)))
colnames(co.sg.resamp.metrics)[1] <- "Data"
colnames(co.sg.resamp.metrics)[2] <- "Model"
rm(CO_sg_resample)
load("/data/data2/data/esgMapping/R/CO_dsm_resample.RData")
co.dsm.resamp.metrics <- cbind(rep("DSM", 4), c("SVM", "RF", "XGB", "ENS"), 
    data.frame(rbind(CO_dsm_resample[[1]]$aggr, CO_dsm_resample[[2]]$aggr, 
        CO_dsm_resample[[3]]$aggr, CO_dsm_resample[[4]]$aggr)))
colnames(co.dsm.resamp.metrics)[1] <- "Data"
colnames(co.dsm.resamp.metrics)[2] <- "Model"
rm(CO_dsm_resample)

# Combine resample results
co.resamp.metrics <- rbind(co.all.resamp.metrics, co.hyper.resamp.metrics, 
    co.ndvi.resamp.metrics, co.Abiotic.resamp.metrics, co.sg.resamp.metrics, 
    co.dsm.resamp.metrics)


theme_set(theme_classic())

# Plot
ggplot(co.resamp.metrics, aes(x = Data, y = acc.test.mean)) + geom_jitter(aes(colour = factor(Model)), 
    size = 4, width = 0.2, height = 0) + # geom_point(col='tomato2', size=3) + # Draw points
geom_segment(aes(x = Data, xend = Data, y = 0.63, yend = 0.8), linetype = "dashed", 
    size = 0.1) + # coord_flip() + # Draw dashed lines
ylab("Accuracy") + xlab("Dataset") + # coord_flip() + # Draw dashed lines
labs(title = "MLRA 35 ESG Model Accuracy", color = "Model")
ggsave("/data/data2/data/esgMapping/analysis/figures/CO_model_comparison5.pdf", 
    width = 4.3, height = 2.6)


# Calculate individual class accuracies
CO_classwise_model <- bind_rows(CO_all.svm.cm$relative.row[, 9], CO_all.rf.cm$relative.row[, 
    9], CO_all.xgb.cm$relative.row[, 9], CO_all.ens.cm$relative.row[, 9], 
    CO_hyper.svm.cm$relative.row[, 9], CO_hyper.rf.cm$relative.row[, 9], 
    CO_hyper.xgb.cm$relative.row[, 9], CO_hyper.ens.cm$relative.row[, 9], 
    CO_ndvi.svm.cm$relative.row[, 9], CO_ndvi.rf.cm$relative.row[, 9], 
    CO_ndvi.xgb.cm$relative.row[, 9], CO_ndvi.ens.cm$relative.row[, 9], 
    CO_abiotic.svm.cm$relative.row[, 9], CO_abiotic.rf.cm$relative.row[, 
        9], CO_abiotic.xgb.cm$relative.row[, 9], CO_abiotic.ens.cm$relative.row[, 
        9], CO_sg.svm.cm$relative.row[, 9], CO_sg.rf.cm$relative.row[, 
        9], CO_sg.xgb.cm$relative.row[, 9], CO_sg.ens.cm$relative.row[, 
        9], CO_dsm.svm.cm$relative.row[, 9], CO_dsm.rf.cm$relative.row[, 
        9], CO_dsm.xgb.cm$relative.row[, 9], CO_dsm.ens.cm$relative.row[, 
        9])
CO_classwise_model - 1
CO.class.accuracy <- data.frame(c(rep("All", 4), rep("Hyper", 4), rep("NDVI", 
    4), rep("Abiotic", 4), rep("SG", 4), rep("DSM", 4)), c(rep(c("SVM", 
    "RF", "XGB", "ENS"), 6))) %>% set_names("Data", "Model") %>% bind_cols(., 
    (1 - CO_classwise_model))

CO.class.accuracy$Data <- factor(CO.class.accuracy$Data, levels = c("All", 
    "Hyper", "NDVI", "Abiotic", "SG", "DSM"))

ESG.class.plot <- function(data, class, title, filename, scale) {
    ggplot(data, aes(x = data[, 1], y = data[, class])) + geom_jitter(aes(colour = factor(Model)), 
        size = 4, width = 0.2, height = 0) + ylab("Accuracy") + xlab("Dataset") + 
        # coord_flip() + # Draw dashed lines
    labs(title = title, color = "Model")
    ggsave(paste0("/data/data2/data/esgMapping/analysis/figures/", filename, 
        "_class_comparison.pdf"), scale = scale)
}

ESG.class.plot(data = CO.class.accuracy, class = 3, title = "MLRA 35 ESG Class 1", 
    filename = "CO_ESG1", scale = 1)
ESG.class.plot(data = CO.class.accuracy, class = 3, title = "MLRA 35 ESG Class 1", 
    filename = "CO_ESG1", scale = 0.6)
ESG.class.plot(data = CO.class.accuracy, class = 4, title = "MLRA 35 ESG Class 2", 
    filename = "CO_ESG2", scale = 0.6)
ESG.class.plot(data = CO.class.accuracy, class = 5, title = "MLRA 35 ESG Class 3", 
    filename = "CO_ESG3", scale = 0.6)
ESG.class.plot(data = CO.class.accuracy, class = 6, title = "MLRA 35 ESG Class 4", 
    filename = "CO_ESG4", scale = 0.6)
ESG.class.plot(data = CO.class.accuracy, class = 7, title = "MLRA 35 ESG Class 5", 
    filename = "CO_ESG5", scale = 0.6)
ESG.class.plot(data = CO.class.accuracy, class = 8, title = "MLRA 35 ESG Class 6", 
    filename = "CO_ESG6", scale = 0.6)
ESG.class.plot(data = CO.class.accuracy, class = 9, title = "MLRA 35 ESG Class 7", 
    filename = "CO_ESG7", scale = 0.6)
ESG.class.plot(data = CO.class.accuracy, class = 10, title = "MLRA 35 ESG Class 8", 
    filename = "CO_ESG8", scale = 0.6)

# Evaluate ESD misclassification contribution to ESG class accuracy
CO_dsm_pred_ens <- CO_dsm_resample_prob[[4]]$pred$data
co.esname <- co.points@data[co.points.covariates$Index, c(1, 8, 12)] %>% 
    set_names(c("id", "esdname", "ESG_ID")) %>% mutate(id = seq(1, length(id), 
    1))
co.esname$id <- as.integer(co.esname$id)


CO_dsm_pred_ens.all <- CO_dsm_pred_ens %>% select(c(id, truth, response)) %>% 
    left_join(., co.esname, by = "id")
CO_dsm_pred_ens.misclass <- CO_dsm_pred_ens %>% filter(truth != response) %>% 
    select(c(id, truth, response))

# ES1
CO_dsm_pred_ens.misclass.es1 <- CO_dsm_pred_ens.misclass %>% filter(truth == 
    "ES1") %>% group_by(esdname) %>% summarise(no_rows = length(esdname))
View(CO_dsm_pred_ens.misclass.es1)

# ES2
#----------------------------------------------------------------------------------------  
# Evaluate ES2 misclassification ESD class
CO_dsm_pred_ens.all.es2 <- CO_dsm_pred_ens.all %>% filter(truth == "ES2") %>% 
    group_by(response) %>% summarise(no_rows = length(response))
# View(CO_dsm_pred_ens.all.es2)

CO_dsm_pred_ens.misclass.es2 <- CO_dsm_pred_ens.misclass %>% filter(truth == 
    "ES2") %>% group_by(esdname) %>% summarise(no_rows = length(esdname))
# View(CO_dsm_pred_ens.misclass.es2)

# combine number of all ESD classes and misclasses
CO_dsm_pred_ens.mis.es2 <- CO_dsm_pred_ens.all.es2 %>% left_join(CO_dsm_pred_ens.misclass.es2, 
    by = "esdname")
CO_dsm_pred_ens.mis.es2$misclassRate <- CO_dsm_pred_ens.mis.es2$no_rows.y/CO_dsm_pred_ens.mis.es2$no_rows.x

ES_misClass <- data.frame(paste0("ES", seq(1:8))) %>% set_names("ESD")
for (i in 1L:length(CO_dsm_pred_ens.mis.es2$esdname)) {
    esd_dist <- CO_dsm_pred_ens.all %>% filter(truth == "ES2") %>% filter(str_detect(esdname, 
        gsub("([.|()\\^{}+$*?]|\\[|\\])", "\\\\\\1", as.character(CO_dsm_pred_ens.mis.es2$esdname[i])))) %>% 
        group_by(response) %>% summarise(no_rows = length(response))
    esd_dist <- esd_dist %>% set_names("ESD", "num")
    ES_misClass <- left_join(ES_misClass, esd_dist, by = "ESD")
}
ES2_misClass <- ES_misClass %>% set_names(c("ESD", as.character(CO_dsm_pred_ens.mis.es2$esdname)))
ES2_misClass <- ES2_misClass %>% gather(key = "ESD")
ES2_misClass <- bind_cols(ES2_misClass, data.frame(rep(paste0("ES", c(1, 
    0, 3, 4, 5, 6, 7, 8)), length(unique(CO_dsm_pred_ens.mis.es2$esdname)))) %>% 
    set_names("ESG"))
ES2_misClass <- ES2_misClass %>% group_by(ESD) %>% arrange(ESG, .by_group = TRUE)

ES2.DF <- ES2_misClass %>% group_by(ESD) %>% mutate(ValuePer = (value/sum(value, 
    na.rm = TRUE))) %>% arrange(ESG, .by_group = TRUE) %>% ungroup()
# cbPalette <- c( '#ffa77f', '#00a884', '#beffe7', '#ffffbf',
# '#737301', '#fe0000', '#0071fe', '#732500')
ggplot(ES2.DF, aes(ESD, ValuePer, fill = ESG)) + geom_bar(stat = "identity", 
    position = position_fill(reverse = TRUE)) + geom_text(aes(label = percent(ValuePer)), 
    position = position_stack(reverse = TRUE)) + scale_y_continuous(labels = percent_format())
ggsave("/data/data2/data/esgMapping/analysis/figures/NM_ES2_ESD_misclass.pdf")


#----------------------------------------------------------------------------------------
# ES3 ESG class
CO_dsm_pred_ens.all.r.es3 <- CO_dsm_pred_ens.all %>% filter(truth == "ES3") %>% 
    group_by(response) %>% summarise(no_rows = length(response))
View(CO_dsm_pred_ens.all.r.es3)

CO_dsm_pred_ens.misclass.r.es3 <- CO_dsm_pred_ens.misclass %>% filter(truth == 
    "ES3") %>% group_by(response) %>% summarise(no_rows = length(response))
View(CO_dsm_pred_ens.misclass.r.es3)

#----------------------------------------------------------------------------------------  
# Evaluate ES3 misclassification ESD class
CO_dsm_pred_ens.all.es3 <- CO_dsm_pred_ens.all %>% filter(truth == "ES3") %>% 
    group_by(esdname) %>% summarise(no_rows = length(esdname))
View(CO_dsm_pred_ens.all.es3)

CO_dsm_pred_ens.misclass.es3 <- CO_dsm_pred_ens.misclass %>% filter(truth == 
    "ES3") %>% group_by(esdname) %>% summarise(no_rows = length(esdname))
View(CO_dsm_pred_ens.misclass.es3)

# combine number of all ESD classes and misclasses
CO_dsm_pred_ens.mis.es3 <- CO_dsm_pred_ens.all.es3 %>% left_join(CO_dsm_pred_ens.misclass.es3, 
    by = "esdname")
CO_dsm_pred_ens.mis.es3$misclassRate <- CO_dsm_pred_ens.mis.es3$no_rows.y/CO_dsm_pred_ens.mis.es3$no_rows.x
CO_dsm_pred_ens.mis.es3$esdname[1]


ES_misClass <- data.frame(paste0("ES", seq(1:8))) %>% set_names("ESD")
for (i in 1L:length(CO_dsm_pred_ens.mis.es3$esdname)) {
    esd_dist <- CO_dsm_pred_ens.all %>% filter(truth == "ES3") %>% filter(str_detect(esdname, 
        gsub("([.|()\\^{}+$*?]|\\[|\\])", "\\\\\\1", as.character(CO_dsm_pred_ens.mis.es3$esdname[i])))) %>% 
        group_by(response) %>% summarise(no_rows = length(response))
    esd_dist <- esd_dist %>% set_names("ESD", "num")
    ES_misClass <- left_join(ES_misClass, esd_dist, by = "ESD")
}
ES3_misClass <- ES_misClass %>% set_names(c("ESD", as.character(CO_dsm_pred_ens.mis.es3$esdname)))
ES3_misClass <- ES3_misClass %>% gather(key = "ESD")
ES3_misClass <- bind_cols(ES3_misClass, data.frame(rep(paste0("ES", c(1, 
    2, 0, 4, 5, 6, 7, 8)), length(unique(CO_dsm_pred_ens.mis.es3$esdname)))) %>% 
    set_names("ESG"))
ES3_misClass <- ES3_misClass %>% group_by(ESD) %>% arrange(ESG, .by_group = TRUE)

ES3.DF <- ES3_misClass %>% group_by(ESD) %>% mutate(ValuePer = (value/sum(value, 
    na.rm = TRUE))) %>% arrange(ESG, .by_group = TRUE) %>% ungroup()
# cbPalette <- c( '#ffa77f', '#00a884', '#beffe7', '#ffffbf',
# '#737301', '#fe0000', '#0071fe', '#732500')
ggplot(ES3.DF, aes(ESD, ValuePer, fill = ESG)) + geom_bar(stat = "identity", 
    position = position_fill(reverse = TRUE)) + geom_text(aes(label = percent(ValuePer)), 
    position = position_stack(reverse = TRUE)) + scale_y_continuous(labels = percent_format())
ggsave("/data/data2/data/esgMapping/analysis/figures/NM_ES3_ESD_misclass.pdf")

#----------------------------------------------------------------------------------------
# Look into individual ESD Classes and which ESG they are being
# misclassified as For ESG3, there are two ESDs that contribute to
# misclassification: 1) Semidesert Shallow Sandy Loam (Utah Juniper,
# Blackbrush), 2) Desert Shallow Sandy Loam (Blackbrush)

# The SSSL as a lower rate of misclassification but has much higher
# number of observations and misclassifications
CO_dsm_pred_ens.SSSL.es3 <- CO_dsm_pred_ens.all %>% filter(truth == "ES3") %>% 
    filter(str_detect(esdname, "Semidesert Shallow Sandy Loam")) %>% group_by(response) %>% 
    summarise(no_rows = length(response))
View(CO_dsm_pred_ens.SSSL.es3)

# The DSSL has a higher misclassification rate but fewer total number
# of misclassications
CO_dsm_pred_ens.DSSL.es3 <- CO_dsm_pred_ens.all %>% filter(truth == "ES3") %>% 
    filter(str_detect(esdname, "Desert Shallow Sandy Loam")) %>% group_by(response) %>% 
    summarise(no_rows = length(response))
View(CO_dsm_pred_ens.DSSL.es3)
#----------------------------------------------------------------------------------------
# ES4 ES4 ESG class
CO_dsm_pred_ens.all.r.es4 <- CO_dsm_pred_ens.all %>% filter(truth == "ES4") %>% 
    group_by(response) %>% summarise(no_rows = length(response))
View(CO_dsm_pred_ens.all.r.es4)

CO_dsm_pred_ens.misclass.r.es4 <- CO_dsm_pred_ens.misclass %>% filter(truth == 
    "ES4") %>% group_by(response) %>% summarise(no_rows = length(response))
View(CO_dsm_pred_ens.misclass.r.es4)

#---------------------------------------------------------------------------------------- 
# Evaluate ES4 misclassification ESD class
CO_dsm_pred_ens.all.es4 <- CO_dsm_pred_ens.all %>% filter(truth == "ES4") %>% 
    group_by(esdname) %>% summarise(no_rows = length(esdname))
View(CO_dsm_pred_ens.all.es4)

CO_dsm_pred_ens.misclass.es4 <- CO_dsm_pred_ens.misclass %>% filter(truth == 
    "ES4") %>% group_by(esdname) %>% summarise(no_rows = length(esdname))
View(CO_dsm_pred_ens.misclass.es4)

# combine number of all ESD classes and misclasses
CO_dsm_pred_ens.mis.es4 <- CO_dsm_pred_ens.all.es4 %>% left_join(CO_dsm_pred_ens.misclass.es4, 
    by = "esdname")
CO_dsm_pred_ens.mis.es4$misclassRate <- CO_dsm_pred_ens.mis.es4$no_rows.y/CO_dsm_pred_ens.mis.es4$no_rows.x
CO_dsm_pred_ens.mis.es4$esdname[1]


ES_misClass <- data.frame(paste0("ES", seq(1:8))) %>% set_names("ESD")
for (i in 1L:length(CO_dsm_pred_ens.mis.es4$esdname)) {
    esd_dist <- CO_dsm_pred_ens.all %>% filter(truth == "ES4") %>% filter(str_detect(esdname, 
        gsub("([.|()\\^{}+$*?]|\\[|\\])", "\\\\\\1", as.character(CO_dsm_pred_ens.mis.es4$esdname[i])))) %>% 
        group_by(response) %>% summarise(no_rows = length(response))
    esd_dist <- esd_dist %>% set_names("ESD", "num")
    ES_misClass <- left_join(ES_misClass, esd_dist, by = "ESD")
}
ES4_misClass <- ES_misClass %>% set_names(c("ESD", as.character(CO_dsm_pred_ens.mis.es4$esdname)))
ES4_misClass <- ES4_misClass %>% gather(key = "ESD")
ES4_misClass <- bind_cols(ES4_misClass, data.frame(rep(paste0("ES", c(1, 
    2, 3, 0, 5, 6, 7, 8)), length(unique(CO_dsm_pred_ens.mis.es4$esdname)))) %>% 
    set_names("ESG"))
ES4_misClass <- ES4_misClass %>% group_by(ESD) %>% arrange(ESG, .by_group = TRUE)

ES4.DF <- ES4_misClass %>% group_by(ESD) %>% mutate(ValuePer = (value/sum(value, 
    na.rm = TRUE))) %>% arrange(ESG, .by_group = TRUE) %>% ungroup()
# cbPalette <- c( '#ffa77f', '#00a884', '#beffe7', '#ffffbf',
# '#737301', '#fe0000', '#0071fe', '#732500')
ggplot(ES4.DF, aes(ESD, ValuePer, fill = ESG)) + geom_bar(stat = "identity", 
    position = position_fill(reverse = TRUE)) + geom_text(aes(label = percent(ValuePer)), 
    position = position_stack(reverse = TRUE)) + scale_y_continuous(labels = percent_format())
ggsave("/data/data2/data/esgMapping/analysis/figures/NM_ES4_ESD_misclass.pdf")

#----------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------
# ES5
#----------------------------------------------------------------------------------------
# ES6 ESG class
CO_dsm_pred_ens.all.r.es6 <- CO_dsm_pred_ens.all %>% filter(truth == "ES6") %>% 
    group_by(esdname) %>% summarise(no_rows = length(esdname))
View(CO_dsm_pred_ens.all.r.es6)

CO_dsm_pred_ens.misclass.r.es6 <- CO_dsm_pred_ens.misclass %>% filter(truth == 
    "ES6") %>% group_by(esdname) %>% summarise(no_rows = length(esdname))
View(CO_dsm_pred_ens.misclass.r.es6)

# combine number of all ESD classes and misclasses
CO_dsm_pred_ens.mis.es6 <- CO_dsm_pred_ens.all.es6 %>% left_join(CO_dsm_pred_ens.misclass.es6, 
    by = "esdname")
View(CO_dsm_pred_ens.mis.es6)
CO_dsm_pred_ens.mis.es6$no_rows.y/CO_dsm_pred_ens.mis.es6$no_rows.x

# Individual classes
CO_dsm_pred_ens.SSRP.es6 <- CO_dsm_pred_ens.all %>% filter(truth == "ES6") %>% 
    filter(str_detect(esdname, "Shallow Sand Rock Pocket")) %>% group_by(response) %>% 
    summarise(no_rows = length(response))
View(CO_dsm_pred_ens.SSRP.es6)

CO_dsm_pred_ens.SSSL.es6 <- CO_dsm_pred_ens.all %>% filter(truth == "ES6") %>% 
    filter(str_detect(esdname, "Semidesert Steep Shallow Loam")) %>% group_by(response) %>% 
    summarise(no_rows = length(response))
View(CO_dsm_pred_ens.SSSL.es6)

CO_dsm_pred_ens.SVSS.es6 <- CO_dsm_pred_ens.all %>% filter(truth == "ES6") %>% 
    filter(str_detect(esdname, "Semidesert Very Steep Stony Loam")) %>% 
    group_by(response) %>% summarise(no_rows = length(response))
View(CO_dsm_pred_ens.SVSS.es6)



# ESD class
CO_dsm_pred_ens.all.es6.resp <- CO_dsm_pred_ens.all %>% filter(truth == 
    "ES6") %>% group_by(response) %>% summarise(no_rows = length(response))
View(CO_dsm_pred_ens.all.es6.resp)

CO_dsm_pred_ens.misclass.es3.resp <- CO_dsm_pred_ens.misclass %>% filter(truth == 
    "ES6") %>% group_by(response) %>% summarise(no_rows = length(response))
View(CO_dsm_pred_ens.misclass.es3.resp)

```


## Chihuahuan Desert Models
```{r eval=FALSE}
# register parallel backend
parallelStartSocket(cpus = 24, show.info = TRUE)
# Create covariate datasets

#---------------NM All covariate dataframe and task
nm.esg.all.cov <- nm.points.covariates[, -1]

nm.esg.all.cov <- na.omit(nm.esg.all.cov)
nm.esg.all.cov.rm <- removeConstantFeatures(nm.esg.all.cov)
NM_all_var = makeClassifTask(id = "NM_ESG_all", data = nm.esg.all.cov.rm, 
    target = "esite")

#---------------NM Hyper-temp covariate dataframe and task
nm.esg.hyper.cov <- nm.points.covariates[, c("esite", hype.ndvi.names, 
    hype.swir2.names, hype.lst_day.names, hype.lst_night.names)]

nm.esg.hyper.cov <- na.omit(nm.esg.hyper.cov)
nm.esg.hyper.cov.rm <- removeConstantFeatures(nm.esg.hyper.cov)
NM_hyper_var = makeClassifTask(id = "NM_ESG_hyper", data = nm.esg.hyper.cov.rm, 
    target = "esite")

#---------------NM NDVI covariate dataframe and task
nm.esg.ndvi.cov <- nm.points.covariates[, c("esite", hype.ndvi.names)]

nm.esg.ndvi.cov <- na.omit(nm.esg.ndvi.cov)
nm.esg.ndvi.cov.rm <- removeConstantFeatures(nm.esg.ndvi.cov)
NM_ndvi_var = makeClassifTask(id = "NM_ESG_ndvi", data = nm.esg.ndvi.cov.rm, 
    target = "esite")

#---------------NM Abiotic covariate dataframe and task
nm.esg.abiotic.cov <- nm.points.covariates[, c("esite", terrain.nm.names, 
    lithology.nm.names, prec.nm.names, temp.nm.names, bio.nm.names, soil.thick.nm.names, 
    soilGrids.nm.names)]

nm.esg.abiotic.cov <- na.omit(nm.esg.abiotic.cov)
nm.esg.abiotic.cov.rm <- removeConstantFeatures(nm.esg.abiotic.cov)
NM_abiotic_var = makeClassifTask(id = "NM_ESG_abiotic", data = nm.esg.abiotic.cov.rm, 
    target = "esite")

#---------------NM SoilsGrid covariate dataframe and task
nm.esg.sg.cov <- nm.points.covariates[, c("esite", soilGrids.nm.names)]

nm.esg.sg.cov <- na.omit(nm.esg.sg.cov)
nm.esg.sg.cov.rm <- removeConstantFeatures(nm.esg.sg.cov)
NM_sg_var = makeClassifTask(id = "NM_ESG_sg", data = nm.esg.sg.cov.rm, 
    target = "esite")

#---------------NM DSM covariate dataframe and task
nm.esg.dsm.cov <- nm.points.covariates[, c("esite", terrain.nm.names, lithology.nm.names, 
    prec.nm.names, temp.nm.names, bio.nm.names, soil.thick.nm.names, soilGrids.nm.names, 
    ndvi.nm.names, mir.nm.names, lst.day.nm.names, lst.night.nm.names)]

nm.esg.dsm.cov <- na.omit(nm.esg.dsm.cov)
nm.esg.dsm.cov.rm <- removeConstantFeatures(nm.esg.dsm.cov)
NM_dsm_var = makeClassifTask(id = "NM_ESG_dsm", data = nm.esg.dsm.cov.rm, 
    target = "esite")


#--------------All covariate models-------------------------------------------------------------------------------
stime1 <- system.time({
    NM_all_lrns <- multiLearner.preprocess(task = NM_all_var)
})[3]
stime1

## Choose the resampling strategy
rdesc.10fcv = makeResampleDesc(method = "CV", iters = 10, stratify = TRUE)
m = list(acc, kappa, mmce, timetrain)

# Apply resampling function
stime2 <- system.time({
    NM_all_resample <- resample.multi.learner(NM_all_lrns, NM_all_var, 
        rdesc.10fcv, m)
})[3]
stime2


NM_all.svm.pred = getRRPredictions(NM_all_resample[[1]])
NM_all.svm.cm <- calculateConfusionMatrix(NM_all.svm.pred, relative = TRUE)
NM_all.rf.pred = getRRPredictions(NM_all_resample[[2]])
NM_all.rf.cm <- calculateConfusionMatrix(NM_all.rf.pred, relative = TRUE)
NM_all.xgb.pred = getRRPredictions(NM_all_resample[[3]])
NM_all.xgb.cm <- calculateConfusionMatrix(NM_all.xgb.pred, relative = TRUE)
NM_all.ens.pred = getRRPredictions(NM_all_resample[[4]])
NM_all.ens.cm <- calculateConfusionMatrix(NM_all.ens.pred, relative = TRUE)

save(NM_all_resample, NM_all_lrns, file = "/data/data2/data/esgMapping/R/NM_all_resample.RData")
rm(NM_all_resample)

#--------------Hyper covariate models-------------------------------------------------------------------------------
stime1 <- system.time({
    NM_hyper_lrns <- multiLearner.preprocess(task = NM_hyper_var)
})[3]
stime1

## Choose the resampling strategy
rdesc.10fcv = makeResampleDesc(method = "CV", iters = 10, stratify = TRUE)
m = list(acc, kappa, mmce, timetrain)

# Apply resampling function
stime2 <- system.time({
    NM_hyper_resample <- resample.multi.learner(NM_hyper_lrns, NM_hyper_var, 
        rdesc.10fcv, m)
})[3]
stime2

NM_hyper.svm.pred = getRRPredictions(NM_hyper_resample[[1]])
NM_hyper.svm.cm <- calculateConfusionMatrix(NM_hyper.svm.pred, relative = TRUE)
NM_hyper.rf.pred = getRRPredictions(NM_hyper_resample[[2]])
NM_hyper.rf.cm <- calculateConfusionMatrix(NM_hyper.rf.pred, relative = TRUE)
NM_hyper.xgb.pred = getRRPredictions(NM_hyper_resample[[3]])
NM_hyper.xgb.cm <- calculateConfusionMatrix(NM_hyper.xgb.pred, relative = TRUE)
NM_hyper.ens.pred = getRRPredictions(NM_hyper_resample[[4]])
NM_hyper.ens.cm <- calculateConfusionMatrix(NM_hyper.ens.pred, relative = TRUE)

save(NM_hyper_resample, NM_hyper_lrns, file = "/data/data2/data/esgMapping/R/NM_hyper_resample.RData")
rm(NM_hyper_resample)

#--------------NDVI covariate models-------------------------------------------------------------------------------
stime1 <- system.time({
    NM_ndvi_lrns <- multiLearner.preprocess(task = NM_ndvi_var)
})[3]
stime1

## Choose the resampling strategy
rdesc.10fcv = makeResampleDesc(method = "CV", iters = 10, stratify = TRUE)
m = list(acc, kappa, mmce, timetrain)

# Apply resampling function
stime2 <- system.time({
    NM_ndvi_resample <- resample.multi.learner(NM_ndvi_lrns, NM_ndvi_var, 
        rdesc.10fcv, m)
})[3]
stime2

NM_ndvi.svm.pred = getRRPredictions(NM_ndvi_resample[[1]])
NM_ndvi.svm.cm <- calculateConfusionMatrix(NM_ndvi.svm.pred, relative = TRUE)
NM_ndvi.rf.pred = getRRPredictions(NM_ndvi_resample[[2]])
NM_ndvi.rf.cm <- calculateConfusionMatrix(NM_ndvi.rf.pred, relative = TRUE)
NM_ndvi.xgb.pred = getRRPredictions(NM_ndvi_resample[[3]])
NM_ndvi.xgb.cm <- calculateConfusionMatrix(NM_ndvi.xgb.pred, relative = TRUE)
NM_ndvi.ens.pred = getRRPredictions(NM_ndvi_resample[[4]])
NM_ndvi.ens.cm <- calculateConfusionMatrix(NM_ndvi.ens.pred, relative = TRUE)

save(NM_ndvi_resample, NM_ndvi_lrns, file = "/data/data2/data/esgMapping/R/NM_ndvi_resample.RData")
rm(NM_ndvi_resample)

#--------------SG covariate models-------------------------------------------------------------------------------
stime1 <- system.time({
    NM_sg_lrns <- multiLearner.preprocess(task = NM_sg_var)
})[3]
stime1

## Choose the resampling strategy
rdesc.10fcv = makeResampleDesc(method = "CV", iters = 10, stratify = TRUE)
m = list(acc, kappa, mmce, timetrain)

# Apply resampling function
stime2 <- system.time({
    NM_sg_resample <- resample.multi.learner(NM_sg_lrns, NM_sg_var, rdesc.10fcv, 
        m)
})[3]
stime2

NM_sg.svm.pred = getRRPredictions(NM_sg_resample[[1]])
NM_sg.svm.cm <- calculateConfusionMatrix(NM_sg.svm.pred, relative = TRUE)
NM_sg.rf.pred = getRRPredictions(NM_sg_resample[[2]])
NM_sg.rf.cm <- calculateConfusionMatrix(NM_sg.rf.pred, relative = TRUE)
NM_sg.xgb.pred = getRRPredictions(NM_sg_resample[[3]])
NM_sg.xgb.cm <- calculateConfusionMatrix(NM_sg.xgb.pred, relative = TRUE)
NM_sg.ens.pred = getRRPredictions(NM_sg_resample[[4]])
NM_sg.ens.cm <- calculateConfusionMatrix(NM_sg.ens.pred, relative = TRUE)

save(NM_sg_resample, NM_sg_lrns, file = "/data/data2/data/esgMapping/R/NM_sg_resample.RData")
rm(NM_sg_resample)

#--------------Abiotic models-------------------------------------------------------------------------------
stime1 <- system.time({
    NM_abiotic_lrns <- multiLearner.preprocess(task = NM_abiotic_var)
})[3]
stime1

## Choose the resampling strategy
rdesc.10fcv = makeResampleDesc(method = "CV", iters = 10, stratify = TRUE)
m = list(acc, kappa, mmce, timetrain)

# Apply resampling function
stime2 <- system.time({
    NM_abiotic_resample <- resample.multi.learner(NM_abiotic_lrns, NM_abiotic_var, 
        rdesc.10fcv, m)
})[3]
stime2

NM_abiotic.svm.pred = getRRPredictions(NM_abiotic_resample[[1]])
NM_abiotic.svm.cm <- calculateConfusionMatrix(NM_abiotic.svm.pred, relative = TRUE)
NM_abiotic.rf.pred = getRRPredictions(NM_abiotic_resample[[2]])
NM_abiotic.rf.cm <- calculateConfusionMatrix(NM_abiotic.rf.pred, relative = TRUE)
NM_abiotic.xgb.pred = getRRPredictions(NM_abiotic_resample[[3]])
NM_abiotic.xgb.cm <- calculateConfusionMatrix(NM_abiotic.xgb.pred, relative = TRUE)
NM_abiotic.ens.pred = getRRPredictions(NM_abiotic_resample[[4]])
NM_abiotic.ens.cm <- calculateConfusionMatrix(NM_abiotic.ens.pred, relative = TRUE)

save(NM_abiotic_resample, NM_abiotic_lrns, file = "/data/data2/data/esgMapping/R/NM_abiotic_resample.RData")
rm(NM_abiotic_resample)

#--------------DSM covariate models-------------------------------------------------------------------------------
stime1 <- system.time({
    NM_dsm_lrns <- multiLearner.preprocess(task = NM_dsm_var)
})[3]
stime1

## Choose the resampling strategy
rdesc.10fcv = makeResampleDesc(method = "CV", iters = 10, stratify = TRUE)
m = list(acc, kappa, mmce, timetrain)

# Apply resampling function
stime2 <- system.time({
    NM_dsm_resample <- resample.multi.learner(NM_dsm_lrns, NM_dsm_var, 
        rdesc.10fcv, m)
})[3]
stime2

stime2 <- system.time({
    NM_dsm_resample_prob <- resample.multi.learner(NM_dsm_lrns.prob, NM_dsm_var, 
        rdesc.10fcv, m)
})[3]
stime2

NM_dsm.svm.pred = getRRPredictions(NM_dsm_resample[[1]])
NM_dsm.svm.cm <- calculateConfusionMatrix(NM_dsm.svm.pred, relative = TRUE)
NM_dsm.rf.pred = getRRPredictions(NM_dsm_resample[[2]])
NM_dsm.rf.cm <- calculateConfusionMatrix(NM_dsm.rf.pred, relative = TRUE)
NM_dsm.xgb.pred = getRRPredictions(NM_dsm_resample[[3]])
NM_dsm.xgb.cm <- calculateConfusionMatrix(NM_dsm.xgb.pred, relative = TRUE)
NM_dsm.ens.pred = getRRPredictions(NM_dsm_resample[[4]])
NM_dsm.ens.cm <- calculateConfusionMatrix(NM_dsm.ens.pred, relative = TRUE)

save(NM_dsm_resample, NM_dsm_lrns, file = "/data/data2/data/esgMapping/R/NM_dsm_resample.RData")
rm(NM_dsm_resample)

NM_dsm_svm_acc <- classwise_accuracy_stats(NM_dsm_resample_prob[[1]])
NM_dsm_rf_acc <- classwise_accuracy_stats(NM_dsm_resample_prob[[2]])
NM_dsm_xgb_acc <- classwise_accuracy_stats(NM_dsm_resample_prob[[3]])
NM_dsm_ens_acc <- classwise_accuracy_stats(NM_dsm_resample_prob[[4]])


NM_dsm_ens.kstat <- kstat(NM_dsm.ens.pred$data$response, NM_dsm.ens.pred$data$truth)

#-----------------------------------------------------------------------------------------------
# Calculate multiclass Precision-Recall AUC with boostrapped 95% CI
NM_dsm_ens = NM_dsm_resample_prob[[4]]

NM_dsm_ens_n.l <- plyr::count(NM_dsm_ens$pred$data$truth)
NM_dsm_ens_n.l <- data.frame(matrix(NM_dsm_ens_n.l$freq, nrow = 1, dimnames = list(1, 
    paste(NM_dsm_ens_n.l$x))))
NM_dsm_ens_probs <- NM_dsm_ens$pred$data[, 3:9]
NM_dsm_ens_names <- colnames(NM_dsm_ens_n.l)
names(NM_dsm_ens_probs) = NM_dsm_ens_names
NM_dsm_ens_obs <- data.frame(lapply(NM_dsm_ens_names, FUN = function(i) {
    ifelse(NM_dsm_ens$pred$data$truth == i, 1, 0)
}))
names(NM_dsm_ens_obs) = NM_dsm_ens_names
NM_dsm_ens_obs.pred <- bind_cols(NM_dsm_ens_obs, NM_dsm_ens_probs)
colnames(NM_dsm_ens_obs.pred) <- c("G1_true", "G2_true", "G3_true", "G4_true", 
    "G5_true", "G6_true", "G7_true", "G1_pred_m1", "G2_pred_m1", "G3_pred_m1", 
    "G4_pred_m1", "G5_pred_m1", "G6_pred_m1", "G7_pred_m1")

# Generate ROC and PR curve data
NM_dsm_ens_roc_res <- multi_roc(NM_dsm_ens_obs.pred, force_diag = T)
NM_dsm_ens_pr_res <- multi_pr(NM_dsm_ens_obs.pred, force_diag = T)

# Plot PR curves
NM_dsm_ens_plot_pr_df <- plot_pr_data(NM_dsm_ens_pr_res)
ggplot(NM_dsm_ens_plot_pr_df, aes(x = Recall, y = Precision)) + geom_path(aes(color = Group, 
    linetype = Method), size = 1.5) + theme_bw() + theme(plot.title = element_text(hjust = 0.5), 
    legend.justification = c(1, 0), legend.position = c(0.95, 0.05), legend.title = element_blank(), 
    legend.background = element_rect(fill = NULL, size = 0.5, linetype = "solid", 
        colour = "black"))

# Calculate PR data with confidence intervals
NM_dsm_pr_auc_ci <- pr_auc_with_ci(NM_dsm_ens_obs.pred, conf = 0.95, type = "basic", 
    R = 100)

#-----------------------------------------------------------------------------------------------

NM_dsm.ens.pred.prob <- NM_dsm.ens.pred$data[, 3:9] %>% set_names("ES1", 
    "ES2", "ES3", "ES4", "ES5", "ES6", "ES7")

MMCE(NM_dsm.ens.pred$data$truth, NM_dsm.ens.pred$data$response)
ACC(NM_dsm.ens.pred$data$truth, NM_dsm.ens.pred$data$response)
BER(NM_dsm.ens.pred$data$truth, NM_dsm.ens.pred$data$response)
KAPPA(NM_dsm.ens.pred$data$truth, NM_dsm.ens.pred$data$response)
WKAPPA(NM_dsm.ens.pred$data$truth, NM_dsm.ens.pred$data$response)


NM_dsm.ens.tpr <- TPR.multiclass(NM_dsm.ens.pred$data$truth, NM_dsm.ens.pred$data$response)
NM_dsm.ens.ppv <- PPV.multiclass(NM_dsm.ens.pred$data$truth, NM_dsm.ens.pred$data$response)
NM_dsm.ens.aunu <- multiclass.AUNU.class(NM_dsm.ens.pred.prob, NM_dsm.ens.pred$data$truth)
NM_dsm.ens.logloss <- Logloss(NM_dsm.ens.pred.prob, NM_dsm.ens.pred$data$truth)
#----------------------------------------------------------------------------------------
#------------------------------------------------------------------------------------------
load("/data/data2/data/esgMapping/R/NM_all_resample.RData")
nm.all.resamp.metrics <- cbind(rep("All", 4), c("SVM", "RF", "XGB", "ENS"), 
    data.frame(rbind(NM_all_resample[[1]]$aggr, NM_all_resample[[2]]$aggr, 
        NM_all_resample[[3]]$aggr, NM_all_resample[[4]]$aggr)))
colnames(nm.all.resamp.metrics)[1] <- "Data"
colnames(nm.all.resamp.metrics)[2] <- "Model"
rm(NM_all_resample)
load("/data/data2/data/esgMapping/R/NM_hyper_resample.RData")
nm.hyper.resamp.metrics <- cbind(rep("Hyper", 4), c("SVM", "RF", "XGB", 
    "ENS"), data.frame(rbind(NM_hyper_resample[[1]]$aggr, NM_hyper_resample[[2]]$aggr, 
    NM_hyper_resample[[3]]$aggr, NM_hyper_resample[[4]]$aggr)))
colnames(nm.hyper.resamp.metrics)[1] <- "Data"
colnames(nm.hyper.resamp.metrics)[2] <- "Model"
rm(NM_hyper_resample)
load("/data/data2/data/esgMapping/R/NM_ndvi_resample.RData")
nm.ndvi.resamp.metrics <- cbind(rep("NDVI", 4), c("SVM", "RF", "XGB", "ENS"), 
    data.frame(rbind(NM_ndvi_resample[[1]]$aggr, NM_ndvi_resample[[2]]$aggr, 
        NM_ndvi_resample[[3]]$aggr, NM_ndvi_resample[[4]]$aggr)))
colnames(nm.ndvi.resamp.metrics)[1] <- "Data"
colnames(nm.ndvi.resamp.metrics)[2] <- "Model"
rm(NM_ndvi_resample)
load("/data/data2/data/esgMapping/R/NM_abiotic_resample.RData")
nm.Abiotic.resamp.metrics <- cbind(rep("Abiotic", 4), c("SVM", "RF", "XGB", 
    "ENS"), data.frame(rbind(NM_abiotic_resample[[1]]$aggr, NM_abiotic_resample[[2]]$aggr, 
    NM_abiotic_resample[[3]]$aggr, NM_abiotic_resample[[4]]$aggr)))
colnames(nm.Abiotic.resamp.metrics)[1] <- "Data"
colnames(nm.Abiotic.resamp.metrics)[2] <- "Model"
rm(NM_abiotic_resample)
load("/data/data2/data/esgMapping/R/NM_sg_resample.RData")
nm.sg.resamp.metrics <- cbind(rep("SG", 4), c("SVM", "RF", "XGB", "ENS"), 
    data.frame(rbind(NM_sg_resample[[1]]$aggr, NM_sg_resample[[2]]$aggr, 
        NM_sg_resample[[3]]$aggr, NM_sg_resample[[4]]$aggr)))
colnames(nm.sg.resamp.metrics)[1] <- "Data"
colnames(nm.sg.resamp.metrics)[2] <- "Model"
rm(NM_sg_resample)
load("/data/data2/data/esgMapping/R/NM_dsm_resample.RData")
nm.dsm.resamp.metrics <- cbind(rep("DSM", 4), c("SVM", "RF", "XGB", "ENS"), 
    data.frame(rbind(NM_dsm_resample[[1]]$aggr, NM_dsm_resample[[2]]$aggr, 
        NM_dsm_resample[[3]]$aggr, NM_dsm_resample[[4]]$aggr)))
colnames(nm.dsm.resamp.metrics)[1] <- "Data"
colnames(nm.dsm.resamp.metrics)[2] <- "Model"
rm(NM_dsm_resample)

# Combine resample results
nm.resamp.metrics <- rbind(nm.all.resamp.metrics, nm.hyper.resamp.metrics, 
    nm.ndvi.resamp.metrics, nm.Abiotic.resamp.metrics, nm.sg.resamp.metrics, 
    nm.dsm.resamp.metrics)

theme_set(theme_classic())

# Plot
NM_model_comparison <- ggplot(nm.resamp.metrics, aes(x = Data, y = acc.test.mean)) + 
    geom_point(aes(colour = factor(Model)), size = 4) + # geom_point(col='tomato2', size=3) + # Draw points
geom_segment(aes(x = Data, xend = Data, y = min(acc.test.mean), yend = max(acc.test.mean)), 
    linetype = "dashed", size = 0.1) + # coord_flip() + # Draw dashed lines
labs(title = "Dot Plot", subtitle = "Data Type Vs ACC", caption = "source: NM")
ggsave("/data/data2/data/esgMapping/analysis/figures/NM_model_comparison2.pdf")

ggplot(nm.resamp.metrics, aes(x = Data, y = acc.test.mean)) + geom_jitter(aes(colour = factor(Model)), 
    size = 4, width = 0.2, height = 0) + geom_segment(aes(x = Data, xend = Data, 
    y = 0.63, yend = 0.8), linetype = "dashed", size = 0.1) + ylab("Accuracy") + 
    xlab("Dataset") + # coord_flip() + # Draw dashed lines
labs(title = "MLRA 42 ESG Model Accuracy", color = "Model")
ggsave("/data/data2/data/esgMapping/analysis/figures/NM_model_comparison5.pdf", 
    width = 4.3, height = 2.6)

# Calculate individual class accuracies
NM_classwise_model <- bind_rows(NM_all.svm.cm$relative.row[, 8], NM_all.rf.cm$relative.row[, 
    8], NM_all.xgb.cm$relative.row[, 8], NM_all.ens.cm$relative.row[, 8], 
    NM_hyper.svm.cm$relative.row[, 8], NM_hyper.rf.cm$relative.row[, 8], 
    NM_hyper.xgb.cm$relative.row[, 8], NM_hyper.ens.cm$relative.row[, 8], 
    NM_ndvi.svm.cm$relative.row[, 8], NM_ndvi.rf.cm$relative.row[, 8], 
    NM_ndvi.xgb.cm$relative.row[, 8], NM_ndvi.ens.cm$relative.row[, 8], 
    NM_abiotic.svm.cm$relative.row[, 8], NM_abiotic.rf.cm$relative.row[, 
        8], NM_abiotic.xgb.cm$relative.row[, 8], NM_abiotic.ens.cm$relative.row[, 
        8], NM_sg.svm.cm$relative.row[, 8], NM_sg.rf.cm$relative.row[, 
        8], NM_sg.xgb.cm$relative.row[, 8], NM_sg.ens.cm$relative.row[, 
        8], NM_dsm.svm.cm$relative.row[, 8], NM_dsm.rf.cm$relative.row[, 
        8], NM_dsm.xgb.cm$relative.row[, 8], NM_dsm.ens.cm$relative.row[, 
        8])
NM_classwise_model - 1
NM.class.accuracy <- data.frame(c(rep("All", 4), rep("Hyper", 4), rep("NDVI", 
    4), rep("Abiotic", 4), rep("SG", 4), rep("DSM", 4)), c(rep(c("SVM", 
    "RF", "XGB", "ENS"), 6))) %>% set_names("Data", "Model") %>% bind_cols(., 
    (1 - NM_classwise_model))

NM.class.accuracy$Data <- factor(NM.class.accuracy$Data, levels = c("All", 
    "Hyper", "NDVI", "Abiotic", "SG", "DSM"))

ESG.class.plot <- function(data, class, title, filename, scale) {
    ggplot(data, aes(x = data[, 1], y = data[, class])) + geom_point(aes(colour = factor(Model)), 
        size = 4) + ylab("Accuracy") + xlab("Dataset") + # coord_flip() + # Draw dashed lines
    labs(title = title, color = "Model")
    ggsave(paste0("/data/data2/data/esgMapping/analysis/figures/", filename, 
        "_class_comparison.pdf"), scale = scale)
}

ESG.class.plot(data = NM.class.accuracy, class = 3, title = "MLRA 42 ESG Class 1", 
    filename = "NM_ESG1", scale = 1)
ESG.class.plot(data = NM.class.accuracy, class = 3, title = "MLRA 42 ESG Class 1", 
    filename = "NM_ESG1", scale = 0.6)
ESG.class.plot(data = NM.class.accuracy, class = 4, title = "MLRA 42 ESG Class 2", 
    filename = "NM_ESG2", scale = 0.6)
ESG.class.plot(data = NM.class.accuracy, class = 5, title = "MLRA 42 ESG Class 3", 
    filename = "NM_ESG3", scale = 0.6)
ESG.class.plot(data = NM.class.accuracy, class = 6, title = "MLRA 42 ESG Class 4", 
    filename = "NM_ESG4", scale = 0.6)
ESG.class.plot(data = NM.class.accuracy, class = 7, title = "MLRA 42 ESG Class 5", 
    filename = "NM_ESG5", scale = 0.6)
ESG.class.plot(data = NM.class.accuracy, class = 8, title = "MLRA 42 ESG Class 6", 
    filename = "NM_ESG6", scale = 0.6)
ESG.class.plot(data = NM.class.accuracy, class = 9, title = "MLRA 42 ESG Class 7", 
    filename = "NM_ESG7", scale = 0.6)
#----------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------
NM_dsm_pred_ens <- NM_dsm_resample_prob[[4]]$pred$data
nm.esname <- nm.points@data[nm.points.covariates$Index, c(1, 8, 9, 16)] %>% 
    set_names(c("id", "es_id", "esdname", "ESG_ID")) %>% mutate(id = seq(1, 
    length(id), 1))
nm.esname$id <- as.integer(nm.esname$id)


NM_dsm_pred_ens.all <- NM_dsm_pred_ens %>% select(c(id, truth, response)) %>% 
    left_join(., nm.esname, by = "id")
NM_dsm_pred_ens.misclass <- NM_dsm_pred_ens %>% filter(truth != response) %>% 
    select(c(id, truth, response)) %>% left_join(., nm.esname, by = "id")



#----------------------------------------------------------------------------------------
# ES3 ESG class
NM_dsm_pred_ens.all.r.es3 <- NM_dsm_pred_ens.all %>% filter(truth == "ES3") %>% 
    group_by(response) %>% summarise(no_rows = length(response))
View(NM_dsm_pred_ens.all.r.es3)

NM_dsm_pred_ens.misclass.r.es3 <- NM_dsm_pred_ens.misclass %>% filter(truth == 
    "ES3") %>% group_by(response) %>% summarise(no_rows = length(response))
View(NM_dsm_pred_ens.misclass.r.es3)

#----------------------------------------------------------------------------------------  
# Evaluate ES3 misclassification ESD class
NM_dsm_pred_ens.all.es3 <- NM_dsm_pred_ens.all %>% filter(truth == "ES3") %>% 
    group_by(esdname) %>% summarise(no_rows = length(esdname))
View(NM_dsm_pred_ens.all.es3)

NM_dsm_pred_ens.misclass.es3 <- NM_dsm_pred_ens.misclass %>% filter(truth == 
    "ES3") %>% group_by(esdname) %>% summarise(no_rows = length(esdname))
View(NM_dsm_pred_ens.misclass.es3)

# combine number of all ESD classes and misclasses
NM_dsm_pred_ens.mis.es3 <- NM_dsm_pred_ens.all.es3 %>% left_join(NM_dsm_pred_ens.misclass.es3, 
    by = "esdname")
NM_dsm_pred_ens.mis.es3$misclassRate <- NM_dsm_pred_ens.mis.es3$no_rows.y/NM_dsm_pred_ens.mis.es3$no_rows.x
NM_dsm_pred_ens.mis.es3$esdname[1]


NM_ES_misClass <- data.frame(paste0("ES", seq(1:8))) %>% set_names("ESD")
for (i in 1L:length(NM_dsm_pred_ens.mis.es3$esdname)) {
    esd_dist <- NM_dsm_pred_ens.all %>% filter(truth == "ES3") %>% filter(str_detect(esdname, 
        gsub("([.|()\\^{}+$*?]|\\[|\\])", "\\\\\\1", as.character(NM_dsm_pred_ens.mis.es3$esdname[i])))) %>% 
        group_by(response) %>% summarise(no_rows = length(response))
    esd_dist <- esd_dist %>% set_names("ESD", "num")
    NM_ES_misClass <- left_join(NM_ES_misClass, esd_dist, by = "ESD")
}
NM_ES3_misClass <- NM_ES_misClass %>% set_names(c("ESD", as.character(NM_dsm_pred_ens.mis.es3$esdname)))
NM_ES3_misClass <- NM_ES3_misClass %>% gather(key = "ESD")
NM_ES3_misClass <- bind_cols(NM_ES3_misClass, data.frame(rep(paste0("ES", 
    c(1, 2, 0, 4, 5, 6, 7, 8)), length(unique(NM_dsm_pred_ens.mis.es3$esdname)))) %>% 
    set_names("ESG"))
NM_ES3_misClass <- NM_ES3_misClass %>% group_by(ESD) %>% arrange(ESG, .by_group = TRUE)

NM_ES3.DF <- NM_ES3_misClass %>% group_by(ESD) %>% mutate(ValuePer = (value/sum(value, 
    na.rm = TRUE))) %>% arrange(ESG, .by_group = TRUE) %>% ungroup()
# cbPalette <- c( '#ffa77f', '#00a884', '#beffe7', '#ffffbf',
# '#737301', '#fe0000', '#0071fe', '#732500')
ggplot(NM_ES3.DF, aes(ESD, ValuePer, fill = ESG)) + geom_bar(stat = "identity", 
    position = position_fill(reverse = TRUE)) + geom_text(aes(label = percent(ValuePer)), 
    position = position_stack(reverse = TRUE)) + scale_y_continuous(labels = percent_format())
ggsave("/data/data2/data/esgMapping/analysis/figures/NM_ES3_ESD_misclass.pdf")

#-------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------
# ES7 ESG class
NM_dsm_pred_ens.all.r.es7 <- NM_dsm_pred_ens.all %>% filter(truth == "ES7") %>% 
    group_by(response) %>% summarise(no_rows = length(response))
# View(NM_dsm_pred_ens.all.r.es7)

NM_dsm_pred_ens.misclass.r.es7 <- NM_dsm_pred_ens.misclass %>% filter(truth == 
    "ES7") %>% group_by(response) %>% summarise(no_rows = length(response))
# View(NM_dsm_pred_ens.misclass.r.es7)

#----------------------------------------------------------------------------------------  
# Evaluate ES7 misclassification ESD class
NM_dsm_pred_ens.all.es7 <- NM_dsm_pred_ens.all %>% filter(truth == "ES7") %>% 
    group_by(esdname) %>% summarise(no_rows = length(esdname))
# View(NM_dsm_pred_ens.all.es7)

NM_dsm_pred_ens.misclass.es7 <- NM_dsm_pred_ens.misclass %>% filter(truth == 
    "ES7") %>% group_by(esdname) %>% summarise(no_rows = length(esdname))
# View(NM_dsm_pred_ens.misclass.es7)

# combine number of all ESD classes and misclasses
NM_dsm_pred_ens.mis.es7 <- NM_dsm_pred_ens.all.es7 %>% left_join(NM_dsm_pred_ens.misclass.es7, 
    by = "esdname")
NM_dsm_pred_ens.mis.es7$misclassRate <- NM_dsm_pred_ens.mis.es7$no_rows.y/NM_dsm_pred_ens.mis.es7$no_rows.x
NM_dsm_pred_ens.mis.es7$esdname[1]
View(NM_dsm_pred_ens.mis.es7)

NM_ES_misClass <- data.frame(paste0("ES", seq(1:8))) %>% set_names("ESD")
for (i in 1L:length(NM_dsm_pred_ens.mis.es7$esdname)) {
    esd_dist <- NM_dsm_pred_ens.all %>% filter(truth == "ES7") %>% filter(str_detect(esdname, 
        gsub("([.|()\\^{}+$*?]|\\[|\\])", "\\\\\\1", as.character(NM_dsm_pred_ens.mis.es7$esdname[i])))) %>% 
        group_by(response) %>% summarise(no_rows = length(response))
    esd_dist <- esd_dist %>% set_names("ESD", "num")
    NM_ES_misClass <- left_join(NM_ES_misClass, esd_dist, by = "ESD")
}
NM_ES7_misClass <- NM_ES_misClass %>% set_names(c("ESD", as.character(NM_dsm_pred_ens.mis.es7$esdname)))
NM_ES7_misClass <- NM_ES7_misClass %>% gather(key = "ESD")
NM_ES7_misClass <- bind_cols(NM_ES7_misClass, data.frame(rep(paste0("ES", 
    c(1, 2, 3, 4, 5, 6, 0, 8)), length(unique(NM_dsm_pred_ens.mis.es7$esdname)))) %>% 
    set_names("ESG"))
NM_ES7_misClass <- NM_ES7_misClass %>% group_by(ESD) %>% arrange(ESG, .by_group = TRUE)

NM_ES7.DF <- NM_ES7_misClass %>% group_by(ESD) %>% mutate(ValuePer = (value/sum(value, 
    na.rm = TRUE))) %>% arrange(ESG, .by_group = TRUE) %>% ungroup()
# cbPalette <- c( '#ffa77f', '#00a884', '#beffe7', '#ffffbf',
# '#737301', '#fe0000', '#0071fe', '#732500')
ggplot(NM_ES7.DF, aes(ESD, ValuePer, fill = ESG)) + geom_bar(stat = "identity", 
    position = position_fill(reverse = TRUE)) + geom_text(aes(label = percent(ValuePer)), 
    position = position_stack(reverse = TRUE)) + scale_y_continuous(labels = percent_format())
ggsave("/data/data2/data/esgMapping/analysis/figures/NM_ES7_ESD_misclass.pdf")

#-------------------------------------------------------------------------------------------
```

## Run train models for different datasets
```{r eval=FALSE}
# CO models All
CO_all_train.svm <- mlr::train(CO_all_lrns[[1]], CO_all_var)
CO_all_train.rf <- mlr::train(CO_all_lrns[[2]], CO_all_var)
CO_all_train.xgb <- mlr::train(CO_all_lrns[[3]], CO_all_var)
CO_all_train.ens <- mlr::train(CO_all_lrns[[4]], CO_all_var)

CO_all_lrns.prob = lapply(CO_all_lrns, setPredictType, "prob")
CO_all_train.svm.prob <- mlr::train(CO_all_lrns.prob[[1]], CO_all_var)
CO_all_train.rf.prob <- mlr::train(CO_all_lrns.prob[[2]], CO_all_var)
CO_all_train.xgb.prob <- mlr::train(CO_all_lrns.prob[[3]], CO_all_var)

# Hyper
CO_hyper_train.svm <- mlr::train(CO_hyper_lrns[[1]], CO_hyper_var)
CO_hyper_train.rf <- mlr::train(CO_hyper_lrns[[2]], CO_hyper_var)
CO_hyper_train.xgb <- mlr::train(CO_hyper_lrns[[3]], CO_hyper_var)
CO_hyper_train.ens <- mlr::train(CO_hyper_lrns[[4]], CO_hyper_var)

CO_hyper_lrns.prob = lapply(CO_hyper_lrns, setPredictType, "prob")
CO_hyper_train.svm.prob <- mlr::train(CO_hyper_lrns.prob[[1]], CO_hyper_var)
CO_hyper_train.rf.prob <- mlr::train(CO_hyper_lrns.prob[[2]], CO_hyper_var)
CO_hyper_train.xgb.prob <- mlr::train(CO_hyper_lrns.prob[[3]], CO_hyper_var)

# NDVI
CO_ndvi_train.svm <- mlr::train(CO_ndvi_lrns[[1]], CO_ndvi_var)
CO_ndvi_train.rf <- mlr::train(CO_ndvi_lrns[[2]], CO_ndvi_var)
CO_ndvi_train.xgb <- mlr::train(CO_ndvi_lrns[[3]], CO_ndvi_var)
CO_ndvi_train.ens <- mlr::train(CO_ndvi_lrns[[4]], CO_ndvi_var)

CO_ndvi_lrns.prob = lapply(CO_ndvi_lrns, setPredictType, "prob")
CO_ndvi_train.svm.prob <- mlr::train(CO_ndvi_lrns.prob[[1]], CO_ndvi_var)
CO_ndvi_train.rf.prob <- mlr::train(CO_ndvi_lrns.prob[[2]], CO_ndvi_var)
CO_ndvi_train.xgb.prob <- mlr::train(CO_ndvi_lrns.prob[[3]], CO_sg_var)

# Abiotic
CO_abiotic_train.svm <- mlr::train(CO_abiotic_lrns[[1]], CO_abiotic_var)
CO_abiotic_train.rf <- mlr::train(CO_abiotic_lrns[[2]], CO_abiotic_var)
CO_abiotic_train.xgb <- mlr::train(CO_abiotic_lrns[[3]], CO_abiotic_var)
CO_abiotic_train.ens <- mlr::train(CO_abiotic_lrns[[4]], CO_abiotic_var)

CO_abiotic_lrns.prob = lapply(CO_abiotic_lrns, setPredictType, "prob")
CO_abiotic_train.svm.prob <- mlr::train(CO_abiotic_lrns.prob[[1]], CO_abiotic_var)
CO_abiotic_train.rf.prob <- mlr::train(CO_abiotic_lrns.prob[[2]], CO_abiotic_var)
CO_abiotic_train.xgb.prob <- mlr::train(CO_abiotic_lrns.prob[[3]], CO_abiotic_var)

# SG
CO_sg_train.svm <- mlr::train(CO_sg_lrns[[1]], CO_sg_var)
CO_sg_train.rf <- mlr::train(CO_sg_lrns[[2]], CO_sg_var)
CO_sg_train.xgb <- mlr::train(CO_sg_lrns[[3]], CO_sg_var)
CO_sg_train.ens <- mlr::train(CO_sg_lrns[[4]], CO_sg_var)

CO_sg_lrns.prob = lapply(CO_sg_lrns, setPredictType, "prob")
CO_sg_train.svm.prob <- mlr::train(CO_sg_lrns.prob[[1]], CO_sg_var)
CO_sg_train.rf.prob <- mlr::train(CO_sg_lrns.prob[[2]], CO_sg_var)
CO_sg_train.xgb.prob <- mlr::train(CO_sg_lrns.prob[[3]], CO_sg_var)

# DSM
CO_dsm_train.svm <- mlr::train(CO_dsm_lrns[[1]], CO_dsm_var)
CO_dsm_train.rf <- mlr::train(CO_dsm_lrns[[2]], CO_dsm_var)
CO_dsm_train.xgb <- mlr::train(CO_dsm_lrns[[3]], CO_dsm_var)
CO_dsm_train.ens <- mlr::train(CO_dsm_lrns[[4]], CO_dsm_var)

CO_dsm_lrns.prob = lapply(CO_dsm_lrns, setPredictType, "prob")
CO_dsm_train.svm.prob <- mlr::train(CO_dsm_lrns.prob[[1]], CO_dsm_var)
CO_dsm_train.rf.prob <- mlr::train(CO_dsm_lrns.prob[[2]], CO_dsm_var)
CO_dsm_train.xgb.prob <- mlr::train(CO_dsm_lrns.prob[[3]], CO_dsm_var)

# NM models
#---------------------------------------------------------------------------------------------
# All
NM_all_train.svm <- mlr::train(NM_all_lrns[[1]], NM_all_var)
NM_all_train.rf <- mlr::train(NM_all_lrns[[2]], NM_all_var)
NM_all_train.xgb <- mlr::train(NM_all_lrns[[3]], NM_all_var)
NM_all_train.ens <- mlr::train(NM_all_lrns[[4]], NM_all_var)

NM_all_lrns.prob = lapply(NM_all_lrns, setPredictType, "prob")
NM_all_train.svm.prob <- mlr::train(NM_all_lrns.prob[[1]], NM_all_var)
NM_all_train.rf.prob <- mlr::train(NM_all_lrns.prob[[2]], NM_all_var)
NM_all_train.xgb.prob <- mlr::train(NM_all_lrns.prob[[3]], NM_all_var)

# Hyper
NM_hyper_train.svm <- mlr::train(NM_hyper_lrns[[1]], NM_hyper_var)
NM_hyper_train.rf <- mlr::train(NM_hyper_lrns[[2]], NM_hyper_var)
NM_hyper_train.xgb <- mlr::train(NM_hyper_lrns[[3]], NM_hyper_var)
NM_hyper_train.ens <- mlr::train(NM_hyper_lrns[[4]], NM_hyper_var)

NM_hyper_lrns.prob = lapply(NM_hyper_lrns, setPredictType, "prob")
NM_hyper_train.svm.prob <- mlr::train(NM_hyper_lrns.prob[[1]], NM_hyper_var)
NM_hyper_train.rf.prob <- mlr::train(NM_hyper_lrns.prob[[2]], NM_hyper_var)
NM_hyper_train.xgb.prob <- mlr::train(NM_hyper_lrns.prob[[3]], NM_hyper_var)

# NDVI
NM_ndvi_train.svm <- mlr::train(NM_ndvi_lrns[[1]], NM_ndvi_var)
NM_ndvi_train.rf <- mlr::train(NM_ndvi_lrns[[2]], NM_ndvi_var)
NM_ndvi_train.xgb <- mlr::train(NM_ndvi_lrns[[3]], NM_ndvi_var)
NM_ndvi_train.ens <- mlr::train(NM_ndvi_lrns[[4]], NM_ndvi_var)

NM_ndvi_lrns.prob = lapply(NM_ndvi_lrns, setPredictType, "prob")
NM_ndvi_train.svm.prob <- mlr::train(NM_ndvi_lrns.prob[[1]], NM_ndvi_var)
NM_ndvi_train.rf.prob <- mlr::train(NM_ndvi_lrns.prob[[2]], NM_ndvi_var)
NM_ndvi_train.xgb.prob <- mlr::train(NM_ndvi_lrns.prob[[3]], NM_sg_var)

# Abiotic
NM_abiotic_train.svm <- mlr::train(NM_abiotic_lrns[[1]], NM_abiotic_var)
NM_abiotic_train.rf <- mlr::train(NM_abiotic_lrns[[2]], NM_abiotic_var)
NM_abiotic_train.xgb <- mlr::train(NM_abiotic_lrns[[3]], NM_abiotic_var)
NM_abiotic_train.ens <- mlr::train(NM_abiotic_lrns[[4]], NM_abiotic_var)

NM_abiotic_lrns.prob = lapply(NM_abiotic_lrns, setPredictType, "prob")
NM_abiotic_train.svm.prob <- mlr::train(NM_abiotic_lrns.prob[[1]], NM_abiotic_var)
NM_abiotic_train.rf.prob <- mlr::train(NM_abiotic_lrns.prob[[2]], NM_abiotic_var)
NM_abiotic_train.xgb.prob <- mlr::train(NM_abiotic_lrns.prob[[3]], NM_abiotic_var)

# SG
NM_sg_train.svm <- mlr::train(NM_sg_lrns[[1]], NM_sg_var)
NM_sg_train.rf <- mlr::train(NM_sg_lrns[[2]], NM_sg_var)
NM_sg_train.xgb <- mlr::train(NM_sg_lrns[[3]], NM_sg_var)
NM_sg_train.ens <- mlr::train(NM_sg_lrns[[4]], NM_sg_var)

NM_sg_lrns.prob = lapply(NM_sg_lrns, setPredictType, "prob")
NM_sg_train.svm.prob <- mlr::train(NM_sg_lrns.prob[[1]], NM_sg_var)
NM_sg_train.rf.prob <- mlr::train(NM_sg_lrns.prob[[2]], NM_sg_var)
NM_sg_train.xgb.prob <- mlr::train(NM_sg_lrns.prob[[3]], NM_sg_var)

# DSM
NM_dsm_train.svm <- mlr::train(NM_dsm_lrns[[1]], NM_dsm_var)
NM_dsm_train.rf <- mlr::train(NM_dsm_lrns[[2]], NM_dsm_var)
NM_dsm_train.xgb <- mlr::train(NM_dsm_lrns[[3]], NM_dsm_var)
NM_dsm_train.ens <- mlr::train(NM_dsm_lrns[[4]], NM_dsm_var)

NM_dsm_lrns.prob = lapply(NM_dsm_lrns, setPredictType, "prob")
NM_dsm_train.svm.prob <- mlr::train(NM_dsm_lrns.prob[[1]], NM_dsm_var)
NM_dsm_train.rf.prob <- mlr::train(NM_dsm_lrns.prob[[2]], NM_dsm_var)
NM_dsm_train.xgb.prob <- mlr::train(NM_dsm_lrns.prob[[3]], NM_dsm_var)

```

## Classifier Calibration
```{r eval=FALSE}
# generate calibration data from resampling
CO_dsm_train.svm.cal = generateCalibrationData(CO_dsm_resample_prob)
plotCalibration(CO_dsm_train.svm.cal, smooth = TRUE)
ggsave("/data/data2/data/esgMapping/analysis/figures/CO_dsm_classifier calibration.png", 
    width = 7, height = 4, dpi = 200, units = "in", device = "png")


NM_dsm_train.svm.cal = generateCalibrationData(NM_dsm_resample_prob)
plotCalibration(NM_dsm_train.svm.cal, smooth = TRUE)
ggsave("/data/data2/data/esgMapping/analysis/figures/NM_dsm_classifier calibration.png", 
    width = 7, height = 4, dpi = 200, units = "in", device = "png")


CO_dsm_train.ens.cal = generateCalibrationData(CO_dsm_resample_prob[[4]])
plotCalibration(CO_dsm_train.ens.cal, smooth = TRUE)
ggsave("/data/data2/data/esgMapping/analysis/figures/CO_dsm_classifier calibration_ens.png", 
    width = 6, height = 4, dpi = 200, units = "in", device = "png")
ggsave("/data/data2/data/esgMapping/analysis/figures/CO_dsm_classifier calibration_ens.pdf", 
    width = 6, height = 4, dpi = 200, units = "in")

NM_dsm_train.ens.cal = generateCalibrationData(NM_dsm_resample_prob[[4]])
plotCalibration(NM_dsm_train.ens.cal, smooth = TRUE)
ggsave("/data/data2/data/esgMapping/analysis/figures/NM_dsm_classifier calibration_ens.png", 
    width = 6, height = 4, dpi = 200, units = "in", device = "png")
ggsave("/data/data2/data/esgMapping/analysis/figures/NM_dsm_classifier calibration_ens.pdf", 
    width = 6, height = 4, dpi = 200, units = "in")

```

## Feature Importance
```{r eval=FALSE}
#---------------------------------------------------------------------------------------  
# Model Agnostic method for feature importance



# define loss function
acc <- function(actual, predicted) {
    cm = as.matrix(table(Actual = actual, Predicted = predicted))
    n = sum(cm)
    diag = diag(cm)
    accuracy = sum(diag)/n
    return(accuracy)
}

# uses the metric 'ce'=classification error which is the opposite of
# accuracy all
CO.all.svm = Predictor$new(CO_all_train.svm.prob, data = co.esg.all.cov.rm[-1], 
    y = co.esg.all.cov.rm[1])
CO.all.svm.imp = FeatureImp$new(CO.all.svm, loss = "ce")
CO.all.rf = Predictor$new(CO_all_train.rf.prob, data = co.esg.all.cov.rm[-1], 
    y = co.esg.all.cov.rm[1])
CO.all.rf.imp = FeatureImp$new(CO.all.rf, loss = "ce")
CO.all.xgb = Predictor$new(CO_all_train.xgb.prob, data = co.esg.all.cov.rm[-1], 
    y = co.esg.all.cov.rm[1])
CO.all.xgb.imp = FeatureImp$new(CO.all.xgb, loss = "ce")
CO.all.ens = Predictor$new(CO_all_train.ens, data = co.esg.all.cov.rm[-1], 
    y = co.esg.all.cov.rm[1])
CO.all.ens.imp = FeatureImp$new(CO.all.ens, loss = "ce")

NM.all.svm = Predictor$new(NM_all_train.svm.prob, data = nm.esg.all.cov.rm[-1], 
    y = nm.esg.all.cov.rm[1])
NM.all.svm.imp = FeatureImp$new(NM.all.svm, loss = "ce")
NM.all.rf = Predictor$new(NM_all_train.rf.prob, data = nm.esg.all.cov.rm[-1], 
    y = nm.esg.all.cov.rm[1])
NM.all.rf.imp = FeatureImp$new(NM.all.rf, loss = "ce")
NM.all.xgb = Predictor$new(NM_all_train.xgb.prob, data = nm.esg.all.cov.rm[-1], 
    y = nm.esg.all.cov.rm[1])
NM.all.xgb.imp = FeatureImp$new(NM.all.xgb, loss = "ce")
NM.all.ens = Predictor$new(NM_all_train.ens, data = NM.esg.all.cov.rm[-1], 
    y = nm.esg.all.cov.rm[1])
NM.all.ens.imp = FeatureImp$new(NM.all.ens, loss = "ce")

# hyper
CO.hyper.svm = Predictor$new(CO_hyper_train.svm.prob, data = co.esg.hyper.cov.rm[-1], 
    y = co.esg.hyper.cov.rm[1])
CO.hyper.svm.imp = FeatureImp$new(CO.hyper.svm, loss = "ce")
CO.hyper.rf = Predictor$new(CO_hyper_train.rf.prob, data = co.esg.hyper.cov.rm[-1], 
    y = co.esg.hyper.cov.rm[1])
CO.hyper.rf.imp = FeatureImp$new(CO.hyper.rf, loss = "ce")
CO.hyper.xgb = Predictor$new(CO_hyper_train.xgb.prob, data = co.esg.hyper.cov.rm[-1], 
    y = co.esg.hyper.cov.rm[1])
CO.hyper.xgb.imp = FeatureImp$new(CO.hyper.xgb, loss = "ce")
CO.hyper.ens = Predictor$new(CO_hyper_train.ens, data = co.esg.hyper.cov.rm[-1], 
    y = co.esg.hyper.cov.rm[1])
CO.hyper.ens.imp = FeatureImp$new(CO.hyper.ens, loss = "ce")

NM.hyper.svm = Predictor$new(NM_hyper_train.svm.prob, data = nm.esg.hyper.cov.rm[-1], 
    y = nm.esg.hyper.cov.rm[1])
NM.hyper.svm.imp = FeatureImp$new(NM.hyper.svm, loss = "ce")
NM.hyper.rf = Predictor$new(NM_hyper_train.rf.prob, data = nm.esg.hyper.cov.rm[-1], 
    y = nm.esg.hyper.cov.rm[1])
NM.hyper.rf.imp = FeatureImp$new(NM.hyper.rf, loss = "ce")
NM.hyper.xgb = Predictor$new(NM_hyper_train.xgb.prob, data = nm.esg.hyper.cov.rm[-1], 
    y = nm.esg.hyper.cov.rm[1])
NM.hyper.xgb.imp = FeatureImp$new(NM.hyper.xgb, loss = "ce")
NM.hyper.ens = Predictor$new(NM_hyper_train.ens, data = NM.esg.hyper.cov.rm[-1], 
    y = nm.esg.hyper.cov.rm[1])
NM.hyper.ens.imp = FeatureImp$new(NM.hyper.ens, loss = "ce")

# ndvi
CO.ndvi.svm = Predictor$new(CO_ndvi_train.svm.prob, data = co.esg.ndvi.cov.rm[-1], 
    y = co.esg.ndvi.cov.rm[1])
CO.ndvi.svm.imp = FeatureImp$new(CO.ndvi.svm, loss = "ce")
CO.ndvi.rf = Predictor$new(CO_ndvi_train.rf.prob, data = co.esg.ndvi.cov.rm[-1], 
    y = co.esg.ndvi.cov.rm[1])
CO.ndvi.rf.imp = FeatureImp$new(CO.ndvi.rf, loss = "ce")
CO.ndvi.xgb = Predictor$new(CO_ndvi_train.xgb.prob, data = co.esg.ndvi.cov.rm[-1], 
    y = co.esg.ndvi.cov.rm[1])
CO.ndvi.xgb.imp = FeatureImp$new(CO.ndvi.xgb, loss = "ce")
CO.ndvi.ens = Predictor$new(CO_ndvi_train.ens, data = co.esg.ndvi.cov.rm[-1], 
    y = co.esg.ndvi.cov.rm[1])
CO.ndvi.ens.imp = FeatureImp$new(CO.ndvi.ens, loss = "ce")

NM.ndvi.svm = Predictor$new(NM_ndvi_train.svm.prob, data = nm.esg.ndvi.cov.rm[-1], 
    y = nm.esg.ndvi.cov.rm[1])
NM.ndvi.svm.imp = FeatureImp$new(NM.ndvi.svm, loss = "ce")
NM.ndvi.rf = Predictor$new(NM_ndvi_train.rf.prob, data = nm.esg.ndvi.cov.rm[-1], 
    y = nm.esg.ndvi.cov.rm[1])
NM.ndvi.rf.imp = FeatureImp$new(NM.ndvi.rf, loss = "ce")
NM.ndvi.xgb = Predictor$new(NM_ndvi_train.xgb.prob, data = nm.esg.ndvi.cov.rm[-1], 
    y = nm.esg.ndvi.cov.rm[1])
NM.ndvi.xgb.imp = FeatureImp$new(NM.ndvi.xgb, loss = "ce")
NM.ndvi.ens = Predictor$new(NM_ndvi_train.ens, data = NM.esg.ndvi.cov.rm[-1], 
    y = nm.esg.ndvi.cov.rm[1])
NM.ndvi.ens.imp = FeatureImp$new(NM.ndvi.ens, loss = "ce")

# abiotic
CO.abiotic.svm = Predictor$new(CO_abiotic_train.svm.prob, data = co.esg.abiotic.cov.rm[-1], 
    y = co.esg.abiotic.cov.rm[1])
CO.abiotic.svm.imp = FeatureImp$new(CO.abiotic.svm, loss = "ce")
CO.abiotic.rf = Predictor$new(CO_abiotic_train.rf.prob, data = co.esg.abiotic.cov.rm[-1], 
    y = co.esg.abiotic.cov.rm[1])
CO.abiotic.rf.imp = FeatureImp$new(CO.abiotic.rf, loss = "ce")
CO.abiotic.xgb = Predictor$new(CO_abiotic_train.xgb.prob, data = co.esg.abiotic.cov.rm[-1], 
    y = co.esg.abiotic.cov.rm[1])
CO.abiotic.xgb.imp = FeatureImp$new(CO.abiotic.xgb, loss = "ce")
CO.abiotic.ens = Predictor$new(CO_abiotic_train.ens, data = co.esg.abiotic.cov.rm[-1], 
    y = co.esg.abiotic.cov.rm[1])
CO.abiotic.ens.imp = FeatureImp$new(CO.abiotic.ens, loss = "ce")

NM.abiotic.svm = Predictor$new(NM_abiotic_train.svm.prob, data = nm.esg.abiotic.cov.rm[-1], 
    y = nm.esg.abiotic.cov.rm[1])
NM.abiotic.svm.imp = FeatureImp$new(NM.abiotic.svm, loss = "ce")
NM.abiotic.rf = Predictor$new(NM_abiotic_train.rf.prob, data = nm.esg.abiotic.cov.rm[-1], 
    y = nm.esg.abiotic.cov.rm[1])
NM.abiotic.rf.imp = FeatureImp$new(NM.abiotic.rf, loss = "ce")
NM.abiotic.xgb = Predictor$new(NM_abiotic_train.xgb.prob, data = nm.esg.abiotic.cov.rm[-1], 
    y = nm.esg.abiotic.cov.rm[1])
NM.abiotic.xgb.imp = FeatureImp$new(NM.abiotic.xgb, loss = "ce")
NM.abiotic.ens = Predictor$new(NM_abiotic_train.ens, data = NM.esg.abiotic.cov.rm[-1], 
    y = nm.esg.abiotic.cov.rm[1])
NM.abiotic.ens.imp = FeatureImp$new(NM.abiotic.ens, loss = "ce")

# sg
CO.sg.svm = Predictor$new(CO_sg_train.svm.prob, data = co.esg.sg.cov.rm[-1], 
    y = co.esg.sg.cov.rm[1])
CO.sg.svm.imp = FeatureImp$new(CO.sg.svm, loss = "ce")
CO.sg.rf = Predictor$new(CO_sg_train.rf.prob, data = co.esg.sg.cov.rm[-1], 
    y = co.esg.sg.cov.rm[1])
CO.sg.rf.imp = FeatureImp$new(CO.sg.rf, loss = "ce")
CO.sg.xgb = Predictor$new(CO_sg_train.xgb.prob, data = co.esg.sg.cov.rm[-1], 
    y = co.esg.sg.cov.rm[1])
CO.sg.xgb.imp = FeatureImp$new(CO.sg.xgb, loss = "ce")
CO.sg.ens = Predictor$new(CO_sg_train.ens, data = co.esg.sg.cov.rm[-1], 
    y = co.esg.sg.cov.rm[1])
CO.sg.ens.imp = FeatureImp$new(CO.sg.ens, loss = "ce")

NM.sg.svm = Predictor$new(NM_sg_train.svm.prob, data = nm.esg.sg.cov.rm[-1], 
    y = nm.esg.sg.cov.rm[1])
NM.sg.svm.imp = FeatureImp$new(NM.sg.svm, loss = "ce")
NM.sg.rf = Predictor$new(NM_sg_train.rf.prob, data = nm.esg.sg.cov.rm[-1], 
    y = nm.esg.sg.cov.rm[1])
NM.sg.rf.imp = FeatureImp$new(NM.sg.rf, loss = "ce")
NM.sg.xgb = Predictor$new(NM_sg_train.xgb.prob, data = nm.esg.sg.cov.rm[-1], 
    y = nm.esg.sg.cov.rm[1])
NM.sg.xgb.imp = FeatureImp$new(NM.sg.xgb, loss = "ce")
NM.sg.ens = Predictor$new(NM_sg_train.ens, data = NM.esg.sg.cov.rm[-1], 
    y = nm.esg.sg.cov.rm[1])
NM.sg.ens.imp = FeatureImp$new(NM.sg.ens, loss = "ce")

# dsm
CO.dsm.svm = Predictor$new(CO_dsm_train.svm.prob, data = co.esg.dsm.cov.rm[-1], 
    y = co.esg.dsm.cov.rm[1])
CO.dsm.svm.imp = FeatureImp$new(CO.dsm.svm, loss = "ce")
CO.dsm.rf = Predictor$new(CO_dsm_train.rf.prob, data = co.esg.dsm.cov.rm[-1], 
    y = co.esg.dsm.cov.rm[1])
CO.dsm.rf.imp = FeatureImp$new(CO.dsm.rf, loss = "ce")
CO.dsm.xgb = Predictor$new(CO_dsm_train.xgb.prob, data = co.esg.dsm.cov.rm[-1], 
    y = co.esg.dsm.cov.rm[1])
CO.dsm.xgb.imp = FeatureImp$new(CO.dsm.xgb, loss = "ce")
CO.dsm.ens = Predictor$new(CO_dsm_train.ens, data = co.esg.dsm.cov.rm[-1], 
    y = co.esg.dsm.cov.rm[1])
CO.dsm.ens.imp = FeatureImp$new(CO.dsm.ens, loss = "ce")

# need to convert categorical to factor
nm.esg.dsm.cov.rm$TAXOUSDA_250m <- as.numeric(nm.esg.dsm.cov.rm$TAXOUSDA_250m)
NM.dsm.svm = Predictor$new(NM_dsm_train.svm.prob, data = nm.esg.dsm.cov.rm[-1], 
    y = nm.esg.dsm.cov.rm[1])
NM.dsm.svm.imp = FeatureImp$new(NM.dsm.svm, loss = "ce")
NM.dsm.rf = Predictor$new(NM_dsm_train.rf.prob, data = nm.esg.dsm.cov.rm[-1], 
    y = nm.esg.dsm.cov.rm[1])
NM.dsm.rf.imp = FeatureImp$new(NM.dsm.rf, loss = "ce")
NM.dsm.xgb = Predictor$new(NM_dsm_train.xgb.prob, data = nm.esg.dsm.cov.rm[-1], 
    y = nm.esg.dsm.cov.rm[1])
NM.dsm.xgb.imp = FeatureImp$new(NM.dsm.xgb, loss = "ce")
NM.dsm.ens = Predictor$new(NM_dsm_train.ens, data = nm.esg.dsm.cov.rm[-1], 
    y = nm.esg.dsm.cov.rm[1])
NM.dsm.ens.imp = FeatureImp$new(NM.dsm.ens, loss = "ce")

CO.dsm.ens = Predictor$new(CO_dsm_train.ens, data = co.esg.dsm.cov.rm[-1], 
    y = co.esg.dsm.cov.rm[1])
CO.dsm.ens.imp = FeatureImp$new(CO.dsm.ens, loss = "ce")

mlr_VI_ggplot <- function(imp, metric_title, sub) {
    mlr_vi <- imp$results
    var_importance <- data.frame(variable = mlr_vi$feature, importance = as.vector(mlr_vi$importance))
    var_importance <- arrange(var_importance, desc(importance))
    var_importance$variable <- factor(var_importance$variable, levels = var_importance$variable)
    if (is.null(sub)) {
        var_importance_sub <- var_importance
    } else {
        var_importance_sub <- var_importance[1:sub, ]
    }
    
    var_importance_sub$variable = with(var_importance_sub, factor(variable, 
        levels = rev(levels(variable))))
    # Plot
    theme_set(theme_bw())
    p <- ggplot(var_importance_sub, aes(x = variable, y = importance)) + 
        geom_point(size = 3) + geom_segment(aes(x = variable, xend = variable, 
        y = 1, yend = importance)) + coord_flip() + labs(title = paste0("Variable Importance"), 
        subtitle = paste0("(", metric_title, ")")) + xlab("Covariates") + 
        ylab(paste0("Importance")) + theme(axis.text.x = element_text(angle = 0, 
        vjust = 0.6)) + theme(axis.text.y = element_text(angle = 0, vjust = 0.6))
    return(p)
}

multiplot <- function(..., plotlist = NULL, file, cols = 1, layout = NULL) {
    library(grid)
    
    # Make a list from the ... arguments and plotlist
    plots <- c(list(...), plotlist)
    
    numPlots = length(plots)
    
    # If layout is NULL, then use 'cols' to determine layout
    if (is.null(layout)) {
        # Make the panel ncol: Number of columns of plots nrow: Number of rows
        # needed, calculated from # of cols
        layout <- matrix(seq(1, cols * ceiling(numPlots/cols)), ncol = cols, 
            nrow = ceiling(numPlots/cols))
    }
    
    if (numPlots == 1) {
        print(plots[[1]])
        
    } else {
        # Set up the page
        grid.newpage()
        pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))
        
        # Make each plot, in the correct location
        for (i in 1:numPlots) {
            # Get the i,j matrix positions of the regions that contain this subplot
            matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))
            
            print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row, 
                layout.pos.col = matchidx$col))
        }
    }
}

CO.dsm.svm.imp.plot <- mlr_VI_ggplot(CO.dsm.svm.imp, "Support Vector Machines", 
    10)
CO.dsm.rf.imp.plot <- mlr_VI_ggplot(CO.dsm.rf.imp, "Random Forest", 10)
CO.dsm.xgb.imp.plot <- mlr_VI_ggplot(CO.dsm.xgb.imp, "Extreme Gradient Boosting", 
    10)

# multiplot(CO.dsm.svm.imp.plot, CO.dsm.rf.imp.plot,
# CO.dsm.xgb.imp.plot, cols=3)
CO_dsm_variableImp <- grid.arrange(CO.dsm.svm.imp.plot, CO.dsm.rf.imp.plot, 
    CO.dsm.xgb.imp.plot, ncol = 3)
ggsave("/data/data2/data/esgMapping/analysis/figures/CO_dsm_svm_variableImp.pdf", 
    CO.dsm.svm.imp.plot, scale = 0.6)
ggsave("/data/data2/data/esgMapping/analysis/figures/CO_dsm_svm_variableImp.pdf", 
    CO.dsm.svm.imp.plot, scale = 0.6)
ggsave("/data/data2/data/esgMapping/analysis/figures/CO_dsm_rf_variableImp.pdf", 
    CO.dsm.rf.imp.plot, scale = 0.6)
ggsave("/data/data2/data/esgMapping/analysis/figures/CO_dsm_xgb_variableImp.pdf", 
    CO.dsm.xgb.imp.plot, scale = 0.6)

NM.dsm.svm.imp.plot <- mlr_VI_ggplot(NM.dsm.svm.imp, "Support Vector Machines", 
    10)
NM.dsm.rf.imp.plot <- mlr_VI_ggplot(NM.dsm.rf.imp, "Random Forest", 10)
NM.dsm.xgb.imp.plot <- mlr_VI_ggplot(NM.dsm.xgb.imp, "Extreme Gradient Boosting", 
    10)

# multiplot(NM.dsm.svm.imp.plot, NM.dsm.rf.imp.plot,
# NM.dsm.xgb.imp.plot, cols=3)
NM_dsm_variableImp <- grid.arrange(NM.dsm.svm.imp.plot, NM.dsm.rf.imp.plot, 
    NM.dsm.xgb.imp.plot, ncol = 3)
ggsave("/data/data2/data/esgMapping/analysis/figures/NM_dsm_svm_variableImp.pdf", 
    NM.dsm.svm.imp.plot, scale = 0.6)
ggsave("/data/data2/data/esgMapping/analysis/figures/NM_dsm_svm_variableImp.pdf", 
    NM.dsm.svm.imp.plot, scale = 0.6)
ggsave("/data/data2/data/esgMapping/analysis/figures/NM_dsm_rf_variableImp.pdf", 
    NM.dsm.rf.imp.plot, scale = 0.6)
ggsave("/data/data2/data/esgMapping/analysis/figures/NM_dsm_xgb_variableImp.pdf", 
    NM.dsm.xgb.imp.plot, scale = 0.6)

# #Another model agnostic approach using the vip package--takes too long to calculate  
#   library(vip)
#   mod <- getLearnerModel(NM_dsm_train.svm.prob)
#   svm.hyper <- getHyperPars(NM_dsm_lrns[[1]])
#   svm.model <- svm(esite ~ ., data = nm.esg.dsm.cov.rm, cost = svm.hyper$cost, gamma = svm.hyper$gamma, scale=svm.hyper$ppc.scale, probability=TRUE)
#   mod.vi <- vip(svm.model, method = "pdp", feature_names=mod$features)
  
  
```


## Partial dependence plots and individual conditional expectation curves
```{r eval=FALSE}
# Create list of observations that were correctly classified
NM_dsm.rf.obsError <- data.frame(as.factor(NM_dsm.rf.pred$data$id)) %>% 
    set_names(".id")
for (i in 1:length(NM_dsm.rf.pred$data$response)) {
    if (NM_dsm.rf.pred$data$response[i] == NM_dsm.rf.pred$data$truth[i]) {
        NM_dsm.rf.obsError$predict[i] <- "Truth"
    } else {
        NM_dsm.rf.obsError$predict[i] <- "False"
    }
}

CO_dsm.rf.obsError <- data.frame(as.factor(CO_dsm.rf.pred$data$id)) %>% 
    set_names(".id")
for (i in 1:length(CO_dsm.rf.pred$data$response)) {
    if (CO_dsm.rf.pred$data$response[i] == CO_dsm.rf.pred$data$truth[i]) {
        CO_dsm.rf.obsError$predict[i] <- "Truth"
    } else {
        CO_dsm.rf.obsError$predict[i] <- "False"
    }
}

#-----------------Create PDP and ICE plots 

#CO RF NDVI
  # CO.dsm.rf.c1 = Predictor$new(CO_dsm_train.rf.prob, data=co.esg.dsm.cov.rm[-1], y=co.esg.dsm.cov.rm[1], class=1)
  # CO.dsm.rf.ndvi.pd.c1 = Partial$new(CO.dsm.rf.c1, feature = "NDVI_Dec_Mean", ice=TRUE)
  # plot(CO.dsm.rf.ndvi.pd.c1)

CO.dsm.rf.ndvi.pd = Partial$new(CO.dsm.rf, feature = "NDVI_Dec_Mean", ice = TRUE)  #, center.at=min(co.esg.dsm.cov.rm$NDVI_Dec_Mean))
plot(CO.dsm.rf.ndvi.pd)
ggplot_build(CO.dsm.rf.ndvi.pd)
CO.dsm.rf.ndvi.results <- CO.dsm.rf.ndvi.pd$results
CO.dsm.rf.ndvi.results$.id <- as.factor(CO.dsm.rf.ndvi.results$.id)
site_es <- data.frame(as.factor(seq(1, length(co.esg.dsm.cov.rm$esite), 
    1)), co.esg.dsm.cov.rm$esite) %>% set_names(c(".id", "esite"))
CO.dsm.rf.ndvi.results <- left_join(CO.dsm.rf.ndvi.results, site_es, by = ".id")
CO.dsm.rf.ndvi.results <- left_join(CO.dsm.rf.ndvi.results, CO_dsm.rf.obsError, 
    by = ".id")

CO.dsm.rf.ndvi.pd.es1 <- CO.dsm.rf.ndvi.results %>% filter(.type == "ice" & 
    .class == "ES1") %>% group_by(.id) %>% group_by(esite) %>% ggplot(aes(x = NDVI_Dec_Mean, 
    y = .y.hat, group = .id, colour = esite)) + geom_line() + scale_y_continuous("Probability") + 
    scale_colour_viridis_d() + theme(legend.position = "none")
CO.dsm.rf.ndvi.pd.es2 <- CO.dsm.rf.ndvi.results %>% filter(.type == "ice" & 
    .class == "ES2") %>% group_by(.id) %>% group_by(esite) %>% ggplot(aes(x = NDVI_Dec_Mean, 
    y = .y.hat, group = .id, colour = esite)) + geom_line() + scale_y_continuous("Probability") + 
    scale_colour_viridis_d() + theme(legend.position = "none")
CO.dsm.rf.ndvi.pd.es3 <- CO.dsm.rf.ndvi.results %>% filter(.type == "ice" & 
    .class == "ES3") %>% group_by(.id) %>% group_by(esite) %>% ggplot(aes(x = NDVI_Dec_Mean, 
    y = .y.hat, group = .id, colour = esite)) + geom_line() + scale_y_continuous("Probability") + 
    scale_colour_viridis_d() + theme(legend.position = "none")
CO.dsm.rf.ndvi.pd.es4 <- CO.dsm.rf.ndvi.results %>% filter(.type == "ice" & 
    .class == "ES4") %>% group_by(.id) %>% group_by(esite) %>% ggplot(aes(x = NDVI_Dec_Mean, 
    y = .y.hat, group = .id, colour = esite)) + geom_line() + scale_y_continuous("Probability") + 
    scale_colour_viridis_d() + theme(legend.position = "none")
CO.dsm.rf.ndvi.pd.es5 <- CO.dsm.rf.ndvi.results %>% filter(.type == "ice" & 
    .class == "ES5") %>% group_by(.id) %>% group_by(esite) %>% ggplot(aes(x = NDVI_Dec_Mean, 
    y = .y.hat, group = .id, colour = esite)) + geom_line() + scale_y_continuous("Probability") + 
    scale_colour_viridis_d() + theme(legend.position = "none")
CO.dsm.rf.ndvi.pd.es6 <- CO.dsm.rf.ndvi.results %>% filter(.type == "ice" & 
    .class == "ES6") %>% group_by(.id) %>% group_by(esite) %>% ggplot(aes(x = NDVI_Dec_Mean, 
    y = .y.hat, group = .id, colour = esite)) + geom_line() + scale_y_continuous("Probability") + 
    scale_colour_viridis_d() + theme(legend.position = "none")
CO.dsm.rf.ndvi.pd.es7 <- CO.dsm.rf.ndvi.results %>% filter(.type == "ice" & 
    .class == "ES7") %>% group_by(.id) %>% group_by(esite) %>% ggplot(aes(x = NDVI_Dec_Mean, 
    y = .y.hat, group = .id, colour = esite)) + geom_line() + scale_y_continuous("Probability") + 
    scale_colour_viridis_d() + theme(legend.position = "none")
CO.dsm.rf.ndvi.pd.es99 <- CO.dsm.rf.ndvi.results %>% filter(.type == "ice" & 
    .class == "ES99") %>% group_by(.id) %>% group_by(esite) %>% ggplot(aes(x = NDVI_Dec_Mean, 
    y = .y.hat, group = .id, colour = esite)) + geom_line() + scale_y_continuous("Probability") + 
    scale_colour_viridis_d() + theme(legend.position = "none")

CO_dsm_rf_ice <- grid.arrange(CO.dsm.rf.ndvi.pd.es1, CO.dsm.rf.ndvi.pd.es2, 
    CO.dsm.rf.ndvi.pd.es3, CO.dsm.rf.ndvi.pd.es4, CO.dsm.rf.ndvi.pd.es5, 
    CO.dsm.rf.ndvi.pd.es6, CO.dsm.rf.ndvi.pd.es7, CO.dsm.rf.ndvi.pd.es99, 
    ncol = 3)
ggsave("/data/data2/data/esgMapping/analysis/figures/CO_dsm_rf_ice.pdf", 
    CO_dsm_rf_ice, width = 10, height = 10, dpi = 300, units = "in")

# Subset so that it only plots observations belonging to each ESG and
# then displays correct and missclassified observations
CO.dsm.rf.ndvi.pd.es1 <- CO.dsm.rf.ndvi.results %>% filter(.type == "ice" & 
    .class == "ES1" & esite == "ES1") %>% group_by(.id) %>% group_by(predict) %>% 
    ggplot(aes(x = NDVI_Dec_Mean, y = .y.hat, group = .id, colour = predict)) + 
    geom_line() + scale_y_continuous("Probability", limits = c(0, 1)) + 
    scale_color_manual(values = c("red", "black")) + theme(legend.position = "none")
CO.dsm.rf.ndvi.pd.es2 <- CO.dsm.rf.ndvi.results %>% filter(.type == "ice" & 
    .class == "ES2" & esite == "ES2") %>% group_by(.id) %>% group_by(predict) %>% 
    ggplot(aes(x = NDVI_Dec_Mean, y = .y.hat, group = .id, colour = predict)) + 
    geom_line() + scale_y_continuous("Probability", limits = c(0, 1)) + 
    scale_color_manual(values = c("red", "black")) + theme(legend.position = "none")
CO.dsm.rf.ndvi.pd.es3 <- CO.dsm.rf.ndvi.results %>% filter(.type == "ice" & 
    .class == "ES3" & esite == "ES3") %>% group_by(.id) %>% group_by(predict) %>% 
    ggplot(aes(x = NDVI_Dec_Mean, y = .y.hat, group = .id, colour = predict)) + 
    geom_line() + scale_y_continuous("Probability", limits = c(0, 1)) + 
    scale_color_manual(values = c("red", "black")) + theme(legend.position = "none")
CO.dsm.rf.ndvi.pd.es4 <- CO.dsm.rf.ndvi.results %>% filter(.type == "ice" & 
    .class == "ES4" & esite == "ES4") %>% group_by(.id) %>% group_by(predict) %>% 
    ggplot(aes(x = NDVI_Dec_Mean, y = .y.hat, group = .id, colour = predict)) + 
    geom_line() + scale_y_continuous("Probability", limits = c(0, 1)) + 
    scale_color_manual(values = c("red", "black")) + theme(legend.position = "none")
CO.dsm.rf.ndvi.pd.es5 <- CO.dsm.rf.ndvi.results %>% filter(.type == "ice" & 
    .class == "ES5" & esite == "ES5") %>% group_by(.id) %>% group_by(predict) %>% 
    ggplot(aes(x = NDVI_Dec_Mean, y = .y.hat, group = .id, colour = predict)) + 
    geom_line() + scale_y_continuous("Probability", limits = c(0, 1)) + 
    scale_color_manual(values = c("red", "black")) + theme(legend.position = "none")
CO.dsm.rf.ndvi.pd.es6 <- CO.dsm.rf.ndvi.results %>% filter(.type == "ice" & 
    .class == "ES6" & esite == "ES6") %>% group_by(.id) %>% group_by(predict) %>% 
    ggplot(aes(x = NDVI_Dec_Mean, y = .y.hat, group = .id, colour = predict)) + 
    geom_line() + scale_y_continuous("Probability", limits = c(0, 1)) + 
    scale_color_manual(values = c("red", "black")) + theme(legend.position = "none")
CO.dsm.rf.ndvi.pd.es7 <- CO.dsm.rf.ndvi.results %>% filter(.type == "ice" & 
    .class == "ES7" & esite == "ES7") %>% group_by(.id) %>% group_by(predict) %>% 
    ggplot(aes(x = NDVI_Dec_Mean, y = .y.hat, group = .id, colour = predict)) + 
    geom_line() + scale_y_continuous("Probability", limits = c(0, 1)) + 
    scale_color_manual(values = c("red", "black")) + theme(legend.position = "none")
CO.dsm.rf.ndvi.pd.es99 <- CO.dsm.rf.ndvi.results %>% filter(.type == "ice" & 
    .class == "ES99" & esite == "ES99") %>% group_by(.id) %>% group_by(predict) %>% 
    ggplot(aes(x = NDVI_Dec_Mean, y = .y.hat, group = .id, colour = predict)) + 
    geom_line() + scale_y_continuous("Probability", limits = c(0, 1)) + 
    scale_color_manual(values = c("red", "black")) + theme(legend.position = "none")

CO_dsm_rf_ice.sub <- grid.arrange(CO.dsm.rf.ndvi.pd.es1, CO.dsm.rf.ndvi.pd.es2, 
    CO.dsm.rf.ndvi.pd.es3, CO.dsm.rf.ndvi.pd.es4, CO.dsm.rf.ndvi.pd.es5, 
    CO.dsm.rf.ndvi.pd.es6, CO.dsm.rf.ndvi.pd.es7, CO.dsm.rf.ndvi.pd.es99, 
    ncol = 3)
ggsave("/data/data2/data/esgMapping/analysis/figures/CO_dsm_rf_ice.sub.pdf", 
    CO_dsm_rf_ice.sub, width = 10, height = 10, dpi = 300, units = "in")

#--------------------------------------------------------------------------------------------
#NM RF TAXOUSDA
  # NM.dsm.rf.c1 = Predictor$new(NM_dsm_train.rf.prob, data=NM.esg.dsm.NMv.rm[-1], y=NM.esg.dsm.NMv.rm[1], class=1)
  # NM.dsm.rf.tax.pd.c1 = Partial$new(NM.dsm.rf.c1, feature = "NDVI_Dec_Mean", ice=TRUE)
  # plot(NM.dsm.rf.tax.pd.c1)
taxousda_legend <- read.csv("/data/data2/data/esgMapping/analysis/data/raw_data/TAXOUSDA_250m_Legend.csv")
nm.taxo <- as.numeric(unique(nm.esg.dsm.cov.rm$TAXOUSDA_250m))
nm.tax.key <- taxousda_legend %>% filter(taxousda_legend$Number %in% nm.taxo) %>% 
    select(Number, Group)
NM.dsm.rf.tax.pd = Partial$new(NM.dsm.rf, feature = "TAXOUSDA_250m", ice = TRUE)  #, center.at=min(nm.esg.dsm.cov.rm$TAXOUSDA_250m))
plot(NM.dsm.rf.tax.pd)
NM.dsm.rf.tax.results <- NM.dsm.rf.tax.pd$results
NM.dsm.rf.tax.results$.id <- as.factor(NM.dsm.rf.tax.results$.id)
site_es <- data.frame(as.factor(seq(1, length(nm.esg.dsm.cov.rm$esite), 
    1)), nm.esg.dsm.cov.rm$esite) %>% set_names(c(".id", "esite"))
NM.dsm.rf.tax.results <- left_join(NM.dsm.rf.tax.results, site_es, by = ".id")
NM.dsm.rf.tax.results <- left_join(NM.dsm.rf.tax.results, NM_dsm.rf.obsError, 
    by = ".id")

NM.dsm.rf.tax.pd.es1 <- NM.dsm.rf.tax.results %>% filter(.type == "ice" & 
    .class == "ES1") %>% group_by(.id) %>% group_by(esite) %>% ggplot(aes(x = TAXOUSDA_250m, 
    y = .y.hat, group = .id, colour = esite)) + geom_line() + scale_y_continuous("Probability") + 
    scale_colour_viridis_d() + theme(legend.position = "none")
NM.dsm.rf.tax.pd.es2 <- NM.dsm.rf.tax.results %>% filter(.type == "ice" & 
    .class == "ES2") %>% group_by(.id) %>% group_by(esite) %>% ggplot(aes(x = TAXOUSDA_250m, 
    y = .y.hat, group = .id, colour = esite)) + geom_line() + scale_y_continuous("Probability") + 
    scale_colour_viridis_d() + theme(legend.position = "none")
NM.dsm.rf.tax.pd.es3 <- NM.dsm.rf.tax.results %>% filter(.type == "ice" & 
    .class == "ES3") %>% group_by(.id) %>% group_by(esite) %>% ggplot(aes(x = TAXOUSDA_250m, 
    y = .y.hat, group = .id, colour = esite)) + geom_line() + scale_y_continuous("Probability") + 
    scale_colour_viridis_d() + theme(legend.position = "none")
NM.dsm.rf.tax.pd.es4 <- NM.dsm.rf.tax.results %>% filter(.type == "ice" & 
    .class == "ES4") %>% group_by(.id) %>% group_by(esite) %>% ggplot(aes(x = TAXOUSDA_250m, 
    y = .y.hat, group = .id, colour = esite)) + geom_line() + scale_y_continuous("Probability") + 
    scale_colour_viridis_d() + theme(legend.position = "none")
NM.dsm.rf.tax.pd.es5 <- NM.dsm.rf.tax.results %>% filter(.type == "ice" & 
    .class == "ES5") %>% group_by(.id) %>% group_by(esite) %>% ggplot(aes(x = TAXOUSDA_250m, 
    y = .y.hat, group = .id, colour = esite)) + geom_line() + scale_y_continuous("Probability") + 
    scale_colour_viridis_d() + theme(legend.position = "none")
NM.dsm.rf.tax.pd.es6 <- NM.dsm.rf.tax.results %>% filter(.type == "ice" & 
    .class == "ES6") %>% group_by(.id) %>% group_by(esite) %>% ggplot(aes(x = TAXOUSDA_250m, 
    y = .y.hat, group = .id, colour = esite)) + geom_line() + scale_y_continuous("Probability") + 
    scale_colour_viridis_d() + theme(legend.position = "none")
NM.dsm.rf.tax.pd.es7 <- NM.dsm.rf.tax.results %>% filter(.type == "ice" & 
    .class == "ES7") %>% group_by(.id) %>% group_by(esite) %>% ggplot(aes(x = TAXOUSDA_250m, 
    y = .y.hat, group = .id, colour = esite)) + geom_line() + scale_y_continuous("Probability") + 
    scale_colour_viridis_d() + theme(legend.position = "none")
NM.dsm.rf.tax.pd.es99 <- NM.dsm.rf.tax.results %>% filter(.type == "ice" & 
    .class == "ES99") %>% group_by(.id) %>% group_by(esite) %>% ggplot(aes(x = TAXOUSDA_250m, 
    y = .y.hat, group = .id, colour = esite)) + geom_line() + scale_y_continuous("Probability") + 
    scale_colour_viridis_d() + theme(legend.position = "none")

NM_dsm_rf_ice <- grid.arrange(NM.dsm.rf.tax.pd.es1, NM.dsm.rf.tax.pd.es2, 
    NM.dsm.rf.tax.pd.es3, NM.dsm.rf.tax.pd.es4, NM.dsm.rf.tax.pd.es5, NM.dsm.rf.tax.pd.es6, 
    NM.dsm.rf.tax.pd.es7, NM.dsm.rf.tax.pd.es99, ncol = 3)
ggsave("/data/data2/data/esgMapping/analysis/figures/NM_dsm_rf_ice.pdf", 
    NM_dsm_rf_ice, width = 10, height = 10, dpi = 300, units = "in")

# Subset so that it only plots observations belonging to each ESG and
# then displays correct and missclassified observations
NM.dsm.rf.tax.pd.es1 <- NM.dsm.rf.tax.results %>% filter(.type == "ice" & 
    .class == "ES1" & esite == "ES1") %>% group_by(.id) %>% group_by(predict) %>% 
    ggplot(aes(x = TAXOUSDA_250m, y = .y.hat, group = .id, colour = predict)) + 
    geom_line() + scale_y_continuous("Probability", limits = c(0, 1)) + 
    scale_color_manual(values = c("red", "black")) + theme(legend.position = "none")
NM.dsm.rf.tax.pd.es2 <- NM.dsm.rf.tax.results %>% filter(.type == "ice" & 
    .class == "ES2" & esite == "ES2") %>% group_by(.id) %>% group_by(predict) %>% 
    ggplot(aes(x = TAXOUSDA_250m, y = .y.hat, group = .id, colour = predict)) + 
    geom_line() + scale_y_continuous("Probability", limits = c(0, 1)) + 
    scale_color_manual(values = c("red", "black")) + theme(legend.position = "none")
NM.dsm.rf.tax.pd.es3 <- NM.dsm.rf.tax.results %>% filter(.type == "ice" & 
    .class == "ES3" & esite == "ES3") %>% group_by(.id) %>% group_by(predict) %>% 
    ggplot(aes(x = TAXOUSDA_250m, y = .y.hat, group = .id, colour = predict)) + 
    geom_line() + scale_y_continuous("Probability", limits = c(0, 1)) + 
    scale_color_manual(values = c("red", "black")) + theme(legend.position = "none")
NM.dsm.rf.tax.pd.es4 <- NM.dsm.rf.tax.results %>% filter(.type == "ice" & 
    .class == "ES4" & esite == "ES4") %>% group_by(.id) %>% group_by(predict) %>% 
    ggplot(aes(x = TAXOUSDA_250m, y = .y.hat, group = .id, colour = predict)) + 
    geom_line() + scale_y_continuous("Probability", limits = c(0, 1)) + 
    scale_color_manual(values = c("red", "black")) + theme(legend.position = "none")
NM.dsm.rf.tax.pd.es5 <- NM.dsm.rf.tax.results %>% filter(.type == "ice" & 
    .class == "ES5" & esite == "ES5") %>% group_by(.id) %>% group_by(predict) %>% 
    ggplot(aes(x = TAXOUSDA_250m, y = .y.hat, group = .id, colour = predict)) + 
    geom_line() + scale_y_continuous("Probability", limits = c(0, 1)) + 
    scale_color_manual(values = c("red", "black")) + theme(legend.position = "none")
NM.dsm.rf.tax.pd.es6 <- NM.dsm.rf.tax.results %>% filter(.type == "ice" & 
    .class == "ES6" & esite == "ES6") %>% group_by(.id) %>% group_by(predict) %>% 
    ggplot(aes(x = TAXOUSDA_250m, y = .y.hat, group = .id, colour = predict)) + 
    geom_line() + scale_y_continuous("Probability", limits = c(0, 1)) + 
    scale_color_manual(values = c("red", "black")) + theme(legend.position = "none")
NM.dsm.rf.tax.pd.es7 <- NM.dsm.rf.tax.results %>% filter(.type == "ice" & 
    .class == "ES7" & esite == "ES7") %>% group_by(.id) %>% group_by(predict) %>% 
    ggplot(aes(x = TAXOUSDA_250m, y = .y.hat, group = .id, colour = predict)) + 
    geom_line() + scale_y_continuous("Probability", limits = c(0, 1)) + 
    scale_color_manual(values = c("red", "black")) + theme(legend.position = "none")
NM.dsm.rf.tax.pd.es99 <- NM.dsm.rf.tax.results %>% filter(.type == "ice" & 
    .class == "ES99" & esite == "ES99") %>% group_by(.id) %>% group_by(predict) %>% 
    ggplot(aes(x = TAXOUSDA_250m, y = .y.hat, group = .id, colour = predict)) + 
    geom_line() + scale_y_continuous("Probability", limits = c(0, 1)) + 
    scale_color_manual(values = c("red", "black")) + theme(legend.position = "none")

NM_dsm_rf_ice.sub <- grid.arrange(NM.dsm.rf.tax.pd.es1, NM.dsm.rf.tax.pd.es2, 
    NM.dsm.rf.tax.pd.es3, NM.dsm.rf.tax.pd.es4, NM.dsm.rf.tax.pd.es5, NM.dsm.rf.tax.pd.es6, 
    NM.dsm.rf.tax.pd.es7, NM.dsm.rf.tax.pd.es99, ncol = 3)
ggsave("/data/data2/data/esgMapping/analysis/figures/NM_dsm_rf_ice.sub.pdf", 
    NM_dsm_rf_ice.sub, width = 10, height = 10, dpi = 300, units = "in")


# Categorical ICE plot

ice.plot.categorical.byclass <- function(R6, filtered.df) {
    p = ggplot(filtered.df, mapping = aes_string(x = R6$feature.name, y = ".y.hat", 
        group = ".id")) + scale_y_continuous(y.axis.label)
    p = p + geom_boxplot(aes_string(group = R6$feature.name))
    rug.dat = cbind(R6$.__enclos_env__$private$sampler$get.x(), data.frame(.y.hat = R6$results$.y.hat[1]), 
        .id = 1)
    rug.dat = rug.dat[sample(1:nrow(rug.dat)), ]
    sides = ifelse(R6$n.features == 2 && R6$feature.type[1] == R6$feature.type[2], 
        "bl", "b")
    p = p + geom_rug(data = rug.dat, alpha = 0.2, sides = sides, position = position_jitter(width = 0.1, 
        height = 0.1))
    # p = p + facet_wrap('.class')
    return(p)
}

NM.dsm.rf.tax.pd.es1 <- NM.dsm.rf.tax.results %>% filter(.type == "ice" & 
    .class == "ES1" & esite == "ES1") %>% group_by(.id) %>% group_by(predict)
NM.dsm.rf.tax.pd.es2 <- NM.dsm.rf.tax.results %>% filter(.type == "ice" & 
    .class == "ES2" & esite == "ES2") %>% group_by(.id) %>% group_by(predict)
NM.dsm.rf.tax.pd.es4 <- NM.dsm.rf.tax.results %>% filter(.type == "ice" & 
    .class == "ES4" & esite == "ES4") %>% group_by(.id) %>% group_by(predict)
NM.dsm.rf.tax.pd.es5 <- NM.dsm.rf.tax.results %>% filter(.type == "ice" & 
    .class == "ES5" & esite == "ES5") %>% group_by(.id) %>% group_by(predict)
NM.dsm.rf.tax.pd.es6 <- NM.dsm.rf.tax.results %>% filter(.type == "ice" & 
    .class == "ES6" & esite == "ES6") %>% group_by(.id) %>% group_by(predict)
NM.dsm.rf.tax.pd.es7 <- NM.dsm.rf.tax.results %>% filter(.type == "ice" & 
    .class == "ES7" & esite == "ES7") %>% group_by(.id) %>% group_by(predict)


NM.dsm.rf.tax.pd.es1.plot <- ice.plot.categorical(NM.dsm.rf.tax.pd, NM.dsm.rf.tax.pd.es1)
NM.dsm.rf.tax.pd.es2.plot <- ice.plot.categorical(NM.dsm.rf.tax.pd, NM.dsm.rf.tax.pd.es2)
NM.dsm.rf.tax.pd.es3.plot <- ice.plot.categorical(NM.dsm.rf.tax.pd, NM.dsm.rf.tax.pd.es3)
NM.dsm.rf.tax.pd.es4.plot <- ice.plot.categorical(NM.dsm.rf.tax.pd, NM.dsm.rf.tax.pd.es4)
NM.dsm.rf.tax.pd.es5.plot <- ice.plot.categorical(NM.dsm.rf.tax.pd, NM.dsm.rf.tax.pd.es5)
NM.dsm.rf.tax.pd.es6.plot <- ice.plot.categorical(NM.dsm.rf.tax.pd, NM.dsm.rf.tax.pd.es6)
NM.dsm.rf.tax.pd.es7.plot <- ice.plot.categorical(NM.dsm.rf.tax.pd, NM.dsm.rf.tax.pd.es7)


NM_dsm_rf_ice.tax.sub <- grid.arrange(NM.dsm.rf.tax.pd.es1.plot, NM.dsm.rf.tax.pd.es2.plot, 
    NM.dsm.rf.tax.pd.es3.plot, NM.dsm.rf.tax.pd.es4.plot, NM.dsm.rf.tax.pd.es5.plot, 
    NM.dsm.rf.tax.pd.es6.plot, NM.dsm.rf.tax.pd.es7.plot, ncol = 3)
ggsave("/data/data2/data/esgMapping/analysis/figures/NM_dsm_rf_tax_ice.sub.pdf", 
    NM_dsm_rf_ice.tax.sub, width = 10, height = 10, dpi = 300, units = "in")





# Categorical ICE plot
p = ggplot(NM.dsm.rf.tax.pd$results[NM.dsm.rf.tax.pd$results$.type == "ice", 
    ], mapping = aes_string(x = NM.dsm.rf.tax.pd$feature.name, y = ".y.hat", 
    group = ".id")) + scale_y_continuous(y.axis.label)
p = p + geom_boxplot(aes_string(group = NM.dsm.rf.tax.pd$feature.name))
aggr = NM.dsm.rf.tax.pd$results[NM.dsm.rf.tax.pd$results$.type == "pdp", 
    ]
p = p + geom_line(data = aggr, mapping = aes_string(x = NM.dsm.rf.tax.pd$feature.name, 
    y = ".y.hat"), size = 2, color = "gold")
p = p + geom_line(data = aggr, mapping = aes_string(x = NM.dsm.rf.tax.pd$feature.name, 
    y = ".y.hat"), size = 1, color = "black")
rug.dat = cbind(NM.dsm.rf.tax.pd$.__enclos_env__$private$sampler$get.x(), 
    data.frame(.y.hat = NM.dsm.rf.tax.pd$results$.y.hat[1]), .id = 1)
rug.dat = rug.dat[sample(1:nrow(rug.dat)), ]
sides = ifelse(NM.dsm.rf.tax.pd$n.features == 2 && NM.dsm.rf.tax.pd$feature.type[1] == 
    NM.dsm.rf.tax.pd$feature.type[2], "bl", "b")
p = p + geom_rug(data = rug.dat, alpha = 0.2, sides = sides, position = position_jitter(width = 0.1, 
    height = 0.1))
p = p + facet_wrap(".class")
p
#---------------------------------------------------------------------------------------------

CO.dsm.mrrtf.pd = Partial$new(CO.dsm.svm, feature = "MRRTF", ice = TRUE, 
    center.at = min(co.esg.dsm.cov.rm$MRRTF))
plot(CO.dsm.mrrtf.pd)
CO.dsm.ndvi.pd.results <- CO.dsm.ndvi.pd$results
CO.dsm.ndvi.pd.results$.id <- as.factor(CO.dsm.ndvi.pd.results$.id)
ES6 <- CO.dsm.ndvi.pd.results %>% filter(.class == "ES6" & .type == "ice" & 
    .id %in% c(CO_es6_list$site)) %>% group_by(.id)
ES6 <- CO.dsm.ndvi.pd$results %>% filter(.class == "ES6" & .type == "ice")
test <- ES6 %>% filter(NDVI_Dec_Mean == max(NDVI_Dec_Mean))

plot_df <- CO.dsm.ndvi.pd$results %>% filter(.type == "ice") %>% group_by(.id)
plot_df <- CO.dsm.ndvi.pd.results %>% filter(.type == "ice" & .class == 
    "ES6" & .id %in% c(CO_es6_list$site)) %>% group_by(.id) %>% plot_ly(x = ~NDVI_Dec_Mean, 
    y = ~.y.hat, type = "scatter", mode = "lines+markers")

plot_df <- CO.dsm.ndvi.pd.results %>% filter(.type == "ice" & .class == 
    "ES6" & .id %in% CO_es6_list) %>% group_by(.id) %>% ggplot(aes(x = NDVI_Dec_Mean, 
    y = .y.hat, group = .id)) + geom_line() + geom_point() + theme_minimal()

plot_df <- CO.dsm.ndvi.pd.results %>% filter(.type == "ice" & .class == 
    "ES6" & (!(.id %in% c(CO_es6_list$site)))) %>% group_by(.id) %>% ggplot(aes(x = NDVI_Dec_Mean, 
    y = .y.hat, group = .id)) + geom_line() + geom_point() + theme_minimal()


# show plots
plot_df$plots

CO.dsm.ndvi.pd = Partial$new(CO.dsm.rf, feature = "NDVI_Dec_Mean", ice = TRUE, 
    center.at = min(co.esg.dsm.cov.rm$NDVI_Dec_Mean))
plot(CO.dsm.ndvi.pd)
# Partial dependence plots using mlr package
CO.dsm.mrrtf.pd = generatePartialDependenceData(CO_dsm_train.svm.prob, 
    CO_dsm_var, "MRRTF")
plotPartialDependence(CO.dsm.mrrtf.pd, data = getTaskData(CO_dsm_var))

# CO PDP: Top 4
CO.dsm.svm.pdp = generatePartialDependenceData(CO_dsm_train.svm.prob, CO_dsm_var, 
    c("MRRTF", "calp3", "nwness", "AWCtS_M_sl5_250m", "BLDFIE_M_sl1_250m", 
        "CLYPPT_M_sl7_250m"), fun = mean)
plotPartialDependence(CO.dsm.svm.pdp, data = getTaskData(CO_dsm_var))
ggsave("/data/data2/data/esgMapping/analysis/figures/CO_dsm_svm_pdp.pdf")

CO.dsm.rf.pdp = generatePartialDependenceData(CO_dsm_train.rf.prob, CO_dsm_var, 
    c("NDVI_Dec_Mean", "relht64", "LST_Day_Nov_Mean", "relht16", "TAXOUSDA_250m", 
        "NDVI_Feb_Mean"), fun = mean)
plotPartialDependence(CO.dsm.rf.pdp, data = getTaskData(CO_dsm_var))
ggsave("/data/data2/data/esgMapping/analysis/figures/CO_dsm_rf_pdp.pdf")

CO.dsm.xgb.pdp = generatePartialDependenceData(CO_dsm_train.xgb.prob, CO_dsm_var, 
    c("TAXOUSDA_250m", "relht32", "NDVI_Feb_Mean", "NDVI_Feb_std"), fun = mean)
plotPartialDependence(CO.dsm.xgb.pdp, data = getTaskData(CO_dsm_var))
ggsave("/data/data2/data/esgMapping/analysis/figures/CO_dsm_xgb_pdp.pdf")

CO.dsm.rf.int = generatePartialDependenceData(CO_dsm_train.rf.prob, CO_dsm_var, 
    c("NAMrad_K", "NAMrad_Th"), interaction = TRUE)
plotPartialDependence(CO.dsm.rf.int, facet = "NAMrad_Th")

```

## Model dependent method for feature importance
```{r eval=FALSE}
############################################################################################################################################
#-------------------Feature Importance---------------------------------

#---------------------------------------------------------------------------------------  
# #Model dependent method for feature importance 
# 
#   #-------Filter methods for feature selection and importance
#     # NM_abiotic_IG = generateFilterValuesData(NM_abiotic_var, method = c("information.gain"))
#     # plotFilterValues(NM_abiotic_IG)
#     #
#     # NM_abiotic_RF = generateFilterValuesData(NM_abiotic_var, method = c("randomForest.importance"))
#     # plotFilterValues(NM_abiotic_RF)
#   
#   #-----svm
#     NM_dsm_var.train.svm = mlr::train(learner = NM_dsm_lrns[[1]],
#                                              task = NM_dsm_var)
#     NM_dsm_svm_FI <-  mlr::getFeatureImportance(NM_dsm_var.train.svm)
#   
#     NM.svm.varImp <- generateFeatureImportanceData(task=NM_dsm_var,
#   
#     ##Backburner for now#######################################################################
#     #rminer approach for calculating variable importance using SA.
#     model <- rminer::fit(esite ~., getTaskData(NM_dsm_var), model="svm")
#     I <- Importance(model, getTaskData(NM_dsm_var),method="sensv")
#     L=list(runs=1,sen=t(I$imp),sresponses=I$sresponses)
#     print(round(I$imp,digits=2))
#     imax=which.max(I$imp)
#     imax
#     mgraph(L,graph="IMP",leg=names(getTaskData(NM_dsm_var)),col="gray",Grid=10)
#     vecplot(I,graph="VEC",xval=1,graph="VEC"(),xval=2,cex=1.2,TC=2,
#             main="VEC curve for x2 influence on y (class B)",xlab="x2")
#   
#   L=list(runs=1,sen=t(I$imp),sresponses=I$sresponses) # create a simple
#   par(mar=c(2.0,2.0,2.0,2.0)) # enlarge PDF margin
#   mgraph(L,graph="IMP",leg=names(cmath),col="gray",Grid=10,PDF="imp-1")
#   txt=paste("VEC curve for",names(cmath)[imax],"influence on class",levels(y)
#   [TC])
#   mgraph(L,graph="VEC",xval=imax,Grid=10,data=cmath[H$tr,],TC=1,main=txt,PDF=
#   "vec-1")
#   
#   
#     library(rminer)
#   M <- fit(y~., data=train, model="svm", kpar=list(sigma=0.10), C=2)
#   svm.imp <- Importance(M, data=train)
#     # ############################################################################################
#   
#   #-----randomForest
#     NM_dsm_var.train.rf = mlr::train(learner = NM_dsm_lrns[[2]],
#                                              task = NM_dsm_var)
#     NM_dsm_rf_FI <-  mlr::getFeatureImportance(NM_dsm_var.train.rf, type=2)
#   
#         # #randomForest variable importance calcualtion and plotting
#         # varImpPlot(getLearnerModel(NM_abiotic_var.train.rf), type=2)
#   
#   #-----xgboost
#     NM_dsm_var.train.xgboost = train(NM_dsm_lrns[[3]],
#                                              task = NM_dsm_var)
#     NM_dsm_xgboost_FI <-  getFeatureImportance(NM_dsm_var.train.xgboost)
#   
#         # #Plotting method using xgb.ggplot.importance function
#         # NM_abiotic_xgboost_FI_mlr.dt <- data.table:::data.table(colnames(NM_abiotic_xgboost_FI_mlr$res), t(NM_abiotic_xgboost_FI_mlr$res))
#         # names(NM_abiotic_xgboost_FI_mlr.dt)<- c("Feature", "Gain")
#         # xgb.ggplot.importance(importance_matrix = NM_abiotic_xgboost_FI_mlr.dt,
#         #                       top_n = 40,
#         #                       n_clusters = 1)
#   
#   
#         #------------------Code from XGBOOST to calculate and plot variable importance
#         # #Produces same result as plotting the output from "getFeatureImportance
#         # library(xgboost)
#         # NM_abiotic_xgboost_FI <-  getLearnerModel(NM_abiotic_var.train.rf)
#         #   xgb.importance(getTaskFeatureNames(NM_abiotic_var.filtered.task), model = getLearnerModel(NM_abiotic_var.train.xgboost))
#         # xgb.ggplot.importance(
#         #   importance_matrix = NM_abiotic_xgboost_FI,
#         #   rel_to_first = TRUE,
#         #   top_n = 40,
#         #   n_clusters = 1
#         # )
#         # xgb.ggplot.importance(importance_matrix = NM_abiotic_xgboost_FI,
#         #                       top_n = 40,
#         #                       n_clusters = 1)
  
```




## Raster predict for CO and NM DSM models
```{r eval=FALSE}
detach("package:caret", unload = TRUE)
# CO raster predictions
#---------------------------------------------------------------------------------------
# create raster brick of CO covariate data
co.mask <- "/data/data2/data/esgMapping/analysis/data/derived_data/raster_covariates/CO_mask"
co.raster.list <- preStack(path = co.mask, pattern = ".tif")
co.cov.brick <- brick(stack(co.raster.list, bands = 1), filename = "/data/data2/data/esgMapping/analysis/data/derived_data/CO_Covariate_Brick.grd")
co.cov.brick <- brick("/data/data2/data/esgMapping/analysis/data/derived_data/CO_Covariate_Brick.grd")

# Need to create hyper-temp bricks, one for each variable, e.g.,
# co.ndvi.brick, co.lst.day.brick...... then write new raster.predict
# function that can read in several imput brick, extract a chunk, join
# them and then predict. That way you don't need to create one giant
# brick that will crash the system.

# Predict modeled surfaces for DSM database
CO_svm_dsm_prediction <- mlr.raster.predict.run(x = co.cov.brick, filename = "/data/data2/data/esgMapping/analysis/data/derived_data/CO_svm_dsm_prediction.tif", 
    model = CO_dsm_train.svm, block_n = 120, mask = CO_raster, layers = 1)
CO_svm_dsm_prediction <- raster("/data/data2/data/esgMapping/analysis/data/derived_data/CO_svm_dsm_prediction.tif")
CO_rf_dsm_prediction <- mlr.raster.predict.run(x = co.cov.brick, filename = "/data/data2/data/esgMapping/analysis/data/derived_data/CO_rf_dsm_prediction.tif", 
    model = CO_dsm_train.rf, block_n = 120, mask = CO_raster, layers = 1)
CO_rf_dsm_prediction <- raster("/data/data2/data/esgMapping/analysis/data/derived_data/CO_xgb_dsm_prediction.tif")
CO_xgb_dsm_prediction <- mlr.raster.predict.run(x = co.cov.brick, filename = "/data/data2/data/esgMapping/analysis/data/derived_data/CO_xgb_dsm_prediction.tif", 
    model = CO_dsm_train.xgb, block_n = 120, mask = CO_raster, layers = 1)
CO_xgb_dsm_prediction <- raster("/data/data2/data/esgMapping/analysis/data/derived_data/CO_xgb_dsm_prediction.tif")
CO_ens_dsm_prediction <- mlr.raster.predict.run(x = co.cov.brick, filename = "/data/data2/data/esgMapping/analysis/data/derived_data/CO_ens_dsm_prediction.tif", 
    model = CO_dsm_train.ens, block_n = 120, mask = CO_raster, layers = 9)  #1 layer for each class plus 1 for the final response

# abiotic prediction
CO_ens_abiotic_prediction <- mlr.raster.predict.run(x = co.cov.brick, filename = "/data/data2/data/esgMapping/analysis/data/derived_data/CO_ens_abiotic_prediction.tif", 
    model = CO_abiotic_train.ens, block_n = 120, mask = CO_raster, layers = 9)

#---------------------------------------Predict model probabilities
CO_svm_dsm_prediction_prob <- mlr.raster.predict.run(x = co.cov.brick, 
    filename = "/data/data2/data/esgMapping/analysis/data/derived_data/CO_svm_dsm_prediction_prob.tif", 
    model = CO_dsm_train.svm.prob, block_n = 120, mask = CO_raster, layers = 9)

CO_rf_dsm_prediction_prob <- mlr.raster.predict.run(x = co.cov.brick, filename = "/data/data2/data/esgMapping/analysis/data/derived_data/CO_rf_dsm_prediction_prob.tif", 
    model = CO_dsm_train.rf.prob, block_n = 120, mask = CO_raster, layers = 9)

CO_xgb_dsm_prediction_prob <- mlr.raster.predict.run(x = co.cov.brick, 
    filename = "/data/data2/data/esgMapping/analysis/data/derived_data/CO_xgb_dsm_prediction_prob.tif", 
    model = CO_dsm_train.xgb.prob, block_n = 120, mask = CO_raster, layers = 9)

# lookup key
unique(co.points@data[10:11])

# Plot prediction probabilites
red <- colorRampPalette(c("tomato4", "yellow2"))
blue <- colorRampPalette(c("green2", "blue2"))
CairoPDF("/data/data2/data/esgMapping/analysis/figures/CO_ESG_RF_class_probabilites.pdf", 
    8, 8, bg = "transparent")
spplot(CO_rf_dsm_prediction_prob[[1:8]], names.attr = c("Shallow shrubland", 
    "Saline uplands", "Finer shrublands", "Saline hills", "Bottoms and flats", 
    "Deep rocky", "Sandy Grasslands", "Outcrops and slopes"), strip = strip.custom(style = 1, 
    bg = "white"), par.strip.text = list(cex = 0.7), col.regions = c(red(20), 
    blue(20)), layout = c(4, 2), cuts = 30, contour = F, labels = F, pretty = T, 
    maxpixels = 1e+05, colorkey = list(space = "top", width = 0.8), at = seq(1, 
        0, length = 40))
dev.off()


#--------------------------------------Confusion Index
## Calculate confusion index and most probable class
CO_svm_dsm_CI <- CI.calc.run(CO_svm_dsm_prediction_prob, filename = "/data/data2/data/esgMapping/analysis/data/derived_data/CO_svm_dsm_CI.tif")
CO_rf_dsm_CI <- CI.calc.run(CO_rf_dsm_prediction_prob, filename = "/data/data2/data/esgMapping/analysis/data/derived_data/CO_rf_dsm_CI.tif")
CO_xgb_dsm_CI <- CI.calc.run(CO_xgb_dsm_prediction_prob, filename = "/data/data2/data/esgMapping/analysis/data/derived_data/CO_xgb_dsm_CI.tif")
CO_ens_dsm_CI <- CI.calc.run(CO_ens_dsm_prediction, filename = "/data/data2/data/esgMapping/analysis/data/derived_data/CO_ens_dsm_CI.tif")


# Plot confusion index
CairoPDF("/data/data2/data/esgMapping/analysis/figures/CO_ESG_SVM_confusion_index.pdf", 
    8, 8, bg = "transparent")
levelplot(CO_svm_dsm_CI, par.settings = RdBuTheme, maxpixels = 8e+05)
dev.off()
CairoPDF("/data/data2/data/esgMapping/analysis/figures/CO_ESG_RF_confusion_index.pdf", 
    8, 8, bg = "transparent")
levelplot(CO_rf_dsm_CI, par.settings = RdBuTheme, maxpixels = 8e+05)
dev.off()
CairoPDF("/data/data2/data/esgMapping/analysis/figures/CO_ESG_XGB_confusion_index.pdf", 
    8, 8, bg = "transparent")
levelplot(CO_xgb_dsm_CI, par.settings = RdBuTheme, maxpixels = 8e+05)
dev.off()
CairoPDF("/data/data2/data/esgMapping/analysis/figures/CO_ESG_ENS_confusion_index.pdf", 
    6, 6, bg = "transparent")
levelplot(CO_ens_dsm_CI, par.settings = RdBuTheme, maxpixels = 8e+05)
dev.off()


# Standardized Shannon Entropy Index
CO_svm_dsm_SSEI <- SSEI.calc.run(CO_svm_dsm_prediction_prob[[-9]], filename = "/data/data2/data/esgMapping/analysis/data/derived_data/CO_svm_dsm_SSEI.tif")
CO_rf_dsm_SSEI <- SSEI.calc.run(CO_rf_dsm_prediction_prob[[-9]], filename = "/data/data2/data/esgMapping/analysis/data/derived_data/CO_rf_dsm_SSEI.tif")
CO_xgb_dsm_SSEI <- SSEI.calc.run(CO_xgb_dsm_prediction_prob[[-9]], filename = "/data/data2/data/esgMapping/analysis/data/derived_data/CO_xgb_dsm_SSEI.tif")
CO_ens_dsm_SSEI <- SSEI.calc.run(CO_ens_dsm_prediction[[-9]], filename = "/data/data2/data/esgMapping/analysis/data/derived_data/CO_ens_dsm_SSEI.tif")

# Standardized Shannon Entropy Index
CairoPDF("/data/data2/data/esgMapping/analysis/figures/CO_ESG_SVM_SSEI.pdf", 
    6, 6, bg = "transparent")
levelplot(CO_svm_dsm_SSEI, par.settings = RdBuTheme, maxpixels = 8e+05, 
    margin = FALSE)
dev.off()
CairoPDF("/data/data2/data/esgMapping/analysis/figures/CO_ESG_RF_SSEI.pdf", 
    6, 6, bg = "transparent")
levelplot(CO_rf_dsm_SSEI, par.settings = RdBuTheme, maxpixels = 8e+05, 
    margin = FALSE)
dev.off()
CairoPDF("/data/data2/data/esgMapping/analysis/figures/CO_ESG_XGB_SSEI.pdf", 
    6, 6, bg = "transparent")
levelplot(CO_xgb_dsm_SSEI, par.settings = RdBuTheme, maxpixels = 8e+05, 
    margin = FALSE)
dev.off()
CairoPDF("/data/data2/data/esgMapping/analysis/figures/CO_ESG_ENS_SSEI.pdf", 
    6, 6, bg = "transparent")
levelplot(CO_ens_dsm_SSEI, par.settings = RdBuTheme, maxpixels = 8e+05, 
    margin = FALSE)
dev.off()

# Theoretical map accuracy
CO_ens_dsm_prediction.maxP <- calc(CO_ens_dsm_prediction[[1:8]], max)
CO_ens_dsm_TheoreticalMapAccuracy <- cellStats(CO_ens_dsm_prediction.maxP, 
    mean)
#---------------------------------------------------------------------------------------
# Color palette used in rangelands article
cbPalette <- c("#00a884", "#beffe7", "#ffa77f", "#ffffbf", "#737301", "#fe0000", 
    "#0071fe", "#732500")
# Plot SVM
CO_svm_dsm_plot <- gplot(CO_svm_dsm_prediction, maxpixels = 8e+05) + geom_raster(aes(fill = factor(value))) + 
    coord_equal() + labs(x = "Long", y = "Lat", fill = "ESG") + ggtitle("Ecological Site Group") + 
    scale_fill_manual(values = cbPalette)
CO_svm_dsm_plot
ggsave(CO_svm_dsm_plot, file = "/data/data2/data/esgMapping/analysis/figures/CO_svm_dsm_plot.pdf", 
    width = 6, height = 6)
ggsave(CO_svm_dsm_plot, file = "/data/data2/data/esgMapping/analysis/figures/CO_svm_dsm_plot.png", 
    width = 6, height = 6, type = "cairo-png")

# Plot RF
CO_rf_dsm_plot <- gplot(CO_rf_dsm_prediction, maxpixels = 8e+05) + geom_raster(aes(fill = factor(value))) + 
    coord_equal() + labs(x = "Long", y = "Lat", fill = "ESG") + ggtitle("Ecological Site Group") + 
    scale_fill_manual(values = cbPalette)
CO_rf_dsm_plot
ggsave(CO_rf_dsm_plot, file = "/data/data2/data/esgMapping/analysis/figures/CO_rf_dsm_plot.pdf", 
    width = 6, height = 6)
ggsave(CO_rf_dsm_plot, file = "/data/data2/data/esgMapping/analysis/figures/CO_rf_dsm_plot.png", 
    width = 6, height = 6, type = "cairo-png")

# Plot xgb
CO_xgb_dsm_plot <- gplot(CO_xgb_dsm_prediction, maxpixels = 8e+05) + geom_raster(aes(fill = factor(value))) + 
    coord_equal() + labs(x = "Long", y = "Lat", fill = "ESG") + ggtitle("Ecological Site Group") + 
    scale_fill_manual(values = cbPalette)
CO_xgb_dsm_plot
ggsave(CO_xgb_dsm_plot, file = "/data/data2/data/esgMapping/analysis/figures/CO_xgb_dsm_plot.pdf", 
    width = 6, height = 6)
ggsave(CO_xgb_dsm_plot, file = "/data/data2/data/esgMapping/analysis/figures/CO_xgb_dsm_plot.png", 
    width = 6, height = 6, type = "cairo-png")

# Plot ENS
CO_ens_dsm_plot <- gplot(CO_ens_dsm_prediction[[9]], maxpixels = 8e+05) + 
    geom_raster(aes(fill = factor(value))) + coord_equal() + labs(x = "Long", 
    y = "Lat", fill = "ESG") + ggtitle("Ecological Site Group") + scale_fill_manual(values = cbPalette)
CO_ens_dsm_plot
ggsave(CO_ens_dsm_plot, file = "/data/data2/data/esgMapping/analysis/figures/CO_ens_dsm_plot.pdf", 
    width = 6, height = 6)
ggsave(CO_ens_dsm_plot, file = "/data/data2/data/esgMapping/analysis/figures/CO_ens_dsm_plot.png", 
    width = 6, height = 6, type = "cairo-png")

# Plot ENS
CO_ens_abiotic_plot <- gplot(CO_ens_abiotic_prediction[[9]], maxpixels = 8e+05) + 
    geom_raster(aes(fill = factor(value))) + coord_equal() + labs(x = "Long", 
    y = "Lat", fill = "ESG") + ggtitle("Ecological Site Group") + scale_fill_manual(values = cbPalette)
CO_ens_abiotic_plot
ggsave(CO_ens_abiotic_plot, file = "/data/data2/data/esgMapping/analysis/figures/CO_ens_abiotic_plot.pdf", 
    width = 8, height = 8)
ggsave(CO_ens_abiotic_plot, file = "/data/data2/data/esgMapping/analysis/figures/CO_ens_abiotic_plot.png", 
    width = 8, height = 8, type = "cairo-png")


#---------------------------------------------------------------------------------------


#---------------------------------------------------------------------------------------
# create raster brick of NM covariate data
nm.mask <- "/data/data2/data/esgMapping/analysis/data/derived_data/raster_covariates/NM_mask"
# aeroradiometric grids have a large hole within study area due to
# White Sands, therefore removed
nm.raster.list <- preStack(path = nm.mask, pattern = ".tif")[-170:-173]
nm.cov.brick <- brick(stack(nm.raster.list, bands = 1), filename = "/data/data2/data/esgMapping/analysis/data/derived_data/NM_Covariate_Brick.grd")
nm.cov.brick <- brick("/data/data2/data/esgMapping/analysis/data/derived_data/NM_Covariate_Brick.grd")
# NM predict modeled surfaces
NM_svm_dsm_prediction <- mlr.raster.predict.run(x = nm.cov.brick, filename = "/data/data2/data/esgMapping/analysis/data/derived_data/NM_svm_dsm_prediction.tif", 
    model = NM_dsm_train.svm, block_n = 120, mask = NM_raster, layers = 1)

NM_rf_dsm_prediction <- mlr.raster.predict.run(x = nm.cov.brick, filename = "/data/data2/data/esgMapping/analysis/data/derived_data/NM_rf_dsm_prediction.tif", 
    model = NM_dsm_train.rf, block_n = 120, mask = NM_raster, layers = 1)

NM_xgb_dsm_prediction <- mlr.raster.predict.run(x = nm.cov.brick, filename = "/data/data2/data/esgMapping/analysis/data/derived_data/NM_xgb_dsm_prediction.tif", 
    model = NM_dsm_train.xgb, block_n = 120, mask = NM_raster, layers = 1)

NM_ens_dsm_prediction <- mlr.raster.predict.run(x = nm.cov.brick, filename = "/data/data2/data/esgMapping/analysis/data/derived_data/NM_ens_dsm_prediction.tif", 
    model = NM_dsm_train.ens, block_n = 120, mask = NM_raster, layers = 8)


#---------------------------------------Predict model probabilities
NM_svm_dsm_prediction_prob <- mlr.raster.predict.run(x = nm.cov.brick, 
    filename = "/data/data2/data/esgMapping/analysis/data/derived_data/NM_svm_dsm_prediction_prob.tif", 
    model = NM_dsm_train.svm.prob, block_n = 120, mask = NM_raster, layers = 8)

NM_rf_dsm_prediction_prob <- mlr.raster.predict.run(x = nm.cov.brick, filename = "/data/data2/data/esgMapping/analysis/data/derived_data/NM_rf_dsm_prediction_prob.tif", 
    model = NM_dsm_train.rf.prob, block_n = 120, mask = NM_raster, layers = 8)

NM_xgb_dsm_prediction_prob <- mlr.raster.predict.run(x = nm.cov.brick, 
    filename = "/data/data2/data/esgMapping/analysis/data/derived_data/NM_xgb_dsm_prediction_prob.tif", 
    model = NM_dsm_train.xgb.prob, block_n = 120, mask = NM_raster, layers = 8)

# lookup key
unique(nm.points@data[14:15])

# Plot prediction probabilites
red <- colorRampPalette(c("tomato4", "yellow2"))
blue <- colorRampPalette(c("green2", "blue2"))
CairoPDF("/data/data2/data/esgMapping/analysis/figures/NM_ESG_RF_class_probabilites.pdf", 
    8, 8, bg = "transparent")
spplot(NM_rf_dsm_prediction_prob[[1:7]], names.attr = c("Gravelly-Calcic", 
    "Loamy-Clayey", "Bedrock and Colluvium", "Bottomland", "Sandy", "Deep sand", 
    "Gypsic"), strip = strip.custom(style = 1, bg = "white"), par.strip.text = list(cex = 0.7), 
    col.regions = c(red(20), blue(20)), layout = c(4, 2), cuts = 30, contour = F, 
    labels = F, pretty = T, maxpixels = 1e+05, colorkey = list(space = "top", 
        width = 0.8), at = seq(1, 0, length = 40))
dev.off()


#--------------------------------------Confusion Index
## Calculate confusion index and most probable class
NM_svm_dsm_CI <- CI.calc.run(NM_svm_dsm_prediction_prob, filename = "/data/data2/data/esgMapping/analysis/data/derived_data/NM_svm_dsm_CI.tif")
NM_rf_dsm_CI <- CI.calc.run(NM_rf_dsm_prediction_prob, filename = "/data/data2/data/esgMapping/analysis/data/derived_data/NM_rf_dsm_CI.tif")
NM_xgb_dsm_CI <- CI.calc.run(NM_xgb_dsm_prediction_prob, filename = "/data/data2/data/esgMapping/analysis/data/derived_data/NM_xgb_dsm_CI.tif")
NM_ens_dsm_CI <- CI.calc.run(NM_ens_dsm_prediction, filename = "/data/data2/data/esgMapping/analysis/data/derived_data/NM_ens_dsm_CI.tif")


# Plot confusion index
CairoPDF("/data/data2/data/esgMapping/analysis/figures/NM_ESG_SVM_confusion_index.pdf", 
    8, 8, bg = "transparent")
levelplot(NM_svm_dsm_CI, par.settings = RdBuTheme, maxpixels = 8e+05)
dev.off()
CairoPDF("/data/data2/data/esgMapping/analysis/figures/NM_ESG_RF_confusion_index.pdf", 
    8, 8, bg = "transparent")
levelplot(NM_rf_dsm_CI, par.settings = RdBuTheme, maxpixels = 8e+05)
dev.off()
CairoPDF("/data/data2/data/esgMapping/analysis/figures/NM_ESG_XGB_confusion_index.pdf", 
    8, 8, bg = "transparent")
levelplot(NM_xgb_dsm_CI, par.settings = RdBuTheme, maxpixels = 8e+05)
dev.off()
CairoPDF("/data/data2/data/esgMapping/analysis/figures/NM_ESG_ENS_confusion_index.pdf", 
    8, 8, bg = "transparent")
levelplot(NM_ens_dsm_CI, par.settings = RdBuTheme, maxpixels = 8e+05)
dev.off()

# Standardized Shannon Entropy Index
NM_svm_dsm_SSEI <- SSEI.calc.run(NM_svm_dsm_prediction_prob[[-8]], filename = "/data/data2/data/esgMapping/analysis/data/derived_data/NM_svm_dsm_SSEI.tif")
NM_rf_dsm_SSEI <- SSEI.calc.run(NM_rf_dsm_prediction_prob[[-8]], filename = "/data/data2/data/esgMapping/analysis/data/derived_data/NM_rf_dsm_SSEI.tif")
NM_xgb_dsm_SSEI <- SSEI.calc.run(NM_xgb_dsm_prediction_prob[[-8]], filename = "/data/data2/data/esgMapping/analysis/data/derived_data/NM_xgb_dsm_SSEI.tif")
NM_ens_dsm_SSEI <- SSEI.calc.run(NM_ens_dsm_prediction[[-8]], filename = "/data/data2/data/esgMapping/analysis/data/derived_data/NM_ens_dsm_SSEI.tif")

# Scaled Shannon Entropy Index
CairoPDF("/data/data2/data/esgMapping/analysis/figures/NM_ESG_SVM_SSEI.pdf", 
    6, 6, bg = "transparent")
levelplot(NM_svm_dsm_SSEI, par.settings = RdBuTheme, maxpixels = 8e+05, 
    margin = FALSE)
dev.off()
CairoPDF("/data/data2/data/esgMapping/analysis/figures/NM_ESG_RF_SSEI.pdf", 
    6, 6, bg = "transparent")
levelplot(NM_rf_dsm_SSEI, par.settings = RdBuTheme, maxpixels = 8e+05, 
    margin = FALSE)
dev.off()
CairoPDF("/data/data2/data/esgMapping/analysis/figures/NM_ESG_XGB_SSEI.pdf", 
    6, 6, , bg = "transparent")
levelplot(NM_xgb_dsm_SSEI, par.settings = RdBuTheme, maxpixels = 8e+05, 
    margin = FALSE)
dev.off()
CairoPDF("/data/data2/data/esgMapping/analysis/figures/NM_ESG_ENS_SSEI.pdf", 
    6, 6, bg = "transparent")
levelplot(NM_ens_dsm_SSEI, par.settings = RdBuTheme, maxpixels = 8e+05, 
    margin = FALSE)
dev.off()

# Theoretical map accuracy
NM_ens_dsm_prediction.maxP <- calc(NM_ens_dsm_prediction[[1:7]], max)
NM_ens_dsm_TheoreticalMapAccuracy <- cellStats(NM_ens_dsm_prediction.maxP, 
    mean)


#---------------------------------------------------------------------------------------
# Plot SVM
NM_svm_dsm_plot <- gplot(NM_svm_dsm_prediction, maxpixels = 8e+05) + geom_raster(aes(fill = factor(value))) + 
    coord_equal() + labs(x = "Long", y = "Lat", fill = "ESG") + ggtitle("Ecological Site Group") + 
    scale_fill_manual(values = cbPalette)
# NM_svm_dsm_plot
ggsave(NM_svm_dsm_plot, file = "/data/data2/data/esgMapping/analysis/figures/NM_svm_dsm_plot.pdf", 
    width = 6, height = 6)
ggsave(NM_svm_dsm_plot, file = "/data/data2/data/esgMapping/analysis/figures/NM_svm_dsm_plot.png", 
    width = 6, height = 6, type = "cairo-png")

# Plot RF
NM_rf_dsm_plot <- gplot(NM_rf_dsm_prediction, maxpixels = 8e+05) + geom_raster(aes(fill = factor(value))) + 
    coord_equal() + labs(x = "Long", y = "Lat", fill = "ESG") + ggtitle("Ecological Site Group") + 
    scale_fill_manual(values = cbPalette)
# NM_rf_dsm_plot
ggsave(NM_rf_dsm_plot, file = "/data/data2/data/esgMapping/analysis/figures/NM_rf_dsm_plot.pdf", 
    width = 6, height = 6)
ggsave(NM_rf_dsm_plot, file = "/data/data2/data/esgMapping/analysis/figures/NM_rf_dsm_plot.png", 
    width = 6, height = 6, type = "cairo-png")

# Plot xgb
NM_xgb_dsm_plot <- gplot(NM_xgb_dsm_prediction, maxpixels = 8e+05) + geom_raster(aes(fill = factor(value))) + 
    coord_equal() + labs(x = "Long", y = "Lat", fill = "ESG") + ggtitle("Ecological Site Group") + 
    scale_fill_manual(values = cbPalette)
# pred_plot
ggsave(NM_xgb_dsm_plot, file = "/data/data2/data/esgMapping/analysis/figures/NM_xgb_dsm_plot.pdf", 
    width = 6, height = 6)
ggsave(NM_xgb_dsm_plot, file = "/data/data2/data/esgMapping/analysis/figures/NM_xgb_dsm_plot.png", 
    width = 6, height = 6, type = "cairo-png")

# Plot ENS
NM_ens_dsm_plot <- gplot(NM_ens_dsm_prediction[[8]], maxpixels = 8e+05) + 
    geom_raster(aes(fill = factor(value))) + coord_equal() + labs(x = "Long", 
    y = "Lat", fill = "ESG") + ggtitle("Ecological Site Group") + scale_fill_manual(values = cbPalette)
# NM_ens_dsm_plot
ggsave(NM_ens_dsm_plot, file = "/data/data2/data/esgMapping/analysis/figures/NM_ens_dsm_plot.pdf", 
    width = 6, height = 6)
ggsave(NM_ens_dsm_plot, file = "/data/data2/data/esgMapping/analysis/figures/NM_ens_dsm_plot.png", 
    width = 6, height = 6, type = "cairo-png")
#---------------------------------------------------------------------------------------


#---------------------------------------------------------------------------------------
# save.image('/data/data2/data/esgMapping/R/CO_NM_ESG_modeling.RData')
load("/data/data2/data/esgMapping/R/CO_NM_ESG_modeling.RData")
#---------------------------------------------------------------------------------------
```





## ESG class distribution
```{r eval=FALSE}
# look at ESG class distribution
co.esite.val.dist <- plyr::count(co.validation.points.covariates[, 2])
par(mar = c(10.5, 4, 3.5, 4))
mp <- barplot(co.esite.val.dist$freq, axes = FALSE, axisnames = FALSE)
text(mp, par("usr")[3], labels = co.esite.val.dist$x, srt = 45, adj = c(1.1, 
    1.1), xpd = TRUE, cex = 0.9)
axis(2)

nm.esite.val.dist <- plyr::count(nm.validation.points.covariates[, 2])
par(mar = c(10.5, 4, 3.5, 4))
mp <- barplot(nm.esite.val.dist$freq, axes = FALSE, axisnames = FALSE)
text(mp, par("usr")[3], labels = nm.esite.val.dist$x, srt = 45, adj = c(1.1, 
    1.1), xpd = TRUE, cex = 0.9)
axis(2)


```


## External Cross-validation
```{r eval=FALSE}
#---------------External Cross-validation
#----External validation load in external validation points and predict on them
co.validation.points.covariates
nm.validation.points.covariates <- nm.validation.points.covariates.narm
# modify level b/c missing two for CO
levels(co.validation.points.covariates[, 2]) <- c(levels(co.validation.points.covariates[, 
    2]), "ES1", "ES6")

library(purrr)
cf_extract <- function(model, data) {
    mod <- predict(model, newdata = data[, model$features])
    cf <- confusionMatrix(mod$data$response, data[, 2])
    return(cf$overall)
}

# CO create list of models to run in loop
datasub <- c("all", "hyper", "ndvi", "abiotic", "sg", "dsm")
CO.models <- data.frame()
for (i in 1:length(datasub)) {
    CO.models <- bind_rows(CO.models, data.frame(paste0("CO_", datasub[i], 
        "_train.svm"), paste0("CO_", datasub[i], "_train.rf"), paste0("CO_", 
        datasub[i], "_train.xgb"), paste0("CO_", datasub[i], "_train.ens")))
}
CO.models <- as.vector(t(CO.models))


cf_results <- data.frame()
for (i in 1:length(CO.models)) {
    ext.res <- cf_extract(get(CO.models[i]), data = co.validation.points.covariates)
    ext.res <- ext.res %>% data.frame() %>% t() %>% set_names(c("Accuracy", 
        "Kappa", "AccuracyLower", "AccuracyUpper", "AccuracyNull", "AccuracyPValue", 
        "McnemarPValue"))
    cf_results <- bind_rows(cf_results, ext.res)
}

CO_ext_val_accuracy <- bind_cols(CO.class.accuracy[, 1:2], cf_results)

ESG.class.plot(data = CO_ext_val_accuracy, class = 3, title = "MLRA 35 ESG Ext-Validation Accuracy", 
    filename = "CO_Model_ExtVal_Accuracy", scale = 1)
ESG.class.plot(data = CO_ext_val_accuracy, class = 3, title = "MLRA 35 ESG Ext-Validation Accuracy", 
    filename = "CO_Model_ExtVal_Accuracy", scale = 0.6)

# Plot
ggplot(CO_ext_val_accuracy, aes(x = Data, y = Accuracy)) + geom_jitter(aes(colour = factor(Model)), 
    size = 4, width = 0.2, height = 0) + # geom_point(col='tomato2', size=3) + # Draw points
geom_segment(aes(x = Data, xend = Data, y = 0.32, yend = 0.56), linetype = "dashed", 
    size = 0.1) + # coord_flip() + # Draw dashed lines
ylab("Accuracy") + xlab("Dataset") + # coord_flip() + # Draw dashed lines
labs(title = "MLRA 35 ESG External Model Accuracy", color = "Model")
ggsave("/data/data2/data/esgMapping/analysis/figures/CO_external_model_comparison5.pdf", 
    width = 4.3, height = 2.6)


# CO DSM ENS
CO_dsm_ens_extVal <- predict(get(CO.models[24]), newdata = co.validation.points.covariates[, 
    get(CO.models[24])$features])

# NM create list of models to run in loop
datasub <- c("all", "hyper", "ndvi", "abiotic", "sg", "dsm")
NM.models <- data.frame()
for (i in 1:length(datasub)) {
    NM.models <- bind_rows(NM.models, data.frame(paste0("NM_", datasub[i], 
        "_train.svm"), paste0("NM_", datasub[i], "_train.rf"), paste0("NM_", 
        datasub[i], "_train.xgb"), paste0("NM_", datasub[i], "_train.ens")))
}
NM.models <- as.vector(t(NM.models))


cf_results <- data.frame()
for (i in 1:length(NM.models)) {
    ext.res <- cf_extract(get(NM.models[i]), data = nm.validation.points.covariates)
    ext.res <- ext.res %>% data.frame() %>% t() %>% set_names(c("Accuracy", 
        "Kappa", "AccuracyLower", "AccuracyUpper", "AccuracyNull", "AccuracyPValue", 
        "McnemarPValue"))
    cf_results <- bind_rows(cf_results, ext.res)
}

NM_ext_val_accuracy <- bind_cols(NM.class.accuracy[, 1:2], cf_results)

ESG.class.plot(data = NM_ext_val_accuracy, class = 3, title = "MLRA 42 ESG Ext-Validation Accuracy", 
    filename = "NM_Model_ExtVal_Accuracy", scale = 1)
ESG.class.plot(data = NM_ext_val_accuracy, class = 3, title = "MLRA 42 ESG Ext-Validation Accuracy", 
    filename = "NM_Model_ExtVal_Accuracy", scale = 0.6)

# Plot
ggplot(NM_ext_val_accuracy, aes(x = Data, y = Accuracy)) + geom_jitter(aes(colour = factor(Model)), 
    size = 4, width = 0.2, height = 0) + # geom_point(col='tomato2', size=3) + # Draw points
geom_segment(aes(x = Data, xend = Data, y = 0.32, yend = 0.56), linetype = "dashed", 
    size = 0.1) + # coord_flip() + # Draw dashed lines
ylab("Accuracy") + xlab("Dataset") + # coord_flip() + # Draw dashed lines
labs(title = "MLRA 42 ESG External Model Accuracy", color = "Model")
ggsave("/data/data2/data/esgMapping/analysis/figures/NM_external_model_comparison5.pdf", 
    width = 4.3, height = 2.6)


# NM DSM ENS
NM_dsm_ens_extVal <- predict(get(NM.models[24]), newdata = nm.validation.points.covariates[, 
    get(NM.models[24])$features])

#---------------------------------------------------------------------------------------

```





