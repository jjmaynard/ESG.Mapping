<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Jonathan Maynard" />


<title>ESG MODIS Hyper-temporal Image Processing</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->



<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Ecological Site Mapping</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Overview</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Code
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="code.html">Modeling Steps</a>
    </li>
    <li>
      <a href="ESG_Covariate_Processing.html">1. Covariate Processing</a>
    </li>
    <li>
      <a href="ESG_HyperTemp_Image_Processing.html">2. Hyper-temporal RS-Image Processing</a>
    </li>
    <li>
      <a href="ESG_MLR_Modeling.html">3. Modeling, Prediction and Validation</a>
    </li>
    <li>
      <a href="ESG_SSURGO_mapping.html">4. Mapping SSURGO ESGs</a>
    </li>
  </ul>
</li>
<li>
  <a href="data.html">Data</a>
</li>
<li>
  <a href="license.html">License</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/jjmaynard/ESG.Mapping">
    <span class="fa fa-github"></span>
     
    Git Repository
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<!-- Add a small amount of space between sections. -->
<style type="text/css">
div.section {
  padding-top: 12px;
}
</style>

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">ESG MODIS Hyper-temporal Image Processing</h1>
<h4 class="author">Jonathan Maynard</h4>
<h4 class="date">Feb 10, 2017</h4>

</div>


<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-report" data-toggle="collapse" data-target="#workflowr-report">
<span class="glyphicon glyphicon-list" aria-hidden="true"></span> workflowr <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span>
</button>
</p>
<div id="workflowr-report" class="collapse">
<ul class="nav nav-tabs">
<li class="active">
<a data-toggle="tab" href="#summary">Summary</a>
</li>
<li>
<a data-toggle="tab" href="#checks"> Checks <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> </a>
</li>
<li>
<a data-toggle="tab" href="#versions">Past versions</a>
</li>
</ul>
<div class="tab-content">
<div id="summary" class="tab-pane fade in active">
<p>
<strong>Last updated:</strong> 2019-06-17
</p>
<p>
<strong>Checks:</strong> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> 6 <span class="glyphicon glyphicon-exclamation-sign text-danger" aria-hidden="true"></span> 0
</p>
<p>
<strong>Knit directory:</strong> <code>ESG.Mapping/</code> <span class="glyphicon glyphicon-question-sign" aria-hidden="true" title="This is the local directory in which the code in this file was executed."> </span>
</p>
<p>
This reproducible <a href="http://rmarkdown.rstudio.com">R Markdown</a> analysis was created with <a
  href="https://github.com/jdblischak/workflowr">workflowr</a> (version 1.3.0). The <em>Checks</em> tab describes the reproducibility checks that were applied when the results were created. The <em>Past versions</em> tab lists the development history.
</p>
<hr>
</div>
<div id="checks" class="tab-pane fade">
<div id="workflowr-checks" class="panel-group">
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRMarkdownfilestronguptodate"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>R Markdown file:</strong> up-to-date </a>
</p>
</div>
<div id="strongRMarkdownfilestronguptodate" class="panel-collapse collapse">
<div class="panel-body">
<p>Great! Since the R Markdown file has been committed to the Git repository, you know the exact version of the code that produced these results.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongEnvironmentstrongempty"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Environment:</strong> empty </a>
</p>
</div>
<div id="strongEnvironmentstrongempty" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! The global environment was empty. Objects defined in the global environment can affect the analysis in your R Markdown file in unknown ways. For reproduciblity it’s best to always run the code in an empty environment.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSeedstrongcodesetseed20190528code"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Seed:</strong> <code>set.seed(20190528)</code> </a>
</p>
</div>
<div id="strongSeedstrongcodesetseed20190528code" class="panel-collapse collapse">
<div class="panel-body">
<p>The command <code>set.seed(20190528)</code> was run prior to running the code in the R Markdown file. Setting a seed ensures that any results that rely on randomness, e.g. subsampling or permutations, are reproducible.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSessioninformationstrongrecorded"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Session information:</strong> recorded </a>
</p>
</div>
<div id="strongSessioninformationstrongrecorded" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! Recording the operating system, R version, and package versions is critical for reproducibility.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongCachestrongnone"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Cache:</strong> none </a>
</p>
</div>
<div id="strongCachestrongnone" class="panel-collapse collapse">
<div class="panel-body">
<p>Nice! There were no cached chunks for this analysis, so you can be confident that you successfully produced the results during this run.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRepositoryversionstrongahrefhttpsgithubcomjjmaynardESGMappingtreef778b156e866ef772ce7426b95ed5d834f12d6eatargetblankf778b15a"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Repository version:</strong> <a href="https://github.com/jjmaynard/ESG.Mapping/tree/f778b156e866ef772ce7426b95ed5d834f12d6ea" target="_blank">f778b15</a> </a>
</p>
</div>
<div id="strongRepositoryversionstrongahrefhttpsgithubcomjjmaynardESGMappingtreef778b156e866ef772ce7426b95ed5d834f12d6eatargetblankf778b15a" class="panel-collapse collapse">
<div class="panel-body">
<p>
Great! You are using Git for version control. Tracking code development and connecting the code version to the results is critical for reproducibility. The version displayed above was the version of the Git repository at the time these results were generated. <br><br> Note that you need to be careful to ensure that all relevant files for the analysis have been committed to Git prior to generating the results (you can use <code>wflow_publish</code> or <code>wflow_git_commit</code>). workflowr only checks the R Markdown file, but you know if there are other scripts or data files that it depends on. Below is the status of the Git repository when the results were generated:
</p>
<pre><code>
Ignored files:
    Ignored:    .Rhistory
    Ignored:    .Rproj.user/
    Ignored:    data/raw_data/
    Ignored:    manuscript/figures/
    Ignored:    proj_setup/

Untracked files:
    Untracked:  data/derived_data/vector/

Unstaged changes:
    Modified:   analysis/ESG_Covariate_Processing.Rmd

</code></pre>
<p>
Note that any generated files, e.g. HTML, png, CSS, etc., are not included in this status report because it is ok for generated content to have uncommitted changes.
</p>
</div>
</div>
</div>
</div>
<hr>
</div>
<div id="versions" class="tab-pane fade">

<p>
These are the previous versions of the R Markdown and HTML files. If you’ve configured a remote Git repository (see <code>?wflow_git_remote</code>), click on the hyperlinks in the table below to view them.
</p>
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
File
</th>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
<th>
Message
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/jjmaynard/ESG.Mapping/e48cb8a2738f0585af94ffca14ab04fa67fbe3d0/docs/ESG_HyperTemp_Image_Processing.html" target="_blank">e48cb8a</a>
</td>
<td>
jjmaynard
</td>
<td>
2019-06-17
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/jjmaynard/ESG.Mapping/blob/0e084ee921fd3e32c5ac50384bbdd2f72b39c2f1/analysis/ESG_HyperTemp_Image_Processing.Rmd" target="_blank">0e084ee</a>
</td>
<td>
jjmaynard
</td>
<td>
2019-06-17
</td>
<td>
Site update
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/jjmaynard/ESG.Mapping/a46f4597d8e1e25d1bbdbe7446eb9b81dee43ca2/docs/ESG_HyperTemp_Image_Processing.html" target="_blank">a46f459</a>
</td>
<td>
jjmaynard
</td>
<td>
2019-05-31
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/jjmaynard/ESG.Mapping/46e9886c835c9c6e96040c010123f680fd54ffa6/docs/ESG_HyperTemp_Image_Processing.html" target="_blank">46e9886</a>
</td>
<td>
jjmaynard
</td>
<td>
2019-05-31
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/jjmaynard/ESG.Mapping/blob/2c19f64ed3873559d85a3ee2efd80a5effa8bdc4/analysis/ESG_HyperTemp_Image_Processing.Rmd" target="_blank">2c19f64</a>
</td>
<td>
jjmaynard
</td>
<td>
2019-05-31
</td>
<td>
ESG_HyperTemp_Image_Processing
</td>
</tr>
</tbody>
</table>
</div>
<hr>
</div>
</div>
</div>
<div id="overview" class="section level2">
<h2>Overview</h2>
<div id="this-script-downloads-and-processes-hyper-temporal-imagery-producing-ndvi-nir-mir-red-lst-day-lst-night-at-250m-and-a-16-day-interval" class="section level4">
<h4>This script downloads and processes hyper-temporal imagery producing: NDVI, NIR, MIR, Red, LST-day, LST-night at 250m and a 16-day interval</h4>
<pre class="r"><code>required.packages &lt;- c(&quot;here&quot;, &quot;MODIS&quot;, &quot;maptools&quot;, &quot;rgdal&quot;, &quot;raster&quot;, 
    &quot;maps&quot;, &quot;hyperSpec&quot;, &quot;lubridate&quot;, &quot;foreach&quot;, &quot;sp&quot;, &quot;gdalUtils&quot;, &quot;e1071&quot;, 
    &quot;prodlim&quot;, &quot;Cairo&quot;, &quot;lattice&quot;, &quot;bfast&quot;, &quot;zoo&quot;, &quot;rgeos&quot;, &quot;shapefiles&quot;, 
    &quot;fastcluster&quot;, &quot;spatial.tools&quot;, &quot;plyr&quot;, &quot;ggplot2&quot;, &quot;rasterVis&quot;, &quot;AnomalyDetection&quot;, 
    &quot;stringdist&quot;, &quot;data.table&quot;, &quot;fastmatch&quot;, &quot;caret&quot;, &quot;kernlab&quot;, &quot;pROC&quot;, 
    &quot;parallel&quot;, &quot;foreach&quot;, &quot;plyr&quot;, &quot;snowfall&quot;, &quot;imputeTS&quot;, &quot;signal&quot;, &quot;dummies&quot;, 
    &quot;gtools&quot;, &quot;imputeTS&quot;, &quot;doParallel&quot;)
new.packages &lt;- required.packages[!(required.packages %in% installed.packages()[, 
    &quot;Package&quot;])]
if (length(new.packages)) install.packages(new.packages)
lapply(required.packages, require, character.only = T)
rm(required.packages, new.packages)

no_cores &lt;- detectCores() - 1
cl &lt;- makeCluster(no_cores, type = &quot;SOCK&quot;, outfile = &quot;&quot;)
registerDoParallel(cl)
getDoParWorkers()</code></pre>
</div>
</div>
<div id="step-1.-load-in-shapefiles" class="section level2">
<h2>Step 1. Load in shapefiles</h2>
<pre class="r"><code># Colorado Plateau (CO) and Chihuahuan Desert (NM) Shapefiles
CO &lt;- readOGR(dsn = &quot;/data/data1/R_DATA/Imagery_Vector/Ecosite_Group_Mapping/CO_Plat_study_area&quot;, 
    layer = &quot;epaL4_mlra35sel_bndc&quot;)
NM &lt;- readOGR(dsn = &quot;/data/data1/R_DATA/Imagery_Vector/Ecosite_Group_Mapping/Chihuahuan_study_area&quot;, 
    layer = &quot;Chihauhuan_Study_Area_Boundary&quot;)

# CO rasterize Set up a raster &#39;template&#39; to use in rasterize()
ext.co &lt;- extent(CO)
xy.co &lt;- abs(apply(as.matrix(bbox(CO)), 1, diff))
r.co &lt;- raster(ext.co, ncol = xy.co[1]/250, nrow = xy.co[2]/250)

# Rasterize the shapefile
CO_raster &lt;- rasterize(CO, r.co)
res(CO_raster) &lt;- 250
plot(CO_raster)

# NM rasterize Set up a raster &#39;template&#39; to use in rasterize()
ext.nm &lt;- extent(NM)
xy.nm &lt;- abs(apply(as.matrix(bbox(NM)), 1, diff))
r.nm &lt;- raster(ext.nm, ncol = xy.nm[1]/250, nrow = xy.nm[2]/250)

# Rasterize the shapefile
NM_raster &lt;- rasterize(NM, r.nm)
res(NM_raster) &lt;- 250
plot(NM_raster)</code></pre>
</div>
<div id="step-2.aquire-all-modis-imagery" class="section level2">
<h2>Step 2.AQUIRE ALL MODIS IMAGERY</h2>
<pre class="r"><code># set once
MODIS:::checkTools()
MODISoptions(MODISserverOrder = c(&quot;LAADS&quot;, &quot;LPDAAC&quot;))

getProduct()

# set for MOD13Q1
MODIS:::checkTools()
# use -- gdalPath=&#39;/usr/local/bin/&#39;) -- in MODISoptions if R can&#39;t find
# gdal
MODISoptions(localArcPath = &quot;/data/data1/R_DATA/MODIS/MODIS_ARC/&quot;, outDirPath = &quot;/data/data1/R_DATA//MODIS/MODIS_ARC/PROCESSES&quot;)

# Vegetation Indicies (250 M) Two study areas: check to make sure we
# have coverage
getTile(NM)
getTile(CO)

# VIs
getHdf(product = &quot;MOD13Q1&quot;, begin = &quot;2017035&quot;, tileH = 8, tileV = 5:6, 
    collection = &quot;005&quot;)
getHdf(product = &quot;MOD13Q1&quot;, begin = &quot;2017035&quot;, tileH = 9, tileV = 5, collection = &quot;005&quot;)

#change MODIS directory to &#39;data&#39; drive because of space
MODISoptions(localArcPath = &quot;/data/data2/data/MODIS/MODIS_ARC/&quot;, outDirPath = &quot;/data/data2/data//MODIS/MODIS_ARC/PROCESSES&quot;)

# Landcover type 500m
getHdf(product = &quot;MCD12Q1&quot;, begin = &quot;2000001&quot;, tileH = 8, tileV = 5, collection = &quot;005&quot;)
getHdf(product = &quot;MCD12Q1&quot;, begin = &quot;2000001&quot;, tileH = 8, tileV = 6, collection = &quot;005&quot;)
getHdf(product = &quot;MCD12Q1&quot;, begin = &quot;2000001&quot;, tileH = 9, tileV = 5, collection = &quot;005&quot;)

# LST 1000m
getHdf(product = &quot;MOD11A2&quot;, begin = &quot;2000001&quot;, tileH = 8, tileV = 5, collection = &quot;005&quot;)
getHdf(product = &quot;MOD11A2&quot;, begin = &quot;2000001&quot;, tileH = 8, tileV = 6, collection = &quot;005&quot;)
getHdf(product = &quot;MOD11A2&quot;, begin = &quot;2000001&quot;, tileH = 9, tileV = 5, collection = &quot;005&quot;)

# Nadir BRDF-Adjusted Reflectance 500m
getHdf(product = &quot;MCD43A4&quot;, begin = &quot;2000001&quot;, tileH = 8, tileV = 5, collection = &quot;005&quot;)
getHdf(product = &quot;MCD43A4&quot;, begin = &quot;2000001&quot;, tileH = 8, tileV = 6, collection = &quot;005&quot;)
getHdf(product = &quot;MCD43A4&quot;, begin = &quot;2000001&quot;, tileH = 9, tileV = 5, collection = &quot;005&quot;)


# Nadir BRDF-QA
getHdf(product = &quot;MCD43A2&quot;, begin = &quot;2000001&quot;, tileH = 8, tileV = 5, collection = &quot;005&quot;)
getHdf(product = &quot;MCD43A2&quot;, begin = &quot;2000001&quot;, tileH = 8, tileV = 6, collection = &quot;005&quot;)
getHdf(product = &quot;MCD43A2&quot;, begin = &quot;2000001&quot;, tileH = 9, tileV = 5, collection = &quot;005&quot;)</code></pre>
</div>
<div id="step-3.-define-modis-processing-functions" class="section level2">
<h2>Step 3. Define MODIS processing functions</h2>
<pre class="r"><code>#-------------------------------------------------------------------------------------------------------
# note: in the past runGDAL had issues, thus I created multiple custom
# processing functions. With updates to MODIS? runGDAL appearst to be
# working again.
#-------------------Data types
      # Datatype definition:    minimum possible value, maximum possible value
      # LOG1S   FALSE (0)   TRUE (1)
      # INT1S   -127    127
      # INT1U   0   255
      # INT2S   -32,767 32,767
      # INT2U   0   65,534
      # INT4S   -2,147,483,647  2,147,483,647
      # INT4U   0   4,294,967,296
      # FLT4S   -3.4e+38    3.4e+38
      # FLT8S   -1.7e+308   1.7e+308
      #LST data=INT2U; LST QA=INT1U; VI=INT2S; BRDF=INT2U; Landcover=INT1U
      #Raster data types: â€™LOG1Sâ€™, â€™INT1Sâ€™, â€™INT2Sâ€™,â€™INT4Sâ€™, â€™INT8Sâ€™, â€™INT1Uâ€™, â€™INT2Uâ€™, â€™FLT4Sâ€™, â€™FLT8Sâ€™
      #GDAL data types: Byte, UInt16, Int16, UInt32, Int32, Float32, Float64, CInt16, CInt32, CFloat32 and CFloat64
      # LOG1S
      # INT1S   = Int8
      # INT1U   = UInt8
      # INT2S   = Int16
      # INT2U   = UInt16
      # INT4S   = Int32
      # INT4U   = UInt32
      # FLT4S
      # FLT8S

#-----------------------------------------------------------------------------------------------------------------------
#------------Processing function for MOD13 imagery
mod13_process &lt;- function(input_folder, output_folder, raster, sd.fill, 
    res, shapefile.path) {
    # res=resolution in meters i.e. 250 or 1000
    
    s_srs &lt;- &quot;+proj=sinu +lon_0=0 +x_0=0 +y_0=0 +a=6371007.181 +b=6371007.181 +units=m +no_defs&quot;
    t_srs &lt;- projection(raster)
    
    # extract the date from the MODIS file name
    # unique(substr(list.files(input_folder,pattern=&#39;.hdf&#39;, recursive=TRUE,
    # include.dirs=TRUE), 21, 27))[1]
    mod13.list &lt;- list()
    for (i in 1:length(unique(substr(list.files(input_folder, pattern = &quot;.hdf&quot;, 
        recursive = TRUE, include.dirs = TRUE), 21, 29)))) {
        mod13.list[[i]] &lt;- grep(paste(as.vector(getTile(raster)$tile), 
            collapse = &quot;|&quot;), as.vector(list.files(path = input_folder, 
            pattern = unique(substr(list.files(input_folder, pattern = &quot;.hdf&quot;, 
                recursive = TRUE, include.dirs = TRUE), 21, 29))[i], recursive = TRUE, 
            include.dirs = TRUE)), value = TRUE)
    }
    
    
    # set up temp files for output.vrt
    output.vrt &lt;- list()
    for (i in 1:length(unique(substr(list.files(input_folder, pattern = &quot;.hdf&quot;, 
        recursive = TRUE, include.dirs = TRUE), 21, 27)))) {
        output.vrt[[i]] &lt;- paste(tempfile(), &quot;.vrt&quot;, sep = &quot;&quot;)
    }
    
    if (sd.fill == 1) {
        j &lt;- &quot;250m_16_days_NDVI&quot;
    } else if (sd.fill == 2) {
        j &lt;- &quot;250m_16_days_EVI&quot;
    } else if (sd.fill == 3) {
        j &lt;- &quot;250m_16 days_VI_Quality&quot;
    } else if (sd.fill == 4) {
        j &lt;- &quot;1_km_16_days_red&quot;
    } else if (sd.fill == 5) {
        j &lt;- &quot;250m_16_days_NIR&quot;
    } else if (sd.fill == 6) {
        j &lt;- &quot;250m_16_days_blue&quot;
    } else if (sd.fill == 7) {
        j &lt;- &quot;250m_16_days_SWIR2&quot;
    } else if (sd.fill == 12) {
        j &lt;- &quot;250m_16_days_PixRel&quot;
    } else {
        j &lt;- &quot;NA&quot;
    }
    
    # [1] &#39;1 km 16 days NDVI&#39; &#39;1 km 16 days EVI&#39; &#39;1 km 16 days VI Quality&#39;
    # [4] &#39;1 km 16 days red reflectance&#39; &#39;1 km 16 days NIR reflectance&#39; &#39;1
    # km 16 days blue reflectance&#39; [7] &#39;1 km 16 days MIR reflectance&#39; &#39;1 km
    # 16 days view zenith angle&#39; &#39;1 km 16 days sun zenith angle&#39; [10] &#39;1 km
    # 16 days relative azimuth angle&#39; &#39;1 km 16 days composite day of the
    # year&#39; &#39;1 km 16 days pixel reliability&#39;
    
    # implement foreach loop here
    
    foreach(i = 1:length(mod13.list), .packages = c(&quot;gdalUtils&quot;, &quot;sp&quot;)) %dopar% 
        {
            gdalbuildvrt(paste0(input_folder, &quot;/&quot;, mod13.list[[i]], sep = &quot;&quot;), 
                output.vrt = output.vrt[[i]], sd = sd.fill, separate = FALSE, 
                tileindex = TRUE, overwrite = TRUE, verbose = TRUE)
            gdalwarp(output.vrt[[i]], dstfile = paste0(output_folder, &quot;/&quot;, 
                unique(substr(mod13.list[[i]], 12, 27)), &quot;_&quot;, j, &quot;.tif&quot;), 
                of = &quot;GTiff&quot;, s_srs = s_srs, t_srs = t_srs, tr = c(res, 
                  res), cutline = shapefile.path, crop_to_cutline = TRUE, 
                dstalpha = TRUE, overwrite = TRUE)
            
        }
}

#------------------Definiition of clipping options in gdalwarp
# # cutline: sets path to shapefile to clip to
# cutline=&#39;/data/data1/R_DATA/Imagery_Vector/Ecosite_Group_Mapping/Chihuahuan_study_area/Chihauhuan_Study_Area_Boundary.shp&#39;,
# # these parameters clip the result based on a shapefile area
# crop_to_cutline=TRUE, dstalpha=TRUE, # te: clips the raster based on
# the bbox of the input shapefile te=c(as.vector(bbox(raster))),

# 
#-----------------------------------------------------------------------------------------------------------------
#------------Processing function for all MODIS imagery, need to specify correct sd code and give name (j) for writing
modis_process &lt;- function(input_folder, output_folder, raster, sd.fill, 
    res, j, shapefile.path) {
    # res=resolution in meters i.e. 250 or 1000
    
    s_srs &lt;- &quot;+proj=sinu +lon_0=0 +x_0=0 +y_0=0 +a=6371007.181 +b=6371007.181 +units=m +no_defs&quot;
    t_srs &lt;- projection(raster)
    
    # extract the date from the MODIS file name
    # unique(substr(list.files(input_folder,pattern=&#39;.hdf&#39;, recursive=TRUE,
    # include.dirs=TRUE), 21, 27))[1]
    mod.list &lt;- list()
    for (i in 1:length(unique(substr(list.files(input_folder, pattern = &quot;.hdf&quot;, 
        recursive = TRUE, include.dirs = TRUE), 21, 29)))) {
        mod.list[[i]] &lt;- grep(paste(as.vector(getTile(raster)$tile), collapse = &quot;|&quot;), 
            as.vector(list.files(path = input_folder, pattern = unique(substr(list.files(input_folder, 
                pattern = &quot;.hdf&quot;, recursive = TRUE, include.dirs = TRUE), 
                21, 29))[i], recursive = TRUE, include.dirs = TRUE)), value = TRUE)
    }
    
    
    # set up temp files for output.vrt
    output.vrt &lt;- list()
    for (i in 1:length(unique(substr(list.files(input_folder, pattern = &quot;.hdf&quot;, 
        recursive = TRUE, include.dirs = TRUE), 21, 27)))) {
        output.vrt[[i]] &lt;- paste(tempfile(), &quot;.vrt&quot;, sep = &quot;&quot;)
    }
    
    # implement foreach loop here
    foreach(i = 1:length(mod.list), .packages = c(&quot;gdalUtils&quot;, &quot;sp&quot;)) %dopar% 
        {
            gdalbuildvrt(paste0(input_folder, &quot;/&quot;, mod.list[[i]], sep = &quot;&quot;), 
                output.vrt = output.vrt[[i]], sd = sd.fill, separate = FALSE, 
                tileindex = TRUE, overwrite = TRUE, verbose = TRUE)
            gdalwarp(output.vrt[[i]], dstfile = paste0(output_folder, &quot;/&quot;, 
                unique(substr(mod.list[[i]], 12, 27)), &quot;_&quot;, j, &quot;.tif&quot;), 
                of = &quot;GTiff&quot;, s_srs = s_srs, t_srs = t_srs, tr = c(res, 
                  res), cutline = shapefile.path, crop_to_cutline = TRUE, 
                dstalpha = TRUE, overwrite = TRUE)
            
        }
    
}

# 
#------------------------------------------------------------------------------------------------------------------
# Process MODIS imagery &gt;250m and resample using gdal
#   -Crop to bbox for coarser imagery so it doesnt clip parts of study area
#   -res=resolution in meters, i.e. 250 or 1000
modis_process_resample &lt;- function(input_folder, output_folder, raster, 
    sd.fill, t_res, resample_method, j, data.type) {
    
    s_srs &lt;- &quot;+proj=sinu +lon_0=0 +x_0=0 +y_0=0 +a=6371007.181 +b=6371007.181 +units=m +no_defs&quot;
    t_srs &lt;- projection(raster)
    
    # extract the date from the MODIS file name
    # unique(substr(list.files(input_folder,pattern=&#39;.hdf&#39;, recursive=TRUE,
    # include.dirs=TRUE), 21, 27))[1]
    mod.list &lt;- list()
    for (i in 1:length(unique(substr(list.files(input_folder, pattern = &quot;.hdf&quot;, 
        recursive = TRUE, include.dirs = TRUE), 21, 29)))) {
        mod.list[[i]] &lt;- grep(paste(as.vector(getTile(raster)$tile), collapse = &quot;|&quot;), 
            as.vector(list.files(path = input_folder, pattern = unique(substr(list.files(input_folder, 
                pattern = &quot;.hdf&quot;, recursive = TRUE, include.dirs = TRUE), 
                21, 29))[i], recursive = TRUE, include.dirs = TRUE)), value = TRUE)
    }
    
    # set up temp files for output.vrt
    output.vrt &lt;- list()
    for (i in 1:length(mod.list)) {
        output.vrt[[i]] &lt;- paste(tempfile(), &quot;.vrt&quot;, sep = &quot;&quot;)
    }
    
    # implement foreach loop here
    foreach(i = 1:length(mod.list), .packages = c(&quot;gdalUtils&quot;, &quot;sp&quot;)) %dopar% 
        {
            gdalbuildvrt(paste0(input_folder, &quot;/&quot;, mod.list[[i]], sep = &quot;&quot;), 
                output.vrt = output.vrt[[i]], sd = sd.fill, separate = FALSE, 
                tileindex = TRUE, overwrite = TRUE, verbose = TRUE)
            gdalwarp(output.vrt[[i]], dstfile = paste0(output_folder, &quot;/&quot;, 
                unique(substr(mod.list[[i]], 12, 27)), &quot;_&quot;, j, &quot;.tif&quot;), 
                of = &quot;GTiff&quot;, s_srs = s_srs, t_srs = t_srs, tr = c(t_res, 
                  t_res), r = resample_method, ot = data.type, dstalpha = TRUE, 
                te = c(as.vector(bbox(raster))), overwrite = TRUE)
            
        }
}


#----------------------------------------------------------------------------------------------------
# Find correct SDS codes for the different MODIS imagery
#----------------------------------------------------------------------------------------------------

# find out which SDS numbers correspond to which bands MOD13Q1
getSds(HdfName = &quot;MOD13Q1.A2000049.h08v04.005.2006269063040.hdf&quot;)

# $SDSnames [1] &#39;250m 16 days NDVI&#39; [2] &#39;250m 16 days EVI&#39; [3] &#39;250m 16
# days VI Quality&#39; [4] &#39;250m 16 days red reflectance&#39; [5] &#39;250m 16 days
# NIR reflectance&#39; [6] &#39;250m 16 days blue reflectance&#39; [7] &#39;250m 16
# days MIR reflectance&#39; [8] &#39;250m 16 days view zenith angle&#39; [9] &#39;250m
# 16 days sun zenith angle&#39; [10] &#39;250m 16 days relative azimuth angle&#39;
# [11] &#39;250m 16 days composite day of the year&#39; [12]&#39;250m 16 days pixel
# reliability&#39;

# M CD12Q1
getSds(HdfName = &quot;/data/data2/data/MODIS/MODIS_ARC/MODIS/MCD12Q1.005/2001.01.01/MCD12Q1.A2001001.h23v03.005.2011230172229.hdf&quot;)
# $SDSnames [1] &#39;Land_Cover_Type_1&#39; &#39;Land_Cover_Type_2&#39; [3]
# &#39;Land_Cover_Type_3&#39; &#39;Land_Cover_Type_4&#39; [5] &#39;Land_Cover_Type_5&#39;
# &#39;Land_Cover_Type_1_Assessment&#39; [7] &#39;Land_Cover_Type_2_Assessment&#39;
# &#39;Land_Cover_Type_3_Assessment&#39; [9] &#39;Land_Cover_Type_4_Assessment&#39;
# &#39;Land_Cover_Type_5_Assessment&#39; [11] &#39;Land_Cover_Type_QC&#39;
# &#39;Land_Cover_Type_1_Secondary&#39; [13]
# &#39;Land_Cover_Type_1_Secondary_Percent&#39; &#39;LC_Property_1&#39; [15]
# &#39;LC_Property_2&#39; &#39;LC_Property_3&#39;

# MCD43A4
getSds(HdfName = &quot;/data/data2/data/MODIS/MODIS_ARC/MODIS/MCD43A4.005/2000.02.18/MCD43A4.A2000049.h23v03.005.2006269095154.hdf&quot;)
# $SDSnames [1] &#39;Nadir_Reflectance_Band1&#39; &#39;Nadir_Reflectance_Band2&#39;
# &#39;Nadir_Reflectance_Band3&#39; [4] &#39;Nadir_Reflectance_Band4&#39;
# &#39;Nadir_Reflectance_Band5&#39; &#39;Nadir_Reflectance_Band6&#39; [7]
# &#39;Nadir_Reflectance_Band7&#39;

getSds(HdfName = &quot;/data/data2/data/MODIS/MODIS_ARC/MODIS/MCD43A2.005/2000.02.18/MCD43A2.A2000049.h23v03.005.2006269095153.hdf&quot;)
# $SDSnames [1] &#39;BRDF_Albedo_Quality&#39; &#39;Snow_BRDF_Albedo&#39;
# &#39;BRDF_Albedo_Ancillary&#39; &#39;BRDF_Albedo_Band_Quality&#39;

# MOD11A2
getSds(HdfName = &quot;/data/data2/data/MODIS/MODIS_ARC/MODIS/MOD11A2.005/2000.03.05/MOD11A2.A2000065.h23v03.005.2007176173151.hdf&quot;)

# $SDSnames [1] &#39;LST_Day_1km&#39; &#39;QC_Day&#39; &#39;Day_view_time&#39; &#39;Day_view_angl&#39;
# &#39;LST_Night_1km&#39; &#39;QC_Night&#39; &#39;Night_view_time&#39; &#39;Night_view_angl&#39; [9]
# &#39;Emis_31&#39; &#39;Emis_32&#39; &#39;Clear_sky_days&#39; &#39;Clear_sky_nights&#39;
#------------------------------------------------------------------------------------------------------</code></pre>
</div>
<div id="step-4.-process-modis-imagery" class="section level2">
<h2>Step 4. Process MODIS Imagery</h2>
<pre class="r"><code>#----------Run functions to process MODIS imagery
# Make sure parallel backend in loaded
getDoParWorkers()  #if not registered then re-register
# cl &lt;- startMPIcluster(count = 24) registerDoMPI(cl) getDoParWorkers()
# closeCluster(cl)

#------------------------------------------------------------------------------------------------------
#-------------------- Process MOD13Q1 imagery  --------------------------------------------------------

# set input and output folders
input_folder &lt;- &quot;/data/data1/R_DATA/MODIS/MODIS_ARC/MODIS/MOD13Q1.005&quot;
dir.create(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_VI_250M&quot;)
output_folder &lt;- &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_VI_250M&quot;
# set working directory to input folder
setwd(input_folder)

# execute MOD13 processing function extract NDVI
mod13_process(input_folder, output_folder, CO_raster, sd.fill = 1, res = 250, 
    shapefile.path = &quot;/data/data1/R_DATA/Imagery_Vector/Ecosite_Group_Mapping/CO_Plat_study_area/epaL4_mlra35sel_bndc.shp&quot;)
# extract Pixel Reliability
mod13_process(input_folder, output_folder, CO_raster, sd.fill = 12, res = 250, 
    shapefile.path = &quot;/data/data1/R_DATA/Imagery_Vector/Ecosite_Group_Mapping/CO_Plat_study_area/epaL4_mlra35sel_bndc.shp&quot;)
# extract Red
mod13_process(input_folder, output_folder, CO_raster, sd.fill = 4, res = 250, 
    shapefile.path = &quot;/data/data1/R_DATA/Imagery_Vector/Ecosite_Group_Mapping/CO_Plat_study_area/epaL4_mlra35sel_bndc.shp&quot;)
# extract SWIR2
mod13_process(input_folder, output_folder, CO_raster, sd.fill = 7, res = 250, 
    shapefile.path = &quot;/data/data1/R_DATA/Imagery_Vector/Ecosite_Group_Mapping/CO_Plat_study_area/epaL4_mlra35sel_bndc.shp&quot;)


dir.create(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_VI_250M&quot;)
output_folder &lt;- &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_VI_250M&quot;
# extract NDVI
mod13_process(input_folder, output_folder, NM_raster, sd.fill = 1, res = 250, 
    shapefile.path = &quot;/data/data1/R_DATA/Imagery_Vector/Ecosite_Group_Mapping/Chihuahuan_study_area/Chihauhuan_Study_Area_Boundary.shp&quot;)
# extract Pixel Reliability
mod13_process(input_folder, output_folder, NM_raster, sd.fill = 12, res = 250, 
    shapefile.path = &quot;/data/data1/R_DATA/Imagery_Vector/Ecosite_Group_Mapping/Chihuahuan_study_area/Chihauhuan_Study_Area_Boundary.shp&quot;)
# extract Red
mod13_process(input_folder, output_folder, NM_raster, sd.fill = 4, res = 250, 
    shapefile.path = &quot;/data/data1/R_DATA/Imagery_Vector/Ecosite_Group_Mapping/Chihuahuan_study_area/Chihauhuan_Study_Area_Boundary.shp&quot;)
# extract SWIR2
mod13_process(input_folder, output_folder, NM_raster, sd.fill = 7, res = 250, 
    shapefile.path = &quot;/data/data1/R_DATA/Imagery_Vector/Ecosite_Group_Mapping/Chihuahuan_study_area/Chihauhuan_Study_Area_Boundary.shp&quot;)


# extract EVI
output_folder &lt;- &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_VI_250M&quot;
mod13_process(input_folder, output_folder, CO_raster, sd.fill = 2, res = 250, 
    shapefile.path = &quot;/data/data1/R_DATA/Imagery_Vector/Ecosite_Group_Mapping/CO_Plat_study_area/epaL4_mlra35sel_bndc.shp&quot;)
output_folder &lt;- &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_VI_250M&quot;
mod13_process(input_folder, output_folder, NM_raster, sd.fill = 2, res = 250, 
    shapefile.path = &quot;/data/data1/R_DATA/Imagery_Vector/Ecosite_Group_Mapping/Chihuahuan_study_area/Chihauhuan_Study_Area_Boundary.shp&quot;)

#------------------------------------------------------------------------------------------------------
#-------------------- Process MOD11A2 imagery  --------------------------------------------------------
# Extract LST and QC set input and output folders input_folder,
# output_folder, raster, sd.fill, s_res, t_res, resampleFactor, j,
# shapefile.path
input_folder &lt;- &quot;/data/data2/data/MODIS/MODIS_ARC/MODIS/MOD11A2.005&quot;
# dir.create(&#39;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_LST_1000M&#39;)
# dir.create(&#39;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_LST_1000M&#39;)
# LST data=INT2U; LST QA=INT1U; LST data=UInt16; LST QA=byte;
output_folder &lt;- &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_LST_1000M&quot;
modis_process_resample(input_folder, output_folder, CO_raster, sd.fill = 1, 
    t_res = 250, resample_method = &quot;bilinear&quot;, j = &quot;LST_Day_250m&quot;, data.type = &quot;UInt16&quot;)
modis_process_resample(input_folder, output_folder, CO_raster, sd.fill = 2, 
    t_res = 250, resample_method = &quot;near&quot;, j = &quot;QC_Day_250m&quot;, data.type = &quot;byte&quot;)
modis_process_resample(input_folder, output_folder, CO_raster, sd.fill = 5, 
    t_res = 250, resample_method = &quot;bilinear&quot;, j = &quot;LST_Night_250m&quot;, data.type = &quot;UInt16&quot;)
modis_process_resample(input_folder, output_folder, CO_raster, sd.fill = 6, 
    t_res = 250, resample_method = &quot;near&quot;, j = &quot;QC_Night_250m&quot;, data.type = &quot;byte&quot;)
# runGdal(job=&#39;CO_LST_1000M&#39;, product=&#39;MOD11A2&#39;, collection=&#39;005&#39;,
# extent=CO_raster, begin=&#39;2000001&#39;,SDSstring=&#39;100010&#39;,
# resamplingType=&#39;bilinear&#39;) runGdal(job=&#39;CO_LST_1000M&#39;,
# product=&#39;MOD11A2&#39;, collection=&#39;005&#39;, extent=CO_raster,
# begin=&#39;2000001&#39;, SDSstring=&#39;010001&#39;, resamplingType=&#39;near&#39;)

# #find and remove files from folders rm.list &lt;-
# list.files(output_folder,pattern=&#39;*QC_Night.tif&#39;, recursive=TRUE,
# include.dirs=TRUE) unlink(paste0(output_folder, &#39;/&#39;, rm.list))

output_folder &lt;- &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_LST_1000M&quot;
modis_process_resample(input_folder, output_folder, NM_raster, sd.fill = 1, 
    t_res = 250, resample_method = &quot;bilinear&quot;, j = &quot;LST_Day_250m&quot;, data.type = &quot;UInt16&quot;)
modis_process_resample(input_folder, output_folder, NM_raster, sd.fill = 2, 
    t_res = 250, resample_method = &quot;near&quot;, j = &quot;QC_Day_250m&quot;, data.type = &quot;byte&quot;)
modis_process_resample(input_folder, output_folder, NM_raster, sd.fill = 5, 
    t_res = 250, resample_method = &quot;bilinear&quot;, j = &quot;LST_Night_250m&quot;, data.type = &quot;UInt16&quot;)
modis_process_resample(input_folder, output_folder, NM_raster, sd.fill = 6, 
    t_res = 250, resample_method = &quot;near&quot;, j = &quot;QC_Night_250m&quot;, data.type = &quot;byte&quot;)


#------------------------------------------------------------------------------------------------------
#-------------------- Process MCD12Q1 imagery  --------------------------------------------------------
# Extract land cover Land Cover Type 1 (IGBP)
input_folder &lt;- &quot;/data/data2/data/MODIS/MODIS_ARC/MODIS/MCD12Q1.005&quot;
dir.create(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_Landcover_500M&quot;)
dir.create(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_Landcover_500M&quot;)

output_folder &lt;- &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_Landcover_500M&quot;
modis_process_resample(input_folder, output_folder, CO_raster, sd.fill = 1, 
    s_res = 500, t_res = 250, resampleFactor = 2, j = &quot;250m_16_days_Cover_T1&quot;, 
    shapefile.path = &quot;/data/data1/R_DATA/Imagery_Vector/Ecosite_Group_Mapping/CO_Plat_study_area/epaL4_mlra35sel_bndc.shp&quot;, 
    data.type = &quot;UInt8&quot;)
modis_process_resample(input_folder, output_folder, CO_raster, sd.fill = 11, 
    s_res = 500, t_res = 250, resampleFactor = 2, j = &quot;250m_16_days_Cover_QC&quot;, 
    shapefile.path = &quot;/data/data1/R_DATA/Imagery_Vector/Ecosite_Group_Mapping/CO_Plat_study_area/epaL4_mlra35sel_bndc.shp&quot;, 
    data.type = &quot;UInt8&quot;)

output_folder &lt;- &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_Landcover_500M&quot;
modis_process_resample(input_folder, output_folder, NM, sd.fill = 1, s_res = 500, 
    t_res = 250, resampleFactor = 2, j = &quot;250m_16_days_Cover_T1&quot;, shapefile.path = &quot;/data/data1/R_DATA/Imagery_Vector/Ecosite_Group_Mapping/Chihuahuan_study_area/Chihauhuan_Study_Area_Boundary.shp&quot;, 
    data.type = &quot;UInt8&quot;)
modis_process_resample(input_folder, output_folder, NM, sd.fill = 11, s_res = 500, 
    t_res = 250, resampleFactor = 2, j = &quot;250m_16_days_Cover_QC&quot;, shapefile.path = &quot;/data/data1/R_DATA/Imagery_Vector/Ecosite_Group_Mapping/Chihuahuan_study_area/Chihauhuan_Study_Area_Boundary.shp&quot;, 
    data.type = &quot;UInt8&quot;)

#------------------------------------------------------------------------------------------------------
#----------------------------Process MCD43A4 imagery---------------------------------------------------
# Extract NIR and MIR MCD43A4
runGdal(job = &quot;CO_Modis_BRDF&quot;, product = &quot;MCD43A4&quot;, collection = &quot;005&quot;, 
    extent = CO_raster, begin = &quot;2000001&quot;, SDSstring = &quot;1100011&quot;, resamplingType = &quot;bilinear&quot;)
runGdal(job = &quot;NM_Modis_BRDF&quot;, product = &quot;MCD43A4&quot;, collection = &quot;005&quot;, 
    extent = NM_raster, begin = &quot;2000001&quot;, SDSstring = &quot;1100011&quot;, resamplingType = &quot;bilinear&quot;)

# # Custom extraction method
# input_folder &lt;- &quot;/data/data2/data/MODIS/MODIS_ARC/MODIS/MCD43A4.005&quot;
# dir.create(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_BRDF_Ref_500M&quot;)
# dir.create(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_BRDF_Ref_500M&quot;)
# 
# output_folder &lt;- &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_BRDF_Ref_500M&quot;
# modis_process_resample(input_folder, output_folder, CO_raster, sd.fill = 1, 
#     s_res = 500, t_res = 250, resampleFactor = 2, j = &quot;250m_16_days_BRDF1_RED&quot;, 
#     shapefile.path = &quot;/data/data1/R_DATA/Imagery_Vector/Ecosite_Group_Mapping/CO_Plat_study_area/epaL4_mlra35sel_bndc.shp&quot;, 
#     data.type = &quot;INT2U&quot;)
# modis_process_resample(input_folder, output_folder, CO_raster, sd.fill = 2, 
#     s_res = 500, t_res = 250, resampleFactor = 2, j = &quot;250m_16_days_BRDF2_NIR&quot;, 
#     shapefile.path = &quot;/data/data1/R_DATA/Imagery_Vector/Ecosite_Group_Mapping/CO_Plat_study_area/epaL4_mlra35sel_bndc.shp&quot;, 
#     data.type = &quot;INT2U&quot;)
# modis_process_resample(input_folder, output_folder, CO_raster, sd.fill = 6, 
#     s_res = 500, t_res = 250, resampleFactor = 2, j = &quot;250m_16_days_BRDF6_SWIR1&quot;, 
#     shapefile.path = &quot;/data/data1/R_DATA/Imagery_Vector/Ecosite_Group_Mapping/CO_Plat_study_area/epaL4_mlra35sel_bndc.shp&quot;, 
#     data.type = &quot;INT2U&quot;)
# modis_process_resample(input_folder, output_folder, CO_raster, sd.fill = 7, 
#     s_res = 500, t_res = 250, resampleFactor = 2, j = &quot;250m_16_days_BRDF7_SWIR2&quot;, 
#     shapefile.path = &quot;/data/data1/R_DATA/Imagery_Vector/Ecosite_Group_Mapping/CO_Plat_study_area/epaL4_mlra35sel_bndc.shp&quot;, 
#     data.type = &quot;INT2U&quot;)
# 
# output_folder &lt;- &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_BRDF_Ref_500M&quot;
# modis_process_resample(input_folder, output_folder, NM_raster, sd.fill = 1, 
#     s_res = 500, t_res = 250, resampleFactor = 2, j = &quot;250m_16_days_BRDF1_RED&quot;, 
#     shapefile.path = &quot;/data/data1/R_DATA/Imagery_Vector/Ecosite_Group_Mapping/Chihuahuan_study_area/Chihauhuan_Study_Area_Boundary.shp&quot;, 
#     data.type = &quot;INT2U&quot;)
# modis_process_resample(input_folder, output_folder, NM_raster, sd.fill = 2, 
#     s_res = 500, t_res = 250, resampleFactor = 2, j = &quot;250m_16_days_BRDF2_NIR&quot;, 
#     shapefile.path = &quot;/data/data1/R_DATA/Imagery_Vector/Ecosite_Group_Mapping/Chihuahuan_study_area/Chihauhuan_Study_Area_Boundary.shp&quot;, 
#     data.type = &quot;INT2U&quot;)
# modis_process_resample(input_folder, output_folder, NM_raster, sd.fill = 6, 
#     s_res = 500, t_res = 250, resampleFactor = 2, j = &quot;250m_16_days_BRDF6_SWIR1&quot;, 
#     shapefile.path = &quot;/data/data1/R_DATA/Imagery_Vector/Ecosite_Group_Mapping/Chihuahuan_study_area/Chihauhuan_Study_Area_Boundary.shp&quot;, 
#     data.type = &quot;INT2U&quot;)
# modis_process_resample(input_folder, output_folder, NM_raster, sd.fill = 7, 
#     s_res = 500, t_res = 250, resampleFactor = 2, j = &quot;250m_16_days_BRDF7_SWIR2&quot;, 
#     shapefile.path = &quot;/data/data1/R_DATA/Imagery_Vector/Ecosite_Group_Mapping/Chihuahuan_study_area/Chihauhuan_Study_Area_Boundary.shp&quot;, 
#     data.type = &quot;INT2U&quot;)

#######################################################################################################################################
#-------------------------Process MCD43A2 imagery
#
#Extract QA MCD43A2
runGdal(job=&quot;CO_Modis_BRDF&quot;, product=&quot;MCD43A2&quot;, collection=&#39;005&#39;, extent=CO_raster, begin=&quot;2000001&quot;,  SDSstring=&quot;1&quot;, resamplingType=&#39;near&#39;)
runGdal(job=&quot;NM_Modis_BRDF&quot;, product=&quot;MCD43A2&quot;, collection=&#39;005&#39;, extent=NM_raster, begin=&quot;2000001&quot;,  SDSstring=&quot;1&quot;, resamplingType=&#39;near&#39;)

# # Custom extraction method
# input_folder &lt;- &quot;/data/data2/data/MODIS/MODIS_ARC/MODIS/MCD43A2.005&quot;
# output_folder &lt;- &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_BRDF_Ref_500M&quot;
# modis_process(input_folder, output_folder, CO_raster, sd.fill = 1, res = 500, 
#     j = &quot;500m_16_days_BRDF_QA&quot;, shapefile.path = &quot;/data/data1/R_DATA/Imagery_Vector/Ecosite_Group_Mapping/CO_Plat_study_area/epaL4_mlra35sel_bndc.shp&quot;)
# 
# output_folder &lt;- &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_BRDF_Ref_500M&quot;
# modis_process(input_folder, output_folder, NM_raster, sd.fill = 1, res = 500, 
#     j = &quot;500m_16_days_BRDF_QA&quot;, shapefile.path = &quot;/data/data1/R_DATA/Imagery_Vector/Ecosite_Group_Mapping/Chihuahuan_study_area/Chihauhuan_Study_Area_Boundary.shp&quot;)</code></pre>
</div>
<div id="step-5.-qa" class="section level2">
<h2>Step 5. QA</h2>
<pre class="r"><code># set the path to get the correct data on the source directory: path to
# imagery sets CO paths&#39;
path.co.vi &lt;- &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_VI_250M&quot;
path.co.BRDF &lt;- &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_Modis_BRDF&quot;
path.co.landcover &lt;- &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_Landcover_500M&quot;
path.co.lst &lt;- &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_LST_1000M&quot;

# NM paths
path.nm.vi &lt;- &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_VI_250M&quot;
path.nm.BRDF &lt;- &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_Modis_BRDF&quot;
path.nm.landcover &lt;- &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_Landcover_500M&quot;
path.nm.lst &lt;- &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_LST_1000M&quot;

# CO
ndvi.co &lt;- preStack(path = path.co.vi, pattern = &quot;*_NDVI.tif$&quot;)
qa.vi.co &lt;- preStack(path = path.co.vi, pattern = &quot;*_PixRel.tif$&quot;)
evi.co &lt;- preStack(path = path.co.vi, pattern = &quot;*_EVI.tif$&quot;)
vi.red.co &lt;- preStack(path = path.co.vi, pattern = &quot;*_red.tif$&quot;)
vi.swir2.co &lt;- preStack(path = path.co.vi, pattern = &quot;*250m_16_days_SWIR2.tif$&quot;)
red.co &lt;- preStack(path = path.co.BRDF, pattern = &quot;*Band1.tif$&quot;)
nir.co &lt;- preStack(path = path.co.BRDF, pattern = &quot;*Band2.tif$&quot;)
swir1.co &lt;- preStack(path = path.co.BRDF, pattern = &quot;*Band6.tif$&quot;)
swir2.co &lt;- preStack(path = path.co.BRDF, pattern = &quot;*Band7.tif$&quot;)
brdf.qa.co &lt;- preStack(path = path.co.BRDF, pattern = &quot;*Quality.tif$&quot;)
landcover.co &lt;- preStack(path = path.co.landcover, pattern = &quot;*_Cover_T1.tif$&quot;)
landcover.qa.co &lt;- preStack(path = path.co.landcover, pattern = &quot;*_Cover_QC.tif$&quot;)
day.lst.co &lt;- preStack(path = path.co.lst, pattern = &quot;*LST_Day_1km.tif$&quot;)
day.qa.co &lt;- preStack(path = path.co.lst, pattern = &quot;*QC_Day_250m.tif$&quot;)
night.lst.co &lt;- preStack(path = path.co.lst, pattern = &quot;*LST_Night_1km.tif$&quot;)
night.qa.co &lt;- preStack(path = path.co.lst, pattern = &quot;*QC_Night_250m.tif$&quot;)
day.lst.co.sub &lt;- day.lst.co[seq(1, length(day.lst.co), by = 2)]
day.qa.co.sub &lt;- day.qa.co[seq(1, length(day.qa.co), by = 2)]
night.lst.co.sub &lt;- night.lst.co[seq(1, length(night.lst.co), by = 2)]
night.qa.co.sub &lt;- night.qa.co[seq(1, length(night.qa.co), by = 2)]

# Subset BRDF 8-day prestack to match 16-day VI
co.bfdf.list &lt;- unique(substr(list.files(path.co.BRDF, pattern = &quot;Band2.tif&quot;, 
    recursive = TRUE, include.dirs = TRUE), 10, 16))
co.vi.list &lt;- unique(substr(list.files(path.co.vi, pattern = &quot;*_red.tif$&quot;, 
    recursive = TRUE, include.dirs = TRUE), 10, 16))
co.vi.index &lt;- na.omit(cbind(seq(1, length(co.bfdf.list), 1), match(co.bfdf.list, 
    co.vi.list, incomparables = TRUE)))[, 1]
red.co.sub &lt;- red.co[co.vi.index]
nir.co.sub &lt;- nir.co[co.vi.index]
swir1.co.sub &lt;- swir1.co[co.vi.index]
swir2.co.sub &lt;- swir2.co[co.vi.index]
brdf.qa.co.sub &lt;- brdf.qa.co[co.vi.index]

# NM
ndvi.nm &lt;- preStack(path = path.nm.vi, pattern = &quot;*_NDVI.tif$&quot;)
qa.vi.nm &lt;- preStack(path = path.nm.vi, pattern = &quot;*_PixRel.tif$&quot;)
evi.nm &lt;- preStack(path = path.nm.vi, pattern = &quot;*_EVI.tif$&quot;)
vi.red.nm &lt;- preStack(path = path.nm.vi, pattern = &quot;*_red.tif$&quot;)
vi.swir2.nm &lt;- preStack(path = path.nm.vi, pattern = &quot;*250m_16_days_SWIR2.tif$&quot;)
red.nm &lt;- preStack(path = path.nm.BRDF, pattern = &quot;*Band1.tif$&quot;)
nir.nm &lt;- preStack(path = path.nm.BRDF, pattern = &quot;*Band2.tif$&quot;)
swir1.nm &lt;- preStack(path = path.nm.BRDF, pattern = &quot;*Band6.tif$&quot;)
swir2.nm &lt;- preStack(path = path.nm.BRDF, pattern = &quot;*Band7.tif$&quot;)
brdf.qa.nm &lt;- preStack(path = path.nm.BRDF, pattern = &quot;*Quality.tif$&quot;)
landcover.nm &lt;- preStack(path = path.nm.landcover, pattern = &quot;*_Cover_T1.tif$&quot;)
landcover.qa.nm &lt;- preStack(path = path.nm.landcover, pattern = &quot;*_Cover_QC.tif$&quot;)
day.lst.nm &lt;- preStack(path = path.nm.lst, pattern = &quot;*_LST_Day_250m.tif$&quot;)
day.qa.nm &lt;- preStack(path = path.nm.lst, pattern = &quot;*_QC_Day_250m.tif$&quot;)
night.lst.nm &lt;- preStack(path = path.nm.lst, pattern = &quot;*_LST_Night_250m.tif$&quot;)
night.qa.nm &lt;- preStack(path = path.nm.lst, pattern = &quot;*_QC_Night_250m.tif$&quot;)
day.lst.nm.sub &lt;- day.lst.nm[seq(1, length(day.lst.nm), by = 2)]
day.qa.nm.sub &lt;- day.qa.nm[seq(1, length(day.qa.nm), by = 2)]
night.lst.nm.sub &lt;- night.lst.nm[seq(1, length(night.lst.nm), by = 2)]
night.qa.nm.sub &lt;- night.qa.nm[seq(1, length(night.qa.nm), by = 2)]

# #Find missing scenes from BRDF QA and band lists
# nm.bfdf.qa.list&lt;-unique(substr(list.files(path.nm.BRDF,pattern=&#39;Quality.tif&#39;, recursive=TRUE,
# include.dirs=TRUE), 10, 16))
# nm.bfdf.nir.list&lt;-unique(substr(list.files(path.nm.BRDF,pattern=&#39;Band2.tif&#39;, recursive=TRUE,
# include.dirs=TRUE), 10, 16))
# match(nm.bfdf.qa.list, nm.bfdf.nir.list, incomparables=TRUE)
# 
# co.bfdf.qa.list&lt;-unique(substr(list.files(path.co.BRDF,pattern=&#39;BRDF_QA.tif&#39;, recursive=TRUE,
# include.dirs=TRUE), 10, 16))
# co.bfdf.nir.list&lt;-unique(substr(list.files(path.co.BRDF,pattern=&#39;NIR.tif&#39;, recursive=TRUE,
# include.dirs=TRUE), 10, 16)) match(co.bfdf.qa.list, co.bfdf.nir.list, incomparables=TRUE)


# Subset BRDF 8-day prestack to match 16-day VI
nm.bfdf.list &lt;- unique(substr(list.files(path.nm.BRDF, pattern = &quot;Band2.tif&quot;, 
    recursive = TRUE, include.dirs = TRUE), 10, 16))
nm.vi.list &lt;- unique(substr(list.files(path.nm.vi, pattern = &quot;*_red.tif$&quot;, 
    recursive = TRUE, include.dirs = TRUE), 10, 16))
nm.vi.index &lt;- na.omit(cbind(seq(1, length(nm.bfdf.list), 1), match(nm.bfdf.list, 
    nm.vi.list, incomparables = TRUE)))[, 1]
nm.vi.index.mod &lt;- mixedsort(c(nm.vi.index, 319))
red.nm.sub &lt;- red.nm[nm.vi.index.mod]  ###Missing 2007017 b/c no QA layer, add scene 319 = 2007025 instead
nir.nm.sub &lt;- nir.nm[nm.vi.index.mod]
swir1.nm.sub &lt;- swir1.nm[nm.vi.index.mod]
swir2.nm.sub &lt;- swir2.nm[nm.vi.index.mod]
brdf.qa.nm.sub &lt;- brdf.qa.nm[nm.vi.index.mod]

CO_NDVI_list &lt;- unstack(stack(ndvi.co, bands = 1))
CO_QA_VI_list &lt;- unstack(stack(qa.vi.co, bands = 1))
CO_EVI_list &lt;- unstack(stack(evi.co, bands = 1))
CO_VI_RED_list &lt;- unstack(stack(vi.red.co, bands = 1))
CO_VI_SWIR2_list &lt;- unstack(stack(vi.swir2.co, bands = 1))
CO_RED_list &lt;- unstack(stack(red.co.sub, bands = 1))
CO_NIR_list &lt;- unstack(stack(nir.co.sub, bands = 1))
CO_SWIR1_list &lt;- unstack(stack(swir1.co.sub, bands = 1))
CO_SWIR2_list &lt;- unstack(stack(swir2.co.sub, bands = 1))
CO_BRDF_QA_list &lt;- unstack(stack(brdf.qa.co.sub, bands = 1))
CO_Landcover_list &lt;- unstack(stack(landcover.co, bands = 1))
CO_Landcover_QA_list &lt;- unstack(stack(landcover.qa.co, bands = 1))
CO_LST_Day_Sub_list &lt;- unstack(stack(day.lst.co.sub, bands = 1))
CO_LST_QA_Day_Sub_list &lt;- unstack(stack(day.qa.co.sub, bands = 1))
CO_LST_Night_Sub_list &lt;- unstack(stack(night.lst.co.sub, bands = 1))
CO_LST_QA_Night_Sub_list &lt;- unstack(stack(night.qa.co.sub, bands = 1))

NM_NDVI_list &lt;- unstack(stack(ndvi.nm, bands = 1))
NM_QA_VI_list &lt;- unstack(stack(qa.vi.nm, bands = 1))
NM_EVI_list &lt;- unstack(stack(evi.nm, bands = 1))
NM_VI_RED_list &lt;- unstack(stack(vi.red.nm, bands = 1))
NM_VI_SWIR2_list &lt;- unstack(stack(vi.swir2.nm, bands = 1))
NM_RED_list &lt;- unstack(stack(red.nm.sub, bands = 1))
NM_NIR_list &lt;- unstack(stack(nir.nm.sub, bands = 1))
NM_SWIR1_list &lt;- unstack(stack(swir1.nm.sub, bands = 1))
NM_SWIR2_list &lt;- unstack(stack(swir2.nm.sub, bands = 1))
NM_BRDF_QA_list &lt;- unstack(stack(brdf.qa.nm.sub, bands = 1))
NM_Landcover_list &lt;- unstack(stack(landcover.nm, bands = 1))
NM_Landcover_QA_list &lt;- unstack(stack(landcover.qa.nm, bands = 1))
NM_LST_Day_Sub_list &lt;- unstack(stack(day.lst.nm.sub, bands = 1))
NM_LST_QA_Day_Sub_list &lt;- unstack(stack(day.qa.nm.sub, bands = 1))
NM_LST_Night_Sub_list &lt;- unstack(stack(night.lst.nm.sub, bands = 1))
NM_LST_QA_Night_Sub_list &lt;- unstack(stack(night.qa.nm.sub, bands = 1))


#################################### MODIS VI timeseries
#################################### ################################################### Create VI Mask CO
#################################### mask
vi.mask &lt;- CO_QA_VI_list
vi.mask.final &lt;- vi.mask
vi.mask.final &lt;- foreach(i = 1:length(vi.mask), .packages = c(&quot;raster&quot;, 
    &quot;rgdal&quot;)) %dopar% {
    vi.mask.layer &lt;- vi.mask[[i]]
    vi.mask.layer[vi.mask.layer == 2] &lt;- NA
    vi.mask.layer[vi.mask.layer == 3] &lt;- NA
    vi.mask.layer[vi.mask.layer == 0] &lt;- 1
    vi.mask.final[[i]] &lt;- vi.mask.layer
}
writeRaster(stack(vi.mask.final), filename = &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_VI_250M/CO_VI_QA_Mask_final.tif&quot;, 
    format = &quot;GTiff&quot;, overwrite = T, options = &quot;INTERLEAVE=BAND&quot;, dataType = &quot;INT1U&quot;)
co.vi.mask.final &lt;- brick(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_VI_250M/CO_VI_QA_Mask_final.tif&quot;)
co.vi.mask.final.list &lt;- unstack(vi.mask.final)

# NM mask
nm.vi.mask &lt;- NM_QA_VI_list
nm.vi.mask.final &lt;- nm.vi.mask
nm.vi.mask.final &lt;- foreach(i = 1:length(nm.vi.mask), .packages = c(&quot;raster&quot;, 
    &quot;rgdal&quot;)) %dopar% {
    nm.vi.mask.layer &lt;- nm.vi.mask[[i]]
    nm.vi.mask.layer[nm.vi.mask.layer == 2] &lt;- NA
    nm.vi.mask.layer[nm.vi.mask.layer == 3] &lt;- NA
    nm.vi.mask.layer[nm.vi.mask.layer == 0] &lt;- 1
    nm.vi.mask.final[[i]] &lt;- nm.vi.mask.layer
}
writeRaster(stack(nm.vi.mask.final), filename = &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_VI_250M/NM_VI_QA_Mask_final.tif&quot;, 
    format = &quot;GTiff&quot;, overwrite = T, bylayer = TRUE, dataType = &quot;INT1U&quot;)
nm.vi.mask.final &lt;- stack(mixedsort(preStack(path = &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_VI_250M/&quot;, 
    pattern = &quot;*NM_VI_QA_Mask_final*&quot;)))
nm.vi.mask.final.list &lt;- unstack(nm.vi.mask.final)

### Create timestamp
co.date &lt;- (orgTime(ndvi.co, nDays = 16, begin = &quot;2000049&quot;, pillow = 0))
nm.date &lt;- (orgTime(ndvi.nm, nDays = 16, begin = &quot;2000049&quot;, pillow = 0))
co.date.lst &lt;- (orgTime(day.lst.co.sub, nDays = 16, begin = &quot;2000049&quot;, 
    pillow = 0))
nm.date.lst &lt;- (orgTime(day.lst.nm.sub, nDays = 16, begin = &quot;2000049&quot;, 
    pillow = 0))

#-------------------------------------------------------------------------------------------------
# functions for infilling
#-------------------------------------------------------------------------------------------------
foreach.raster.timeseries.run &lt;- function(x, filename, fun, dates, rescale) {
    outDate &lt;- dates$inputLayerDates
    out &lt;- brick(x, nl = length(outDate), values = FALSE)
    out &lt;- writeStart(out, filename, format = &quot;GTiff&quot;, overwrite = TRUE)
    bs &lt;- blockSize(x)
    pb &lt;- pbCreate(bs$n)
    bs &lt;- blockSize(x, minblocks = bs$n * 2)
    pb &lt;- txtProgressBar(min = 1, max = bs$n, style = 3)
    todisk &lt;- TRUE
    for (i in 1:bs$n) {
        v &lt;- getValuesBlock(x, row = bs$row[i], nrows = bs$nrows[i])
        vv &lt;- array(, dim = c(nrow(v), length(outDate)))
        vvv &lt;- foreach.raster.timeseries(v, vv, fun, outDate, rescale)
        vvvv &lt;- do.call(&quot;rbind&quot;, lapply(vvv, array))
        out &lt;- writeValues(out, vvvv, bs$row[i])
        setTxtProgressBar(pb, i)
    }
    out &lt;- writeStop(out)
    return(out)
    close(pb)
}


foreach.raster.timeseries &lt;- function(v, vv, fun, outDate, rescale) {
    vv &lt;- foreach(i = 1:nrow(v), .packages = c(&quot;bfast&quot;, &quot;zoo&quot;, &quot;MODIS&quot;, 
        &quot;signal&quot;, &quot;imputeTS&quot;, &quot;data.table&quot;, &quot;raster&quot;)) %dopar% {
        vv[i, ] &lt;- t(apply(t(as.matrix(v[i, ])), 1, fun, outDate, rescale))
    }
    
}


# bfastts infill function set up to remove the first three observations
# from each timeseries
bfastts.infill &lt;- function(data, outDate, rescale) {
    if (length(na.omit(data)) &lt; 2) {
        tso &lt;- data
    } else {
        z &lt;- zoo(data * rescale, outDate)
        
        # This runs a sgolay filter to smooth out the time series
        tso &lt;- ts(sgolayfilt(na.interpolation(as.numeric(z), option = &quot;stine&quot;)), 
            frequency = (365.25/16), start = start(z))  ####modified part of bfastts code to account for leap year
    }
    return(tso)
}

#-------------------------------------------------------------------------------------------------

#--------------------------------------------- CO mask and infill
################# Execute Mask NDVI
CO_NDVI_mask &lt;- CO_NDVI_list
CO_NDVI_mask &lt;- foreach(i = 1:length(CO_NDVI_list), .packages = c(&quot;raster&quot;, 
    &quot;rgdal&quot;)) %dopar% {
    CO_NDVI_mask[[i]] &lt;- mask(CO_NDVI_list[[i]], vi.mask.final.list[[i]])
}
writeRaster(stack(CO_NDVI_mask), filename = &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_VI_250M/CO_NDVI_Mask.tif&quot;, 
    format = &quot;GTiff&quot;, overwrite = T, options = &quot;INTERLEAVE=BAND&quot;, dataType = &quot;INT2S&quot;)
CO_NDVI_mask &lt;- brick(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_VI_250M/CO_NDVI_Mask.tif&quot;)
CO_NDVI_mask &lt;- unstack(CO_NDVI_mask)

stime &lt;- system.time({
    CO_infill.ndvi &lt;- foreach.raster.timeseries.run(CO_NDVI_mask, filename = &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_VI_250M/CO_NDVI_infill.tif&quot;, 
        fun = bfastts.infill, dates = co.date, rescale = 1e-04)
})[3]
stime
CO_infill.ndvi &lt;- brick(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_VI_250M/CO_NDVI_infill.tif&quot;)
################# Execute Mask EVI
CO_EVI_mask &lt;- CO_EVI_list
CO_EVI_mask &lt;- foreach(i = 1:length(CO_EVI_list), .packages = c(&quot;raster&quot;, 
    &quot;rgdal&quot;)) %dopar% {
    CO_EVI_mask[[i]] &lt;- mask(CO_EVI_list[[i]], vi.mask.final.list[[i]])
}
writeRaster(stack(CO_EVI_mask), filename = &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_VI_250M/CO_EVI_Mask.tif&quot;, 
    format = &quot;GTiff&quot;, overwrite = T, options = &quot;INTERLEAVE=BAND&quot;, dataType = &quot;INT2S&quot;)
CO_EVI_mask &lt;- brick(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_VI_250M/CO_EVI_Mask.tif&quot;)
CO_EVI_mask &lt;- unstack(CO_EVI_mask)

stime &lt;- system.time({
    CO_infill.evi &lt;- foreach.raster.timeseries.run(CO_EVI_mask, filename = &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_VI_250M/CO_EVI_infill.tif&quot;, 
        fun = bfastts.infill, dates = co.date, rescale = 1e-04)
})[3]
stime
CO_infill.evi &lt;- brick(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_VI_250M/CO_EVI_infill.tif&quot;)
################# Execute Mask Red
CO_VI_RED_mask &lt;- CO_VI_RED_list
CO_VI_RED_mask &lt;- foreach(i = 1:length(CO_VI_RED_list), .packages = c(&quot;raster&quot;, 
    &quot;rgdal&quot;)) %dopar% {
    CO_VI_RED_mask[[i]] &lt;- mask(CO_VI_RED_list[[i]], vi.mask.final.list[[i]])
}
writeRaster(stack(CO_VI_RED_mask), filename = &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_VI_250M/CO_VI_RED_Mask.tif&quot;, 
    format = &quot;GTiff&quot;, overwrite = T, options = &quot;INTERLEAVE=BAND&quot;, dataType = &quot;INT2S&quot;)
CO_VI_RED_mask &lt;- brick(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_VI_250M/CO_VI_RED_Mask.tif&quot;)
CO_VI_RED_mask &lt;- unstack(CO_VI_RED_mask)

stime &lt;- system.time({
    CO_infill.vi.red &lt;- foreach.raster.timeseries.run(CO_VI_RED_mask, filename = &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_VI_250M/CO_VI_RED_infill.tif&quot;, 
        fun = bfastts.infill, dates = co.date, rescale = 1e-04)
})[3]
stime
CO_infill.vi.red &lt;- brick(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_VI_250M/CO_VI_RED_infill.tif&quot;)
################# Execute Mask SWIR2
CO_VI_SWIR2_mask &lt;- CO_VI_SWIR2_list
CO_VI_SWIR2_mask &lt;- foreach(i = 1:length(CO_VI_SWIR2_list), .packages = c(&quot;raster&quot;, 
    &quot;rgdal&quot;)) %dopar% {
    CO_VI_SWIR2_mask[[i]] &lt;- mask(CO_VI_SWIR2_list[[i]], vi.mask.final.list[[i]])
}
writeRaster(stack(CO_VI_SWIR2_mask), filename = &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_VI_250M/CO_VI_SWIR2_Mask.tif&quot;, 
    format = &quot;GTiff&quot;, overwrite = T, options = &quot;INTERLEAVE=BAND&quot;, dataType = &quot;INT2S&quot;)
CO_VI_SWIR2_mask &lt;- brick(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_VI_250M/CO_VI_SWIR2_Mask.tif&quot;)
CO_VI_SWIR2_mask &lt;- unstack(CO_VI_SWIR2_mask)

stime &lt;- system.time({
    CO_infill.vi.swir2 &lt;- foreach.raster.timeseries.run(CO_VI_SWIR2_mask, 
        filename = &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_VI_250M/CO_VI_SWIR2_infill.tif&quot;, 
        fun = bfastts.infill, dates = co.date, rescale = 1e-04)
})[3]
stime
CO_infill.vi.swir2 &lt;- brick(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_VI_250M/CO_VI_SWIR2_infill.tif&quot;)

# NM mask and infill Execute Mask NDVI
NM_NDVI_mask &lt;- NM_NDVI_list
NM_NDVI_mask &lt;- foreach(i = 1:length(NM_NDVI_list), .packages = c(&quot;raster&quot;, 
    &quot;rgdal&quot;)) %dopar% {
    NM_NDVI_mask[[i]] &lt;- mask(NM_NDVI_list[[i]], nm.vi.mask.final.list[[i]])
}
writeRaster(stack(NM_NDVI_mask), filename = &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_VI_250M/NM_NDVI_Mask.tif&quot;, 
    format = &quot;GTiff&quot;, overwrite = T, options = &quot;INTERLEAVE=BAND&quot;, dataType = &quot;INT2S&quot;)
NM_NDVI_mask &lt;- brick(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_VI_250M/NM_NDVI_Mask.tif&quot;)
NM_NDVI_mask &lt;- unstack(NM_NDVI_mask)

stime &lt;- system.time({
    NM_infill.ndvi &lt;- foreach.raster.timeseries.run(NM_NDVI_mask, filename = &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_VI_250M/NM_NDVI_infill.tif&quot;, 
        fun = bfastts.infill, dates = nm.date, rescale = 1e-04)
})[3]
stime
NM_infill.ndvi &lt;- brick(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_VI_250M/NM_NDVI_infill.tif&quot;)

################# Execute Mask EVI
NM_EVI_mask &lt;- NM_EVI_list
NM_EVI_mask &lt;- foreach(i = 1:length(NM_EVI_list), .packages = c(&quot;raster&quot;, 
    &quot;rgdal&quot;)) %dopar% {
    NM_EVI_mask[[i]] &lt;- mask(NM_EVI_list[[i]], nm.vi.mask.final.list[[i]])
}
writeRaster(stack(NM_EVI_mask), filename = &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_VI_250M/NM_EVI_Mask.tif&quot;, 
    format = &quot;GTiff&quot;, overwrite = T, options = &quot;INTERLEAVE=BAND&quot;, dataType = &quot;INT2S&quot;)
NM_EVI_mask &lt;- brick(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_VI_250M/NM_EVI_Mask.tif&quot;)
NM_EVI_mask &lt;- unstack(NM_EVI_mask)

stime &lt;- system.time({
    NM_infill.evi &lt;- foreach.raster.timeseries.run(NM_EVI_mask, filename = &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_VI_250M/NM_EVI_infill.tif&quot;, 
        fun = bfastts.infill, dates = nm.date, rescale = 1e-04)
})[3]
stime
NM_infill.evi &lt;- brick(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_VI_250M/NM_EVI_infill.tif&quot;)

################# Execute Mask Red
NM_VI_RED_mask &lt;- NM_VI_RED_list
NM_VI_RED_mask &lt;- foreach(i = 1:length(NM_VI_RED_list), .packages = c(&quot;raster&quot;, 
    &quot;rgdal&quot;)) %dopar% {
    NM_VI_RED_mask[[i]] &lt;- mask(NM_VI_RED_list[[i]], nm.vi.mask.final.list[[i]])
}
writeRaster(stack(NM_VI_RED_mask), filename = &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_VI_250M/NM_VI_RED_Mask.tif&quot;, 
    format = &quot;GTiff&quot;, overwrite = T, options = &quot;INTERLEAVE=BAND&quot;, dataType = &quot;INT2S&quot;)
NM_VI_RED_mask &lt;- brick(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_VI_250M/NM_VI_RED_Mask.tif&quot;)
NM_VI_RED_mask &lt;- unstack(NM_VI_RED_mask)

stime &lt;- system.time({
    NM_infill.vi.red &lt;- foreach.raster.timeseries.run(NM_VI_RED_mask, filename = &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_VI_250M/NM_VI_RED_infill.tif&quot;, 
        fun = bfastts.infill, dates = nm.date, rescale = 1e-04)
})[3]
stime
NM_infill.vi.red &lt;- brick(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_VI_250M/NM_VI_RED_infill.tif&quot;)

################# Execute Mask SWIR2
NM_VI_SWIR2_mask &lt;- NM_VI_SWIR2_list
NM_VI_SWIR2_mask &lt;- foreach(i = 1:length(NM_VI_SWIR2_list), .packages = c(&quot;raster&quot;, 
    &quot;rgdal&quot;)) %dopar% {
    NM_VI_SWIR2_mask[[i]] &lt;- mask(NM_VI_SWIR2_list[[i]], nm.vi.mask.final.list[[i]])
}
writeRaster(stack(NM_VI_SWIR2_mask), filename = &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_VI_250M/NM_VI_SWIR2_Mask.tif&quot;, 
    format = &quot;GTiff&quot;, overwrite = T, options = &quot;INTERLEAVE=BAND&quot;, dataType = &quot;INT2S&quot;)
NM_VI_SWIR2_mask &lt;- brick(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_VI_250M/NM_VI_SWIR2_Mask.tif&quot;)
NM_VI_SWIR2_mask &lt;- unstack(NM_VI_SWIR2_mask)

stime &lt;- system.time({
    NM_infill.vi.swir2 &lt;- foreach.raster.timeseries.run(NM_VI_SWIR2_mask, 
        filename = &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_VI_250M/NM_VI_SWIR2_infill.tif&quot;, 
        fun = bfastts.infill, dates = nm.date, rescale = 1e-04)
})[3]
stime
NM_infill.vi.swir2 &lt;- brick(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_VI_250M/NM_VI_SWIR2_infill.tif&quot;)
#-------------------------------------------------------------------------------------------------

#-------------------------------------------------------------------------------------------------
#################### RASTER BRDF QA PROCESSING #######################################
#-------------------------------------------------------------------------------------------------

#### CO Study area
#-------------------------------------------------------------------------------------------------

######### create mask
stime &lt;- system.time({
    CO_BRDF_QA_mask &lt;- CO_BRDF_QA_list
    CO_BRDF_QA_mask &lt;- foreach(i = 1:length(CO_BRDF_QA_list), .packages = c(&quot;raster&quot;)) %dopar% 
        {
            CO_BRDF_QA_list.i &lt;- CO_BRDF_QA_list[[i]]
            CO_BRDF_QA_list.i[CO_BRDF_QA_list.i == 0] &lt;- 1
            CO_BRDF_QA_list.i[is.na(CO_BRDF_QA_list.i)] &lt;- 0
            CO_BRDF_QA_mask[[i]] &lt;- CO_BRDF_QA_list.i
        }
})[3]
stime

writeRaster(stack(CO_BRDF_QA_mask), filename = &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_Modis_BRDF/CO_BRDF_QA_mask.tif&quot;, 
    format = &quot;GTiff&quot;, overwrite = T, options = &quot;INTERLEAVE=BAND&quot;, dataType = &quot;INT2U&quot;)
CO_BRDF_QA_mask &lt;- brick(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_Modis_BRDF/CO_BRDF_QA_mask.tif&quot;)
CO_BRDF_QA_mask &lt;- unstack(CO_BRDF_QA_mask)
#########----------------------------------------------------------------------------------------------
######### SWIR1 masking and infilling Mask SWIR1
stime2 &lt;- system.time({
    CO_SWIR1_mask &lt;- CO_SWIR1_list
    CO_SWIR1_mask &lt;- foreach(i = 1:length(CO_SWIR1_mask), .packages = c(&quot;raster&quot;, 
        &quot;rgdal&quot;)) %dopar% {
        CO_SWIR1_mask[[i]] &lt;- mask(CO_SWIR1_mask[[i]], (CO_BRDF_QA_mask[[i]]))
    }
    
    writeRaster(stack(CO_SWIR1_mask), filename = &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_Modis_BRDF/CO_SWIR1_Mask.tif&quot;, 
        format = &quot;GTiff&quot;, overwrite = T, options = &quot;INTERLEAVE=BAND&quot;, dataType = &quot;INT2U&quot;)
    
})[3]
stime2
CO_SWIR1_mask &lt;- brick(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_Modis_BRDF/CO_SWIR1_Mask.tif&quot;)

################# Infill SWIR1
stime3 &lt;- system.time({
    CO_SWIR1_infill &lt;- foreach.raster.timeseries.run(CO_SWIR1_mask, filename = &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_Modis_BRDF/CO_SWIR1_infill.tif&quot;, 
        fun = bfastts.infill, dates = co.date, rescale = 1e-04)
})[3]
stime3

CO_SWIR1_infill &lt;- brick(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_Modis_BRDF/CO_SWIR1_infill.tif&quot;)
#-------------------------------------------------------------------------------------------------
######### SWIR2 masking and infilling Mask SWIR2
stime2 &lt;- system.time({
    CO_SWIR2_mask &lt;- CO_SWIR2_list
    CO_SWIR2_mask &lt;- foreach(i = 1:length(CO_SWIR2_mask), .packages = c(&quot;raster&quot;, 
        &quot;rgdal&quot;)) %do% {
        CO_SWIR2_mask[[i]] &lt;- mask(CO_SWIR2_mask[[i]], (CO_BRDF_QA_mask[[i]]))
    }
    
    writeRaster(stack(CO_SWIR2_mask), filename = &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_Modis_BRDF/CO_SWIR2_Mask.tif&quot;, 
        format = &quot;GTiff&quot;, overwrite = T, options = &quot;INTERLEAVE=BAND&quot;, dataType = &quot;INT2U&quot;)
    
})[3]
stime2
CO_SWIR2_mask &lt;- brick(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_Modis_BRDF/CO_SWIR2_Mask.tif&quot;)
################# Infill SWIR2
stime3 &lt;- system.time({
    CO_SWIR2_infill &lt;- foreach.raster.timeseries.run(CO_SWIR2_mask, filename = &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_Modis_BRDF/CO_SWIR2_infill.tif&quot;, 
        fun = bfastts.infill, dates = co.date, rescale = 1e-04)
})[3]
stime3
CO_SWIR2_infill &lt;- brick(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_Modis_BRDF/CO_SWIR2_infill.tif&quot;)
#-------------------------------------------------------------------------------------------------
# unstack raster bricks
CO_SWIR1_infill_list &lt;- unstack(CO_SWIR1_infill)
CO_infill.vi.swir2_list &lt;- unstack(CO_infill.vi.swir2)
CO_infill.vi.red_list &lt;- unstack(CO_infill.vi.red)
# Calculate SATVI on raster brick
CO_SATVI_infill &lt;- CO_infill.vi.red_list
CO_SATVI_infill &lt;- foreach(i = 1:length(CO_infill.vi.red_list), .packages = c(&quot;raster&quot;, 
    &quot;rgdal&quot;)) %dopar% {
    CO_SATVI_infill[[i]] &lt;- (((CO_SWIR1_infill_list[[i]] - CO_infill.vi.red_list[[i]])/(CO_SWIR1_infill_list[[i]] + 
        CO_infill.vi.red_list[[i]] + 0.5)) * (1 + 0.5) - (CO_infill.vi.swir2_list[[i]]/2))
    
}
writeRaster(stack(CO_SATVI_infill), filename = &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_VI_250M/CO_SATVI_Infill.tif&quot;, 
    format = &quot;GTiff&quot;, overwrite = T, options = &quot;INTERLEAVE=BAND&quot;, dataType = &quot;INT2S&quot;)
CO_SATVI_infill &lt;- brick(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_VI_250M/CO_SATVI_Infill.tif&quot;)

#-------------------------------------------------------------------------------------------------
#-------------------------------------------------------------------------------------------------

#### NM Study area
#-------------------------------------------------------------------------------------------------

######### create mask
stime &lt;- system.time({
    NM_BRDF_QA_mask &lt;- NM_BRDF_QA_list
    NM_BRDF_QA_mask &lt;- foreach(i = 1:length(NM_BRDF_QA_list), .packages = c(&quot;raster&quot;)) %dopar% 
        {
            NM_BRDF_QA_list.i &lt;- NM_BRDF_QA_list[[i]]
            NM_BRDF_QA_list.i[NM_BRDF_QA_list.i == 0] &lt;- 1
            NM_BRDF_QA_list.i[is.na(NM_BRDF_QA_list.i)] &lt;- 0
            NM_BRDF_QA_mask[[i]] &lt;- NM_BRDF_QA_list.i
        }
})[3]
stime

writeRaster(stack(NM_BRDF_QA_mask), filename = &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_Modis_BRDF/NM_BRDF_QA_mask.tif&quot;, 
    format = &quot;GTiff&quot;, overwrite = T, options = &quot;INTERLEAVE=BAND&quot;, dataType = &quot;INT2U&quot;)
NM_BRDF_QA_mask &lt;- brick(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_Modis_BRDF/NM_BRDF_QA_mask.tif&quot;)

######## SWIR1 masking and infilling Mask SWIR1
stime2 &lt;- system.time({
    NM_SWIR1_mask &lt;- NM_SWIR1_list
    NM_SWIR1_mask &lt;- foreach(i = 1:length(NM_SWIR1_mask), .packages = c(&quot;raster&quot;, 
        &quot;rgdal&quot;)) %do% {
        NM_SWIR1_mask[[i]] &lt;- mask(NM_SWIR1_mask[[i]], (NM_BRDF_QA_mask[[i]]))
    }
    
    writeRaster(stack(NM_SWIR1_mask), filename = &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_Modis_BRDF/NM_SWIR1_Mask.tif&quot;, 
        format = &quot;GTiff&quot;, overwrite = T, options = &quot;INTERLEAVE=BAND&quot;, dataType = &quot;INT2U&quot;)
    NM_SWIR1_mask &lt;- brick(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_Modis_BRDF/NM_SWIR1_Mask.tif&quot;)
})[3]
stime2
################# Infill SWIR1
stime3 &lt;- system.time({
    NM_SWIR1_infill &lt;- foreach.raster.timeseries.run(NM_SWIR1_mask, filename = &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_Modis_BRDF/NM_SWIR1_infill.tif&quot;, 
        fun = bfastts.infill, dates = nm.date, rescale = 1e-04)
})[3]
stime3
#-------------------------------------------------------------------------------------------------

######################## SWIR2 masking and infilling Mask SWIR2
stime2 &lt;- system.time({
    NM_SWIR2_mask &lt;- NM_SWIR2_list
    NM_SWIR2_mask &lt;- foreach(i = 1:length(NM_SWIR2_mask), .packages = c(&quot;raster&quot;, 
        &quot;rgdal&quot;)) %do% {
        NM_SWIR2_mask[[i]] &lt;- mask(NM_SWIR2_mask[[i]], (NM_BRDF_QA_mask[[i]]))
    }
    
    writeRaster(stack(NM_SWIR2_mask), filename = &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_Modis_BRDF/NM_SWIR2_Mask.tif&quot;, 
        format = &quot;GTiff&quot;, overwrite = T, options = &quot;INTERLEAVE=BAND&quot;, dataType = &quot;INT2U&quot;)
    NM_SWIR2_mask &lt;- brick(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_Modis_BRDF/NM_SWIR2_Mask.tif&quot;)
})[3]
stime2
################# Infill SWIR2
stime3 &lt;- system.time({
    NM_SWIR2_infill &lt;- foreach.raster.timeseries.run(NM_SWIR2_mask, filename = &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_Modis_BRDF/NM_SWIR2_infill.tif&quot;, 
        fun = bfastts.infill, dates = nm.date, rescale = 1e-04)
})[3]
stime3

#-------------------------------------------------------------------------------------------------
# unstack raster bricks
NM_SWIR1_infill_list &lt;- unstack(NM_SWIR1_infill)
NM_infill.vi.swir2_list &lt;- unstack(NM_infill.vi.swir2)
NM_infill.vi.red_list &lt;- unstack(NM_infill.vi.red)
# Calculate SATVI on raster brick
NM_SATVI_infill &lt;- NM_infill.vi.red_list
NM_SATVI_infill &lt;- foreach(i = 1:length(NM_infill.vi.red_list), .packages = c(&quot;raster&quot;, 
    &quot;rgdal&quot;)) %dopar% {
    NM_SATVI_infill[[i]] &lt;- mask((((NM_SWIR1_infill_list[[i]] - NM_infill.vi.red_list[[i]])/(NM_SWIR1_infill_list[[i]] + 
        NM_infill.vi.red_list[[i]] + 0.5)) * (1 + 0.5) - (NM_infill.vi.swir2_list[[i]]/2)), 
        vi.mask.final.list[[i]])
    
}
writeRaster(stack(NM_SATVI_infill), filename = &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_VI_250M/NM_SATVI_Infill.tif&quot;, 
    format = &quot;GTiff&quot;, overwrite = T, options = &quot;INTERLEAVE=BAND&quot;, dataType = &quot;INT2S&quot;)
NM_SATVI_infill &lt;- brick(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_VI_250M/NM_SATVI_Infill.tif&quot;)


#-------------------------------------------------------------------------------------------------
############### Landcover #############################################
#-------------------------------------------------------------------------------------------------


## Landcover Error table
QC_Data_land &lt;- data.frame(Integer_Value = 0:255, Bit7 = NA, Bit6 = NA, 
    Bit5 = NA, Bit4 = NA, Bit3 = NA, Bit2 = NA, Bit1 = NA, Bit0 = NA, QA_word1 = NA, 
    QA_word2 = NA, QA_word3 = NA)

for (i in QC_Data_land$Integer_Value) {
    AsInt &lt;- as.integer(intToBits(i)[1:8])
    QC_Data_land[i + 1, 2:9] &lt;- AsInt[8:1]
}

# Quality
QC_Data_land$QA_word1[QC_Data_land$Bit1 == 0 &amp; QC_Data_land$Bit0 == 0] &lt;- &quot;Good Quality&quot;
QC_Data_land$QA_word1[QC_Data_land$Bit1 == 0 &amp; QC_Data_land$Bit0 == 1] &lt;- &quot;Other Quality&quot;
QC_Data_land$QA_word1[QC_Data_land$Bit1 == 1 &amp; QC_Data_land$Bit0 == 0] &lt;- &quot;No Pixel,clouds&quot;
QC_Data_land$QA_word1[QC_Data_land$Bit1 == 1 &amp; QC_Data_land$Bit0 == 1] &lt;- &quot;No Pixel, Other QA&quot;

# Qarters sinced updated
QC_Data_land$QA_word2[QC_Data_land$Bit3 == 0 &amp; QC_Data_land$Bit2 == 0] &lt;- &quot;0 Quarter&quot;
QC_Data_land$QA_word2[QC_Data_land$Bit3 == 0 &amp; QC_Data_land$Bit2 == 1] &lt;- &quot;1 Quarter&quot;
QC_Data_land$QA_word2[QC_Data_land$Bit3 == 1 &amp; QC_Data_land$Bit2 == 0] &lt;- &quot;2 Quarter&quot;
QC_Data_land$QA_word2[QC_Data_land$Bit3 == 1 &amp; QC_Data_land$Bit2 == 1] &lt;- &quot;3 Quarter&quot;

# Land-water mask
QC_Data_land$QA_word3[QC_Data_land$Bit7 == 0 &amp; QC_Data_land$Bit6 == 0 &amp; 
    QC_Data_land$Bit5 == 0 &amp; QC_Data_land$Bit4 == 0] &lt;- &quot;Shallow Ocean&quot;
QC_Data_land$QA_word3[QC_Data_land$Bit7 == 0 &amp; QC_Data_land$Bit6 == 0 &amp; 
    QC_Data_land$Bit5 == 0 &amp; QC_Data_land$Bit4 == 1] &lt;- &quot;Land&quot;
QC_Data_land$QA_word3[QC_Data_land$Bit7 == 0 &amp; QC_Data_land$Bit6 == 0 &amp; 
    QC_Data_land$Bit5 == 1 &amp; QC_Data_land$Bit4 == 0] &lt;- &quot;Ocean coastlines&quot;
QC_Data_land$QA_word3[QC_Data_land$Bit7 == 0 &amp; QC_Data_land$Bit6 == 0 &amp; 
    QC_Data_land$Bit5 == 1 &amp; QC_Data_land$Bit4 == 1] &lt;- &quot;Shallow inland&quot;
QC_Data_land$QA_word3[QC_Data_land$Bit7 == 0 &amp; QC_Data_land$Bit6 == 1 &amp; 
    QC_Data_land$Bit5 == 0 &amp; QC_Data_land$Bit4 == 0] &lt;- &quot;Ephemeral water&quot;
QC_Data_land$QA_word3[QC_Data_land$Bit7 == 0 &amp; QC_Data_land$Bit6 == 1 &amp; 
    QC_Data_land$Bit5 == 0 &amp; QC_Data_land$Bit4 == 1] &lt;- &quot;Deep inland water&quot;
QC_Data_land$QA_word3[QC_Data_land$Bit7 == 0 &amp; QC_Data_land$Bit6 == 1 &amp; 
    QC_Data_land$Bit5 == 1 &amp; QC_Data_land$Bit4 == 0] &lt;- &quot;Continental Ocean&quot;
QC_Data_land$QA_word3[QC_Data_land$Bit7 == 0 &amp; QC_Data_land$Bit6 == 1 &amp; 
    QC_Data_land$Bit5 == 1 &amp; QC_Data_land$Bit4 == 1] &lt;- &quot;Deep Ocean&quot;
QC_Data_land$QA_word3[QC_Data_land$Bit7 == 1 &amp; QC_Data_land$Bit6 == 0 &amp; 
    QC_Data_land$Bit5 == 0 &amp; QC_Data_land$Bit4 == 0] &lt;- &quot;NA&quot;
QC_Data_land$QA_word3[QC_Data_land$Bit7 == 1 &amp; QC_Data_land$Bit6 == 0 &amp; 
    QC_Data_land$Bit5 == 0 &amp; QC_Data_land$Bit4 == 1] &lt;- &quot;NA&quot;
QC_Data_land$QA_word3[QC_Data_land$Bit7 == 1 &amp; QC_Data_land$Bit6 == 0 &amp; 
    QC_Data_land$Bit5 == 1 &amp; QC_Data_land$Bit4 == 0] &lt;- &quot;NA&quot;
QC_Data_land$QA_word3[QC_Data_land$Bit7 == 1 &amp; QC_Data_land$Bit6 == 0 &amp; 
    QC_Data_land$Bit5 == 1 &amp; QC_Data_land$Bit4 == 1] &lt;- &quot;NA&quot;
QC_Data_land$QA_word3[QC_Data_land$Bit7 == 1 &amp; QC_Data_land$Bit6 == 1 &amp; 
    QC_Data_land$Bit5 == 0 &amp; QC_Data_land$Bit4 == 0] &lt;- &quot;NA&quot;
QC_Data_land$QA_word3[QC_Data_land$Bit7 == 1 &amp; QC_Data_land$Bit6 == 1 &amp; 
    QC_Data_land$Bit5 == 0 &amp; QC_Data_land$Bit4 == 1] &lt;- &quot;NA&quot;
QC_Data_land$QA_word3[QC_Data_land$Bit7 == 1 &amp; QC_Data_land$Bit6 == 1 &amp; 
    QC_Data_land$Bit5 == 1 &amp; QC_Data_land$Bit4 == 0] &lt;- &quot;NA&quot;
QC_Data_land$QA_word3[QC_Data_land$Bit7 == 1 &amp; QC_Data_land$Bit6 == 1 &amp; 
    QC_Data_land$Bit5 == 1 &amp; QC_Data_land$Bit4 == 1] &lt;- &quot;NA&quot;
#-------------------------------------------------------------------------------------------------

# Function to QA and filter MODIS timeseries
modis.time.filter.landcover &lt;- function(data, qa) {
    data.filter &lt;- matrix(data = NA, nrow = nrow(data), ncol = ncol(data))
    for (i in 1:nrow(data)) {
        data.i &lt;- data[i, ]
        qa.i &lt;- qa[i, ]
        data.mask &lt;- data.i * qa.i
        if (length(na.omit(data.mask)) &lt; 2) {
            data.filter[i, ] &lt;- data.mask
        } else {
            data.filter[i, ] &lt;- na.interpolation(as.numeric(data.i * qa.i), 
                option = &quot;stine&quot;)
        }
    }
    return(data.filter)
}

# Landcover QA filter
#------Landcover classes
# Water, Evergreen Needleleaf forest, Evergreen Broadleaf forest,
# Deciduous Needleleaf forest, Deciduous Broadleaf forest, Mixed
# forest, Closed shrublands, Open shrublands, Woody savannas, Savannas,
# Grasslands, Permanent wetlands, Croplands, Urban, Cropland/Natural
# vegetation mosaic, Snow and ice, Barren or sparsely vegetated,
# Unclassified, Fill Value

land.class &lt;- data.table(rbind(c(0, &quot;WA&quot;), c(1, &quot;ENF&quot;), c(2, &quot;EBF&quot;), c(3, 
    &quot;DNF&quot;), c(4, &quot;DBF&quot;), c(5, &quot;MF&quot;), c(6, &quot;CS&quot;), c(7, &quot;OS&quot;), c(8, &quot;WS&quot;), 
    c(9, &quot;SA&quot;), c(10, &quot;GR&quot;), c(11, &quot;PW&quot;), c(12, &quot;CR&quot;), c(13, &quot;UR&quot;), c(14, 
        &quot;CNVM&quot;), c(15, &quot;SI&quot;), c(16, &quot;BSV&quot;), c(254, &quot;UN&quot;), c(255, &quot;FV&quot;)))




names(land.class) &lt;- c(&quot;ID&quot;, &quot;Cover&quot;)
land.class &lt;- data.frame(land.class)
land.class$ID &lt;- as.numeric(land.class$ID)

#-------------------------------------------------------------------------------------------------
#### CO landcover QA filtering ############

# Point filtering get unique QA values
co.landcover.qa.unique &lt;- unique(as.vector(co.points.landcover.qa))
co.landcover.qa.unique[is.na(co.landcover.qa.unique)] &lt;- 0
# now subset QA_Data to extract only relevant QA integers
co.landcover.qa.unique &lt;- subset(QC_Data_land, Integer_Value %in% co.landcover.qa.unique)
# select all with good quality
co.VI.QA &lt;- subset(co.landcover.qa.unique, QA_word1 == &quot;Good Quality&quot; | 
    QA_word1 == &quot;Other Quality&quot;)
co.QA.int &lt;- co.VI.QA$Integer_Value
co.landcover.qa.mask &lt;- co.points.landcover.qa
co.landcover.qa.mask[is.na(co.landcover.qa.mask)] &lt;- 0
# First loop assigns all good pixels a value of 1 based on previous
# selection
for (i in 1:length(co.landcover.qa.mask)) {
    
    for (j in 1:length(co.QA.int)) {
        co.landcover.qa.mask[[i]][co.landcover.qa.mask[[i]] == co.QA.int[j]] &lt;- 1
        
    }
}
# Second loop assigns all values greater than 1 to NA
for (i in 1:length(co.landcover.qa.mask)) {
    co.landcover.qa.mask[[i]][co.landcover.qa.mask[[i]] &gt; 1] &lt;- NA
}

co.landcover &lt;- modis.time.filter.landcover(co.points.landcover, co.landcover.qa.mask)

###### NOTE: I&#39;ve decided not to use QA filtering of landcover data b/c
###### there is no way to infill values and although certain pixels may have
###### a higher uncertertanty, it is better than lots of holes with NA
###### values

# Using dummies library for one hot encoding:
co.landcover.2009 &lt;- co.points.landcover[, 9]
co.landcover.2009 &lt;- data.frame(co.landcover.2009)
names(co.landcover.2009) &lt;- c(&quot;ID&quot;)
co.landcover.2009.names &lt;- join(land.class, co.landcover.2009, by = &quot;ID&quot;, 
    type = &quot;right&quot;)
co.landcover.dummy &lt;- dummy.data.frame(co.landcover.2009.names, names = c(&quot;Cover&quot;), 
    sep = &quot;_&quot;)[, -1]

#-------------------------------------------------------------------------------------------------
#### NM landcover QA filtering ############

# get unique QA values
nm.landcover.qa.unique &lt;- unique(as.vector(nm.points.landcover.qa))
nm.landcover.qa.unique[is.na(nm.landcover.qa.unique)] &lt;- 0
# now subset QA_Data to extract only relevant QA integers
nm.landcover.qa.unique &lt;- subset(QC_Data_land, Integer_Value %in% nm.landcover.qa.unique)
# select all with good quality
nm.VI.QA &lt;- subset(nm.landcover.qa.unique, QA_word1 == &quot;Good Quality&quot; | 
    QA_word1 == &quot;Other Quality&quot;)
nm.QA.int &lt;- nm.VI.QA$Integer_Value
nm.landcover.qa.mask &lt;- nm.points.landcover.qa
nm.landcover.qa.mask[is.na(nm.landcover.qa.mask)] &lt;- 0
# First loop assigns all good pixels a value of 1 based on previous
# selection
for (i in 1:length(nm.landcover.qa.mask)) {
    
    for (j in 1:length(nm.QA.int)) {
        nm.landcover.qa.mask[[i]][nm.landcover.qa.mask[[i]] == nm.QA.int[j]] &lt;- 1
        
    }
}
# Second loop assigns all values greater than 1 to NA
for (i in 1:length(nm.landcover.qa.mask)) {
    nm.landcover.qa.mask[[i]][nm.landcover.qa.mask[[i]] &gt; 1] &lt;- NA
}

nm.landcover &lt;- modis.time.filter.landcover(nm.points.landcover, nm.landcover.qa.mask)

###### NOTE: I&#39;ve decided not to use QA filtering of landcover data b/c
###### there is no way to infill values and although certain pixels may have
###### a higher uncertertanty, it is better than lots of holes with NA
###### values Using dummies library for one hot encoding:
nm.landcover.2009 &lt;- nm.points.landcover[, 9]
nm.landcover.2009 &lt;- data.frame(nm.landcover.2009)
names(nm.landcover.2009) &lt;- c(&quot;ID&quot;)
nm.landcover.2009.names &lt;- join(land.class, nm.landcover.2009, by = &quot;ID&quot;, 
    type = &quot;right&quot;)
nm.landcover.dummy &lt;- dummy.data.frame(nm.landcover.2009.names, names = c(&quot;Cover&quot;), 
    sep = &quot;_&quot;)[, -1]

#-------------------------------------------------------------------------------------------------
### Landcover Raster Layers
co_landcover_raster.layer &lt;- layerize(CO_Landcover_list[[9]], filename = &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_Landcover_500M/CO_landcover_layers.tif&quot;, 
    format = &quot;GTiff&quot;, overwrite = T)
names(co_landcover_raster.layer) &lt;- land.class[, 2]
names(co_landcover_raster.layer) &lt;- paste0(&quot;Cover_&quot;, names(co_landcover_raster.layer))
co_landcover_raster.layer &lt;- brick(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_Landcover_500M/CO_landcover_layers.tif&quot;)

nm_landcover_raster.layer &lt;- layerize(NM_Landcover_list[[9]], filename = &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_Landcover_500M/NM_landcover_layers.tif&quot;, 
    format = &quot;GTiff&quot;, overwrite = T)
names(nm_landcover_raster.layer) &lt;- land.class[, 2]
names(nm_landcover_raster.layer) &lt;- paste0(&quot;Cover_&quot;, names(nm_landcover_raster.layer))
nm_landcover_raster.layer &lt;- brick(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_Landcover_500M/NM_landcover_layers.tif&quot;)

#-------------------------------------------------------------------------------------------------
############ LST ##############
#-------------------------------------------------------------------------------------------------
# LST Error table
QC_Data &lt;- data.frame(Integer_Value = 0:255, Bit7 = NA, Bit6 = NA, Bit5 = NA, 
    Bit4 = NA, Bit3 = NA, Bit2 = NA, Bit1 = NA, Bit0 = NA, QA_word1 = NA, 
    QA_word2 = NA, QA_word3 = NA, QA_word4 = NA)

for (i in QC_Data$Integer_Value) {
    AsInt &lt;- as.integer(intToBits(i)[1:8])
    QC_Data[i + 1, 2:9] &lt;- AsInt[8:1]
}

# VI Quality
QC_Data$QA_word1[QC_Data$Bit1 == 0 &amp; QC_Data$Bit0 == 0] &lt;- &quot;VI GOOD&quot;
QC_Data$QA_word1[QC_Data$Bit1 == 0 &amp; QC_Data$Bit0 == 1] &lt;- &quot;VI Produced,Other Quality&quot;
QC_Data$QA_word1[QC_Data$Bit1 == 1 &amp; QC_Data$Bit0 == 0] &lt;- &quot;No Pixel,clouds&quot;
QC_Data$QA_word1[QC_Data$Bit1 == 1 &amp; QC_Data$Bit0 == 1] &lt;- &quot;No Pixel, Other QA&quot;

# VI Usefullness
QC_Data$QA_word2[QC_Data$Bit3 == 0 &amp; QC_Data$Bit2 == 0] &lt;- &quot;Good Quality&quot;
QC_Data$QA_word2[QC_Data$Bit3 == 0 &amp; QC_Data$Bit2 == 1] &lt;- &quot;Other Quality&quot;
QC_Data$QA_word2[QC_Data$Bit3 == 1 &amp; QC_Data$Bit2 == 0] &lt;- &quot;TBD&quot;
QC_Data$QA_word2[QC_Data$Bit3 == 1 &amp; QC_Data$Bit2 == 1] &lt;- &quot;TBD&quot;

# Emis Error flag
QC_Data$QA_word3[QC_Data$Bit5 == 0 &amp; QC_Data$Bit4 == 0] &lt;- &quot;Avg Emissivigy error &lt;0.01&quot;
QC_Data$QA_word3[QC_Data$Bit5 == 0 &amp; QC_Data$Bit4 == 1] &lt;- &quot;Avg Emissivigy error &lt;0.02&quot;
QC_Data$QA_word3[QC_Data$Bit5 == 1 &amp; QC_Data$Bit4 == 0] &lt;- &quot;Avg Emissivigy error &lt;0.04&quot;
QC_Data$QA_word3[QC_Data$Bit5 == 1 &amp; QC_Data$Bit4 == 1] &lt;- &quot;Avg Emissivigy error &gt;0.04&quot;

# LST Error flag
QC_Data$QA_word4[QC_Data$Bit7 == 0 &amp; QC_Data$Bit6 == 0] &lt;- &quot;Avg LST error &lt;1K&quot;
QC_Data$QA_word4[QC_Data$Bit7 == 0 &amp; QC_Data$Bit6 == 1] &lt;- &quot;Avg LST error &lt;2K&quot;
QC_Data$QA_word4[QC_Data$Bit7 == 1 &amp; QC_Data$Bit6 == 0] &lt;- &quot;Avg LST error &lt;3K&quot;
QC_Data$QA_word4[QC_Data$Bit7 == 1 &amp; QC_Data$Bit6 == 1] &lt;- &quot;Avg LST error &gt;3K&quot;
#-------------------------------------------------------------------------------------------------


#-------------------------------------------------------------------------------------------------
################ LST RASTER FILTERING #################################
#-------------------------------------------------------------------------------------------------

#-------------------------------------------------------------------------------------------------
# LST CO Day QA filter raster
#-------------------------------------------------------------------------------------------------

# extract unique QA values from raster brick
stime1 &lt;- system.time({
    CO_LST_QA_Day_unique &lt;- foreach(i = 1:length(CO_LST_QA_Day_Sub_list), 
        .combine = &quot;c&quot;, .packages = c(&quot;raster&quot;, &quot;rgdal&quot;)) %dopar% {
        unique(CO_LST_QA_Day_list[[i]])
    }
    
    # final list of unique QA integers from image brick
    CO_LST_QA_Day_unique.final &lt;- unique(CO_LST_QA_Day_unique)
    
    # now subset QA_Data to extract only relevant QA integers
    CO_QC_Data_Day &lt;- subset(QC_Data, Integer_Value %in% CO_LST_QA_Day_unique.final)
    
    ## Now subset based on the most important QA variables select all with
    ## VI quality of 00
    CO.LST.good.Day &lt;- subset(CO_QC_Data_Day, QA_word1 == &quot;VI GOOD&quot;)
    
    # select subset of VI Usefullness
    CO.VI.okay.day &lt;- subset(subset(CO_QC_Data_Day, QA_word1 == &quot;VI Produced,Other Quality&quot;), 
        QA_word4 == &quot;Avg LST error &lt;1K&quot; | QA_word4 == &quot;Avg LST error &lt;2K&quot; | 
            QA_word4 == &quot;Avg LST error &lt;3K&quot;)
    
    # combine good and okay integer values and then assign to a vector.
    CO.LST.QA.day &lt;- rbind(CO.LST.good.Day, CO.VI.okay.day)
    CO.LST.QA.day.int &lt;- CO.LST.QA.day$Integer_Value
    CO.LST.QA.day.bad.int &lt;- setdiff(CO_QC_Data_Day$Integer_Value, CO.LST.QA.day.int)
    co.rep.matrix.day1 &lt;- as.matrix(data.frame(CO.LST.QA.day.int, CO.LST.QA.day.int, 
        rep.int(1, length(CO.LST.QA.day.int))))
    co.rep.matrix.day2 &lt;- as.matrix(data.frame(CO.LST.QA.day.bad.int, CO.LST.QA.day.bad.int, 
        rep(NA, length(CO.LST.QA.day.bad.int))))
    co.rep.matrix.day &lt;- rbind(c(NA, NA, 1), co.rep.matrix.day1, co.rep.matrix.day2)
    
})[3]
stime1

stime2 &lt;- system.time({
    CO_LST_QA_Day_QA &lt;- CO_LST_QA_Day_list
    CO_LST_QA_Day_QA &lt;- foreach(i = 1:length(CO_LST_QA_Day_QA), .packages = c(&quot;raster&quot;, 
        &quot;rgdal&quot;)) %dopar% {
        CO_LST_QA_Day_QA[[i]] &lt;- reclassify(CO_LST_QA_Day_QA[[i]], co.rep.matrix.day, 
            right = NA, filename = paste0(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_LST_1000M/CO_LST_QA_Day_reclass&quot;, 
                &quot;_&quot;, i, &quot;.tif&quot;), format = &quot;GTiff&quot;, dataType = &quot;INT1U&quot;, 
            overwrite = T)
    }
})[3]
stime2

## Final loop creates mask to mask out bad pixels This loop uses the
## foreach fucntion in a cluster configuration and thus requires that
## the raster data be in a list format so that it can subset the data

################# Mask LST
stime3 &lt;- system.time({
    CO_LST_Day_mask &lt;- CO_LST_Day_Sub_list
    CO_LST_Day_mask &lt;- foreach(i = 1:length(CO_LST_Day_mask), .packages = c(&quot;raster&quot;, 
        &quot;rgdal&quot;)) %dopar% {
        CO_LST_Day_mask[[i]] &lt;- mask(CO_LST_Day_mask[[i]], (CO_LST_QA_Day_QA[[i]]))
    }
    
    
    writeRaster(stack(CO_LST_Day_mask), filename = &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_LST_1000M/CO_LST_Day_Mask.tif&quot;, 
        format = &quot;GTiff&quot;, overwrite = T, options = &quot;INTERLEAVE=BAND&quot;, dataType = &quot;INT2U&quot;)
    CO_LST_Day_mask &lt;- brick(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_LST_1000M/CO_LST_Day_Mask.tif&quot;)
})[3]
stime3

################# Infill LST
stime4 &lt;- system.time({
    CO_LST_Day_infill &lt;- foreach.raster.timeseries.run(CO_LST_Day_mask, 
        filename = &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_LST_1000M/CO_LST_Day_infill.tif&quot;, 
        fun = bfastts.infill, dates = co.date.lst, rescale = 0.02)
})[3]
stime4
CO_LST_Day_infill &lt;- brick(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_LST_1000M/CO_LST_Day_infill.tif&quot;)

#-------------------------------------------------------------------------------------------------
# LST CO Night QA filter raster
#-------------------------------------------------------------------------------------------------

# extract unique QA values from raster brick
stime1 &lt;- system.time({
    CO_LST_QA_Night_unique &lt;- foreach(i = 1:length(CO_LST_QA_Night_Sub_list), 
        .combine = &quot;c&quot;, .packages = c(&quot;raster&quot;, &quot;rgdal&quot;)) %dopar% {
        unique(CO_LST_QA_Night_list[[i]])
    }
    
    # final list of unique QA integers from image brick
    CO_LST_QA_Night_unique.final &lt;- unique(CO_LST_QA_Night_unique)
    
    # now subset QA_Data to extract only relevant QA integers
    CO_QC_Data_Night &lt;- subset(QC_Data, Integer_Value %in% CO_LST_QA_Night_unique.final)
    
    ## Now subset based on the most important QA variables select all with
    ## VI quality of 00
    CO.LST.good.Night &lt;- subset(CO_QC_Data_Night, QA_word1 == &quot;VI GOOD&quot;)
    
    # select subset of VI Usefullness
    CO.VI.okay.night &lt;- subset(subset(CO_QC_Data_Night, QA_word1 == &quot;VI Produced,Other Quality&quot;), 
        QA_word4 == &quot;Avg LST error &lt;1K&quot; | QA_word4 == &quot;Avg LST error &lt;2K&quot; | 
            QA_word4 == &quot;Avg LST error &lt;3K&quot;)
    
    # combine good and okay integer values and then assign to a vector.
    CO.LST.QA.night &lt;- rbind(CO.LST.good.Night, CO.VI.okay.night)
    CO.LST.QA.night.int &lt;- CO.LST.QA.night$Integer_Value
    CO.LST.QA.night.bad.int &lt;- setdiff(CO_QC_Data_Night$Integer_Value, 
        CO.LST.QA.night.int)
    co.rep.matrix.night1 &lt;- as.matrix(data.frame(CO.LST.QA.night.int, CO.LST.QA.night.int, 
        rep.int(1, length(CO.LST.QA.night.int))))
    co.rep.matrix.night2 &lt;- as.matrix(data.frame(CO.LST.QA.night.bad.int, 
        CO.LST.QA.night.bad.int, rep(NA, length(CO.LST.QA.night.bad.int))))
    co.rep.matrix.night &lt;- rbind(c(NA, NA, 1), co.rep.matrix.night1, co.rep.matrix.night2)
    
})[3]
stime1

stime2 &lt;- system.time({
    CO_LST_QA_Night_QA &lt;- CO_LST_QA_Night_Sub_list
    CO_LST_QA_Night_QA &lt;- foreach(i = 1:length(CO_LST_QA_Night_QA), .packages = c(&quot;raster&quot;, 
        &quot;rgdal&quot;)) %dopar% {
        CO_LST_QA_Night_QA[[i]] &lt;- reclassify(CO_LST_QA_Night_QA[[i]], 
            co.rep.matrix.night, right = NA, filename = paste0(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_LST_1000M/CO_LST_QA_Night_reclass&quot;, 
                &quot;_&quot;, i, &quot;.tif&quot;), format = &quot;GTiff&quot;, dataType = &quot;INT1U&quot;, 
            overwrite = T)
    }
})[3]
stime2

## Final loop creates mask to mask out bad pixels This loop uses the
## foreach fucntion in a cluster configuration and thus requires that
## the raster data be in a list format so that it can subset the data

################# Mask LST
stime3 &lt;- system.time({
    CO_LST_Night_mask &lt;- CO_LST_Night_Sub_list
    CO_LST_Night_mask &lt;- foreach(i = 1:length(CO_LST_Night_mask), .packages = c(&quot;raster&quot;, 
        &quot;rgdal&quot;)) %dopar% {
        CO_LST_Night_mask[[i]] &lt;- mask(CO_LST_Night_mask[[i]], (CO_LST_QA_Night_QA[[i]]))
    }
    
    
    writeRaster(stack(CO_LST_Night_mask), filename = &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_LST_1000M/CO_LST_Night_Mask.tif&quot;, 
        format = &quot;GTiff&quot;, overwrite = T, options = &quot;INTERLEAVE=BAND&quot;, dataType = &quot;INT2U&quot;)
    CO_LST_Night_mask &lt;- brick(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_LST_1000M/CO_LST_Night_Mask.tif&quot;)
})[3]
stime3

################# Infill LST
stime4 &lt;- system.time({
    CO_LST_Night_infill &lt;- foreach.raster.timeseries.run(CO_LST_Night_mask, 
        filename = &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_LST_1000M/CO_LST_Night_infill.tif&quot;, 
        fun = bfastts.infill, dates = co.date.lst, rescale = 0.02)
})[3]
stime4
CO_LST_Night_infill &lt;- brick(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/CO_LST_1000M/CO_LST_Night_infill.tif&quot;)
################# Difference
CO_LST_Dif_infill &lt;- CO_LST_Day_infill - CO_LST_Night_infill

CO_LST_Day_infill_list &lt;- unstack(CO_LST_Day_infill)
CO_LST_Night_infill_list &lt;- unstack(CO_LST_Night_infill)
CO_LST_Dif_infill &lt;- CO_LST_Night_list

CO_LST_Dif_infill &lt;- foreach(i = 1:length(CO_LST_Night_mask), .packages = c(&quot;raster&quot;, 
    &quot;rgdal&quot;)) %dopar% {
    CO_LST_Dif_infill[[i]] &lt;- overlay(CO_LST_Day_infill_list[[i]], CO_LST_Night_infill_list[[i]], 
        fun = function(r1, r2) {
            return(r1 - r2)
        })
}


#-------------------------------------------------------------------------------------------------
# LST NM Day QA filter raster
#-------------------------------------------------------------------------------------------------

# extract unique QA values from raster brick
stime1 &lt;- system.time({
    NM_LST_QA_Day_unique &lt;- foreach(i = 1:length(NM_LST_QA_Day_Sub_list), 
        .combine = &quot;c&quot;, .packages = c(&quot;raster&quot;, &quot;rgdal&quot;)) %dopar% {
        unique(NM_LST_QA_Day_list[[i]])
    }
    
    # final list of unique QA integers from image brick
    NM_LST_QA_Day_unique.final &lt;- unique(NM_LST_QA_Day_unique)
    
    # now subset QA_Data to extract only relevant QA integers
    NM_QC_Data_Day &lt;- subset(QC_Data, Integer_Value %in% NM_LST_QA_Day_unique.final)
    
    ## Now subset based on the most important QA variables select all with
    ## VI quality of 00
    NM.LST.good.Day &lt;- subset(NM_QC_Data_Day, QA_word1 == &quot;VI GOOD&quot;)
    
    # select subset of VI Usefullness
    NM.VI.okay.day &lt;- subset(subset(NM_QC_Data_Day, QA_word1 == &quot;VI Produced,Other Quality&quot;), 
        QA_word4 == &quot;Avg LST error &lt;1K&quot; | QA_word4 == &quot;Avg LST error &lt;2K&quot; | 
            QA_word4 == &quot;Avg LST error &lt;3K&quot;)
    
    # combine good and okay integer values and then assign to a vector.
    NM.LST.QA.day &lt;- rbind(NM.LST.good.Day, NM.VI.okay.day)
    NM.LST.QA.day.int &lt;- NM.LST.QA.day$Integer_Value
    NM.LST.QA.day.bad.int &lt;- setdiff(NM_QC_Data_Day$Integer_Value, NM.LST.QA.day.int)
    nm.rep.matrix.day1 &lt;- as.matrix(data.frame(NM.LST.QA.day.int, NM.LST.QA.day.int, 
        rep.int(1, length(NM.LST.QA.day.int))))
    nm.rep.matrix.day2 &lt;- as.matrix(data.frame(NM.LST.QA.day.bad.int, NM.LST.QA.day.bad.int, 
        rep(NA, length(NM.LST.QA.day.bad.int))))
    nm.rep.matrix.day &lt;- rbind(c(NA, NA, 1), nm.rep.matrix.day1, nm.rep.matrix.day2)
    
})[3]
stime1

stime2 &lt;- system.time({
    NM_LST_QA_Day_QA &lt;- NM_LST_QA_Day_Sub_list
    NM_LST_QA_Day_QA &lt;- foreach(i = 1:length(NM_LST_QA_Day_QA), .packages = c(&quot;raster&quot;, 
        &quot;rgdal&quot;)) %dopar% {
        NM_LST_QA_Day_QA[[i]] &lt;- reclassify(NM_LST_QA_Day_QA[[i]], nm.rep.matrix.day, 
            right = NA, filename = paste0(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_LST_1000M/NM_LST_QA_Day_reclass&quot;, 
                &quot;_&quot;, i, &quot;.tif&quot;), format = &quot;GTiff&quot;, dataType = &quot;INT1U&quot;, 
            overwrite = T)
    }
})[3]
stime2

NM_LST_QA_Day_QA &lt;- unstack(stack(mixedsort(paste0(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_LST_1000M/&quot;, 
    list.files(path = &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_LST_1000M/&quot;, 
        pattern = &quot;*Day_reclass&quot;, recursive = TRUE)))))

## Final loop creates mask to mask out bad pixels This loop uses the
## foreach fucntion in a cluster configuration and thus requires that
## the raster data be in a list format so that it can subset the data

################# Mask LST
stime3 &lt;- system.time({
    NM_LST_Day_mask &lt;- NM_LST_Day_Sub_list
    NM_LST_Day_mask &lt;- foreach(i = 1:length(NM_LST_Day_mask), .packages = c(&quot;raster&quot;, 
        &quot;rgdal&quot;)) %dopar% {
        NM_LST_Day_mask[[i]] &lt;- mask(NM_LST_Day_mask[[i]], (NM_LST_QA_Day_QA[[i]]))
    }
    
    writeRaster(stack(NM_LST_Day_mask), filename = &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_LST_1000M/NM_LST_Day_Mask.tif&quot;, 
        format = &quot;GTiff&quot;, overwrite = T, options = &quot;INTERLEAVE=BAND&quot;, datatype = &quot;INT2U&quot;, 
        progress = &quot;text&quot;)
    NM_LST_Day_mask &lt;- brick(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_LST_1000M/NM_LST_Day_Mask.tif&quot;)
})[3]
stime3
################# Infill LST
stime4 &lt;- system.time({
    NM_LST_Day_infill &lt;- foreach.raster.timeseries.run(NM_LST_Day_mask, 
        filename = &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_LST_1000M/NM_LST_Day_infill.tif&quot;, 
        fun = bfastts.infill, dates = nm.date.lst, rescale = 0.02)
})[3]
stime4
NM_LST_Day_infill &lt;- brick(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_LST_1000M/NM_LST_Day_infill.tif&quot;)
# save workspace
save.image(&quot;/data/data2/data/CO_NM_Ecosite_mlr.RData&quot;)

#-------------------------------------------------------------------------------------------------
# LST NM Night QA filter raster
#-------------------------------------------------------------------------------------------------

# extract unique QA values from raster brick
stime1 &lt;- system.time({
    NM_LST_QA_Night_unique &lt;- foreach(i = 1:length(NM_LST_QA_Night_Sub_list), 
        .combine = &quot;c&quot;, .packages = c(&quot;raster&quot;, &quot;rgdal&quot;)) %dopar% {
        unique(NM_LST_QA_Night_list[[i]])
    }
    
    # final list of unique QA integers from image brick
    NM_LST_QA_Night_unique.final &lt;- unique(NM_LST_QA_Night_unique)
    
    # now subset QA_Data to extract only relevant QA integers
    NM_QC_Data_Night &lt;- subset(QC_Data, Integer_Value %in% NM_LST_QA_Night_unique.final)
    
    ## Now subset based on the most important QA variables select all with
    ## VI quality of 00
    NM.LST.good.Night &lt;- subset(NM_QC_Data_Night, QA_word1 == &quot;VI GOOD&quot;)
    
    # select subset of VI Usefullness
    NM.VI.okay.night &lt;- subset(subset(NM_QC_Data_Night, QA_word1 == &quot;VI Produced,Other Quality&quot;), 
        QA_word4 == &quot;Avg LST error &lt;1K&quot; | QA_word4 == &quot;Avg LST error &lt;2K&quot; | 
            QA_word4 == &quot;Avg LST error &lt;3K&quot;)
    
    # combine good and okay integer values and then assign to a vector.
    NM.LST.QA.night &lt;- rbind(NM.LST.good.Night, NM.VI.okay.night)
    NM.LST.QA.night.int &lt;- NM.LST.QA.night$Integer_Value
    NM.LST.QA.night.bad.int &lt;- setdiff(NM_QC_Data_Night$Integer_Value, 
        NM.LST.QA.night.int)
    nm.rep.matrix.night1 &lt;- as.matrix(data.frame(NM.LST.QA.night.int, NM.LST.QA.night.int, 
        rep.int(1, length(NM.LST.QA.night.int))))
    nm.rep.matrix.night2 &lt;- as.matrix(data.frame(NM.LST.QA.night.bad.int, 
        NM.LST.QA.night.bad.int, rep(NA, length(NM.LST.QA.night.bad.int))))
    nm.rep.matrix.night &lt;- rbind(c(NA, NA, 1), nm.rep.matrix.night1, nm.rep.matrix.night2)
    
})[3]
stime1

stime2 &lt;- system.time({
    NM_LST_QA_Night_QA &lt;- NM_LST_QA_Night_Sub_list
    NM_LST_QA_Night_QA &lt;- foreach(i = 1:length(NM_LST_QA_Night_QA), .packages = c(&quot;raster&quot;, 
        &quot;rgdal&quot;)) %dopar% {
        NM_LST_QA_Night_QA[[i]] &lt;- reclassify(NM_LST_QA_Night_QA[[i]], 
            nm.rep.matrix.night, right = NA, filename = paste0(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_LST_1000M/NM_LST_QA_Night_reclass&quot;, 
                &quot;_&quot;, i, &quot;.tif&quot;), format = &quot;GTiff&quot;, dataType = &quot;INT1U&quot;, 
            overwrite = T)
    }
})[3]
stime2

## Final loop creates mask to mask out bad pixels This loop uses the
## foreach fucntion in a cluster configuration and thus requires that
## the raster data be in a list format so that it can subset the data

################# Mask LST
stime3 &lt;- system.time({
    NM_LST_Night_mask &lt;- NM_LST_Night_Sub_list
    NM_LST_Night_mask &lt;- foreach(i = 1:length(NM_LST_Night_mask), .packages = c(&quot;raster&quot;, 
        &quot;rgdal&quot;)) %dopar% {
        NM_LST_Night_mask[[i]] &lt;- mask(NM_LST_Night_mask[[i]], (NM_LST_QA_Night_QA[[i]]))
    }
    
    writeRaster(stack(NM_LST_Night_mask), filename = &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_LST_1000M/NM_LST_Night_Mask.tif&quot;, 
        format = &quot;GTiff&quot;, overwrite = T, options = &quot;INTERLEAVE=BAND&quot;, datatype = &quot;INT2U&quot;, 
        progress = &quot;text&quot;)
    NM_LST_Night_mask &lt;- brick(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_LST_1000M/NM_LST_Night_Mask.tif&quot;)
    
})[3]
stime3
################# Infill LST
stime4 &lt;- system.time({
    NM_LST_Night_infill &lt;- foreach.raster.timeseries.run(NM_LST_Night_mask, 
        filename = &quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_LST_1000M/NM_LST_Night_infill.tif&quot;, 
        fun = bfastts.infill, dates = nm.date.lst, rescale = 0.02)
})[3]
stime4
NM_LST_Night_infill &lt;- brick(&quot;/data/data2/data/MODIS/MODIS_ARC/PROCESSES/NM_LST_1000M/NM_LST_Night_infill.tif&quot;)
################# Difference
NM_LST_Dif_infill &lt;- NM_LST_Day_infill - NM_LST_Night_infill

NM_LST_Day_infill_list &lt;- unstack(NM_LST_Day_infill)
NM_LST_Night_infill_list &lt;- unstack(NM_LST_Night_infill)
NM_LST_Dif_infill &lt;- NM_LST_Night_list

NM_LST_Dif_infill &lt;- foreach(i = 1:length(NM_LST_Night_mask), .packages = c(&quot;raster&quot;, 
    &quot;rgdal&quot;)) %dopar% {
    NM_LST_Dif_infill[[i]] &lt;- overlay(NM_LST_Day_infill_list[[i]], NM_LST_Night_infill_list[[i]], 
        fun = function(r1, r2) {
            return(r1 - r2)
        })
}

######################################################################################################################## 

# functions to remove temp files
removeTmpFiles(h = 0)
# clear memory
gc()


############################################################################################### 
##----------- Now we join extracted MODIS data at points with ESG designations --------------##
############################################################################################### 

# create esite df with site index
co.site_id &lt;- data.frame(seq(1, nrow(co.points), 1), co.points$ESG_ID)
names(co.site_id) &lt;- c(&quot;Index&quot;, &quot;esite&quot;)

nm.site_id &lt;- data.frame(seq(1, nrow(nm.points), 1), nm.points$ESG_ID)
names(nm.site_id) &lt;- c(&quot;Index&quot;, &quot;esite&quot;)
#-------------------------------------------------------------------------------------------------

# create NDVI df with site index
co.NDVI.df &lt;- data.frame(seq(1, nrow(co.points), 1), co.timeseries.ndvi)
names(co.NDVI.df) &lt;- c(&quot;Index&quot;, paste0(&quot;T&quot;, seq(1, ncol(co.timeseries.ndvi), 
    1)))
co.esite.spec.ndvi &lt;- data.frame(join(co.site_id, co.NDVI.df, by = &quot;Index&quot;))

nm.NDVI.df &lt;- data.frame(seq(1, nrow(nm.points), 1), nm.timeseries.ndvi)
names(nm.NDVI.df) &lt;- c(&quot;Index&quot;, paste0(&quot;T&quot;, seq(1, ncol(nm.timeseries.ndvi), 
    1)))
nm.esite.spec.ndvi &lt;- data.frame(join(nm.site_id, nm.NDVI.df, by = &quot;Index&quot;))
#-------------------------------------------------------------------------------------------------

# create EVI df with site index
co.EVI.df &lt;- data.frame(seq(1, nrow(co.points), 1), co.timeseries.evi)
names(co.EVI.df) &lt;- c(&quot;Index&quot;, paste0(&quot;T&quot;, seq(1, ncol(co.timeseries.evi), 
    1)))
co.esite.spec.evi &lt;- data.frame(join(co.site_id, co.EVI.df, by = &quot;Index&quot;))

nm.EVI.df &lt;- data.frame(seq(1, nrow(nm.points), 1), nm.timeseries.evi)
names(nm.EVI.df) &lt;- c(&quot;Index&quot;, paste0(&quot;T&quot;, seq(1, ncol(nm.timeseries.evi), 
    1)))
nm.esite.spec.evi &lt;- data.frame(join(nm.site_id, nm.EVI.df, by = &quot;Index&quot;))
#-------------------------------------------------------------------------------------------------

# SATVI df with site index
co.esite.SATVI
#-------------------------------------------------------------------------------------------------

# create EVI df with site index
co.landcover.df &lt;- data.frame(seq(1, nrow(co.points), 1), co.landcover.dummy)
names(co.landcover.df) &lt;- c(&quot;Index&quot;, names(co.landcover.df[-1]))
co.esite.landcover &lt;- data.frame(join(co.site_id, co.landcover.df, by = &quot;Index&quot;))

nm.landcover.df &lt;- data.frame(seq(1, nrow(nm.points), 1), nm.landcover.dummy)
names(nm.landcover.df) &lt;- c(&quot;Index&quot;, names(nm.landcover.df[-1]))
nm.esite.landcover &lt;- data.frame(join(nm.site_id, nm.landcover.df, by = &quot;Index&quot;))
#-------------------------------------------------------------------------------------------------

# create VI Red df with site index
co.VI.RED.df &lt;- data.frame(seq(1, nrow(co.points), 1), co.timeseries.vi.red)
names(co.VI.RED.df) &lt;- c(&quot;Index&quot;, paste0(&quot;T&quot;, seq(1, ncol(co.timeseries.vi.red), 
    1)))
co.esite.spec.vi.red &lt;- data.frame(join(co.site_id, co.VI.RED.df, by = &quot;Index&quot;))

nm.VI.RED.df &lt;- data.frame(seq(1, nrow(nm.points), 1), nm.timeseries.vi.red)
names(nm.VI.RED.df) &lt;- c(&quot;Index&quot;, paste0(&quot;T&quot;, seq(1, ncol(nm.timeseries.vi.red), 
    1)))
nm.esite.spec.vi.red &lt;- data.frame(join(nm.site_id, nm.VI.RED.df, by = &quot;Index&quot;))
#-------------------------------------------------------------------------------------------------

# create BRDF Red df with site index
co.RED.df &lt;- data.frame(seq(1, nrow(co.points), 1), co.timeseries.red)
names(co.RED.df) &lt;- c(&quot;Index&quot;, paste0(&quot;T&quot;, seq(1, ncol(co.timeseries.red), 
    1)))
co.esite.spec.red &lt;- data.frame(join(co.site_id, co.RED.df, by = &quot;Index&quot;))

nm.RED.df &lt;- data.frame(seq(1, nrow(nm.points), 1), nm.timeseries.red)
names(nm.RED.df) &lt;- c(&quot;Index&quot;, paste0(&quot;T&quot;, seq(1, ncol(nm.timeseries.red), 
    1)))
nm.esite.spec.red &lt;- data.frame(join(nm.site_id, nm.RED.df, by = &quot;Index&quot;))
#-------------------------------------------------------------------------------------------------

# create BRDF NIR df with site index
co.NIR.df &lt;- data.frame(seq(1, nrow(co.points), 1), co.timeseries.nir)
names(co.NIR.df) &lt;- c(&quot;Index&quot;, paste0(&quot;T&quot;, seq(1, ncol(co.timeseries.nir), 
    1)))
co.esite.spec.nir &lt;- data.frame(join(co.site_id, co.NIR.df, by = &quot;Index&quot;))

nm.NIR.df &lt;- data.frame(seq(1, nrow(nm.points), 1), nm.timeseries.nir)
names(nm.NIR.df) &lt;- c(&quot;Index&quot;, paste0(&quot;T&quot;, seq(1, ncol(nm.timeseries.nir), 
    1)))
nm.esite.spec.nir &lt;- data.frame(join(nm.site_id, nm.NIR.df, by = &quot;Index&quot;))

#-------------------------------------------------------------------------------------------------

# create BRDF SWIR1 df with site index
co.swir1.df &lt;- data.frame(seq(1, nrow(co.points), 1), co.timeseries.swir1)
names(co.swir1.df) &lt;- c(&quot;Index&quot;, paste0(&quot;T&quot;, seq(1, ncol(co.timeseries.swir1), 
    1)))
co.esite.spec.swir1 &lt;- data.frame(join(co.site_id, co.swir1.df, by = &quot;Index&quot;))

nm.swir1.df &lt;- data.frame(seq(1, nrow(nm.points), 1), nm.timeseries.swir1)
names(nm.swir1.df) &lt;- c(&quot;Index&quot;, paste0(&quot;T&quot;, seq(1, ncol(nm.timeseries.swir1), 
    1)))
nm.esite.spec.swir1 &lt;- data.frame(join(nm.site_id, nm.swir1.df, by = &quot;Index&quot;))
#-------------------------------------------------------------------------------------------------

# create VI swir2 df with site index
co.VI.swir2.df &lt;- data.frame(seq(1, nrow(co.points), 1), co.timeseries.vi.swir2)
names(co.VI.swir2.df) &lt;- c(&quot;Index&quot;, paste0(&quot;SWIR2_&quot;, seq(1, ncol(co.timeseries.vi.swir2), 
    1)))
co.esite.spec.vi.swir2 &lt;- data.frame(join(co.site_id, co.VI.swir2.df, by = &quot;Index&quot;))

nm.VI.swir2.df &lt;- data.frame(seq(1, nrow(nm.points), 1), nm.timeseries.vi.swir2)
names(nm.VI.swir2.df) &lt;- c(&quot;Index&quot;, paste0(&quot;SWIR2_&quot;, seq(1, ncol(nm.timeseries.vi.swir2), 
    1)))
nm.esite.spec.vi.swir2 &lt;- data.frame(join(nm.site_id, nm.VI.swir2.df, by = &quot;Index&quot;))
#-------------------------------------------------------------------------------------------------

# create BRDF swir2 df with site index
co.swir2.df &lt;- data.frame(seq(1, nrow(co.points), 1), co.timeseries.swir2)
names(co.swir2.df) &lt;- c(&quot;Index&quot;, paste0(&quot;T&quot;, seq(1, ncol(co.timeseries.swir2), 
    1)))
co.esite.spec.swir2 &lt;- data.frame(join(co.site_id, co.swir2.df, by = &quot;Index&quot;))

nm.swir2.df &lt;- data.frame(seq(1, nrow(nm.points), 1), nm.timeseries.swir2)
names(nm.swir2.df) &lt;- c(&quot;Index&quot;, paste0(&quot;T&quot;, seq(1, ncol(nm.timeseries.swir2), 
    1)))
nm.esite.spec.swir2 &lt;- data.frame(join(nm.site_id, nm.swir2.df, by = &quot;Index&quot;))
#-------------------------------------------------------------------------------------------------

# create Landcover df with site index
co.landcover.df2 &lt;- data.frame(seq(1, nrow(co.points), 1), co.landcover.df)
names(co.landcover.df2)[1] &lt;- c(&quot;Index&quot;)
co.esite.landcover &lt;- data.frame(join(co.site_id, co.landcover.df2, by = &quot;Index&quot;))
# co.esite.landcover[] &lt;- lapply(co.esite.landcover, factor)

nm.landcover.df2 &lt;- data.frame(seq(1, nrow(nm.points), 1), nm.landcover.df)
names(nm.landcover.df2)[1] &lt;- c(&quot;Index&quot;)
nm.esite.landcover &lt;- data.frame(join(nm.site_id, nm.landcover.df2, by = &quot;Index&quot;))
# nm.esite.landcover[] &lt;- lapply(nm.esite.landcover, factor) create LST
# day df with site index
#-------------------------------------------------------------------------------------------------

# create LST day df with site index
co.LST.day.df &lt;- data.frame(seq(1, nrow(co.points), 1), co.lst.day)
names(co.LST.day.df) &lt;- c(&quot;Index&quot;, paste0(&quot;Tday_&quot;, seq(1, ncol(co.lst.day), 
    1)))
co.esite.LST.day &lt;- data.frame(join(co.site_id, co.LST.day.df, by = &quot;Index&quot;))

nm.LST.day.df &lt;- data.frame(seq(1, nrow(nm.points), 1), nm.lst.day)
names(nm.LST.day.df) &lt;- c(&quot;Index&quot;, paste0(&quot;Tday_&quot;, seq(1, ncol(nm.lst.day), 
    1)))
nm.esite.LST.day &lt;- data.frame(join(nm.site_id, nm.LST.day.df, by = &quot;Index&quot;))
#-------------------------------------------------------------------------------------------------

# create LST night df with site index
co.LST.night.df &lt;- data.frame(seq(1, nrow(co.points), 1), co.lst.night)
names(co.LST.night.df) &lt;- c(&quot;Index&quot;, paste0(&quot;Tnight_&quot;, seq(1, ncol(co.lst.night), 
    1)))
co.esite.LST.night &lt;- data.frame(join(co.site_id, co.LST.night.df, by = &quot;Index&quot;))

nm.LST.night.df &lt;- data.frame(seq(1, nrow(nm.points), 1), nm.lst.night)
names(nm.LST.night.df) &lt;- c(&quot;Index&quot;, paste0(&quot;Tnight_&quot;, seq(1, ncol(nm.lst.night), 
    1)))
nm.esite.LST.night &lt;- data.frame(join(nm.site_id, nm.LST.night.df, by = &quot;Index&quot;))
#-------------------------------------------------------------------------------------------------

# create LST dif df with site index
co.LST.dif.df &lt;- data.frame(seq(1, nrow(co.points), 1), co.lst.dif)
names(co.LST.dif.df) &lt;- c(&quot;Index&quot;, paste0(&quot;Tdif_&quot;, seq(1, ncol(co.lst.dif), 
    1)))
co.esite.LST.dif &lt;- data.frame(join(co.site_id, co.LST.dif.df, by = &quot;Index&quot;))

co.esite.LST.all &lt;- cbind(co.esite.LST.day, co.LST.night.df[, -1:-2], co.esite.LST.dif[, 
    -1:-2])
co.esite.LST.day.night &lt;- cbind(co.esite.LST.day, co.LST.night.df[, -1:-2])

nm.LST.dif.df &lt;- data.frame(seq(1, nrow(nm.points), 1), nm.lst.dif)
names(nm.LST.dif.df) &lt;- c(&quot;Index&quot;, paste0(&quot;Tdif_&quot;, seq(1, ncol(nm.lst.dif), 
    1)))
nm.esite.LST.dif &lt;- data.frame(join(nm.site_id, nm.LST.dif.df, by = &quot;Index&quot;))

nm.esite.LST.all &lt;- cbind(nm.esite.LST.day, nm.LST.night.df[, -1:-2], nm.esite.LST.dif[, 
    -1:-2])
nm.esite.LST.day.night &lt;- cbind(nm.esite.LST.day, nm.LST.night.df[, -1:-2])
#-------------------------------------------------------------------------------------------------

# Calculate SATVI
satvi.co &lt;- (((co.esite.spec.swir1[, -1:-2]) - co.esite.spec.vi.red[, -1:-2])/((co.esite.spec.swir1[, 
    -1:-2]) + co.esite.spec.vi.red[, -1:-2] + 0.5)) * (1 + 0.5) - (co.esite.spec.vi.swir2[, 
    -1:-2]/2)
co.SATVI.df &lt;- data.frame(seq(1, nrow(co.points), 1), satvi.co)
names(co.SATVI.df) &lt;- c(&quot;Index&quot;, paste0(&quot;T&quot;, seq(1, ncol(satvi.co), 1)))
co.esite.SATVI &lt;- data.frame(join(co.site_id, co.SATVI.df, by = &quot;Index&quot;))

# co.points.satvi &lt;- extract(CO_SATVI_infill, co.points)
# head(co.points.satvi) nm.points.terrain &lt;-
# sfSapply(terrain.nm_list,extract,y=nm.points)

satvi.nm &lt;- (((nm.esite.spec.swir1[, -1:-2]/10000) - nm.esite.spec.vi.red[, 
    -1:-2])/((nm.esite.spec.swir1[, -1:-2]/10000) + nm.esite.spec.vi.red[, 
    -1:-2] + 0.5)) * (1 + 0.5) - (nm.esite.spec.vi.swir2[, -1:-2]/2)
nm.SATVI.df &lt;- data.frame(seq(1, nrow(nm.points), 1), satvi.nm)
names(nm.SATVI.df) &lt;- c(&quot;Index&quot;, paste0(&quot;T&quot;, seq(1, ncol(satvi), 1)))
nm.esite.SATVI &lt;- data.frame(join(nm.site_id, nm.SATVI.df, by = &quot;Index&quot;))


############################################################################################################### 
save.image(&quot;/data/data2/data/esgMapping/R/CO_NM_Ecosite_hyptemp_process.RData&quot;)
load(&quot;/data/data2/data/esgMapping/R/CO_NM_Ecosite_hyptemp_process.RData&quot;)
############################################################################################################### </code></pre>
<br>
<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-sessioninfo" data-toggle="collapse" data-target="#workflowr-sessioninfo" style="display: block;">
<span class="glyphicon glyphicon-wrench" aria-hidden="true"></span> Session information
</button>
</p>
<div id="workflowr-sessioninfo" class="collapse">
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>R version 3.5.2 (2018-12-20)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252 
[2] LC_CTYPE=English_United States.1252   
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C                          
[5] LC_TIME=English_United States.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
 [1] workflowr_1.3.0   Rcpp_1.0.1        digest_0.6.19    
 [4] rprojroot_1.3-2   backports_1.1.4   git2r_0.25.2.9000
 [7] magrittr_1.5      evaluate_0.13     stringi_1.4.3    
[10] fs_1.2.7          whisker_0.3-2     rmarkdown_1.12   
[13] tools_3.5.2       stringr_1.4.0     glue_1.3.1       
[16] xfun_0.6          yaml_2.2.0        compiler_3.5.2   
[19] htmltools_0.3.6   knitr_1.23       </code></pre>
</div>
</div>


<!-- Adjust MathJax settings so that all math formulae are shown using
TeX fonts only; see
http://docs.mathjax.org/en/latest/configuration.html.  This will make
the presentation more consistent at the cost of the webpage sometimes
taking slightly longer to load. Note that this only works because the
footer is added to webpages before the MathJax javascript. -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
